{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Greenmask","text":"<p>Greenmask is a powerful open-source utility that is designed for logical database backup dumping, obfuscation, and restoration. It offers extensive functionality for backup, anonymization, and data masking.</p> <p>Greenmask is written in pure Go and includes ported PostgreSQL libraries that allows for platform independence. This tool is stateless and does not require any changes to your database schema. It is designed to be highly customizable and backward-compatible with existing PostgreSQL utilities.</p>"},{"location":"#purpose","title":"Purpose","text":"<p>The Greenmask utility plays a central role in the Greenmask ecosystem. Our goal is to develop a comprehensive, UI-based solution for managing obfuscation procedures. We recognize the challenges of maintaining obfuscation consistency throughout the software lifecycle. Greenmask is dedicated to providing valuable tools and features that ensure the obfuscation process remains fresh, predictable, and transparent.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Cross-platform \u2014 can be easily built and executed on any platform, thanks to its Go-based architecture,   which eliminates platform dependencies.</li> <li>Database type safe \u2014 ensures data integrity by validating data and utilizing the database driver for   encoding and decoding operations. This approach guarantees the preservation of data formats.</li> <li>Transformation validation and easy maintainable \u2014 during obfuscation development, Greenmask provides validation warnings and a transformation diff feature, allowing you to monitor and maintain transformations effectively throughout the software lifecycle.</li> <li>Partitioned tables transformation inheritance \u2014 define transformation configurations once and apply them to all partitions within partitioned tables, simplifying the obfuscation process.</li> <li>Stateless \u2014 Greenmask operates as a logical dump and does not impact your existing database schema.</li> <li>Backward compatible \u2014 it fully supports the same features and protocols as existing vanilla PostgreSQL utilities. Dumps created by Greenmask can be successfully restored using the pg_restore utility.</li> <li>Extensible \u2014 users have the flexibility to implement domain-based transformations in any programming language or use predefined templates.</li> <li>Declarative \u2014 Greenmask allows you to define configurations in a structured, easily parsed, and recognizable format.</li> <li>Integrable \u2014 integrate Greenmask seamlessly into your CI/CD system for automated database obfuscation and restoration.</li> <li>Parallel execution \u2014 take advantage of parallel dumping and restoration, significantly reducing the time required to deliver results.</li> <li>Provide variety of storages \u2014 Greenmask offers a variety of storage options for local and remote data storage, including directories and S3-like storage solutions.</li> </ul>"},{"location":"#use-cases","title":"Use cases","text":"<p>Greenmask is ideal for various scenarios, including:</p> <ul> <li>Backup and restoration. Use Greenmask for your daily routines involving logical backup dumping and restoration. It seamlessly handles tasks like table restoration after truncation. Its functionality closely mirrors that of pg_dump and pg_restore, making it a straightforward replacement.</li> <li>Anonymization, transformation, and data masking. Employ Greenmask for anonymizing, transforming, and masking backups, especially when setting up a staging environment or for analytical purposes. It simplifies the deployment of a pre-production environment with consistently anonymized data, facilitating faster time-to-market in the development lifecycle.</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>Email</li> <li>Twitter</li> <li>Telegram</li> <li>Discord</li> <li>DockerHub</li> </ul>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#introduction","title":"Introduction","text":"<p>It is evident that the most appropriate approach for executing logical backup dumping and restoration is by leveraging the core PostgreSQL utilities, specifically <code>pg_dump</code> and <code>pg_restore</code>. Greenmask has been purposefully designed to align with PostgreSQL's native utilities, ensuring compatibility. Greenmask primarily handles data dumping operations independently and delegates the responsibilities of schema dumping and restoration to <code>pg_dump</code> and <code>pg_restore</code> respectively, maintaining seamless integration with PostgreSQL's standard tools.</p>"},{"location":"architecture/#backup-process","title":"Backup process","text":"<p>The process of backing up PostgreSQL databases is divided into three distinct sections:</p> <ul> <li>Pre-data \u2014 this section encompasses the raw schema of tables, excluding primary keys (PK) and foreign keys (FK).</li> <li>Data \u2014 the data section contains the actual table data in COPY format, including information about sequence current values and Large Objects data.</li> <li>Post-data \u2014 in this section, you'll find the definitions of indexes, triggers, rules, and constraints (such as PK and FK).</li> </ul> <p>Greenmask focuses exclusively on the data section during runtime. It delegates the handling of the <code>pre-data</code> and <code>post-data</code> sections to the core PostgreSQL utilities, <code>pg_dump</code> and <code>pg_restore</code>.</p> <p>Greenmask employs the directory format of <code>pg_dump</code> and <code>pg_restore</code>. This format is particularly suitable for parallel execution and partial restoration, and it includes clear metadata files that aid in determining the backup and restoration steps. Greenmask has been optimized to work seamlessly with remote storage systems and obfuscation procedures.</p> <p>When performing data dumping, Greenmask utilizes the COPY command in TEXT format, maintaining reliability and compatibility with the vanilla PostgreSQL utilities.</p> <p>Additionally, Greenmask supports parallel execution, significantly reducing the time required for the dumping process.</p>"},{"location":"architecture/#storage-options","title":"Storage options","text":"<p>The core PostgreSQL utilities, <code>pg_dump</code> and <code>pg_restore</code>, traditionally operate with files in a directory format, offering no alternative methods. To meet modern backup requirements and provide flexible approaches, Greenmask introduces the concept of storages.</p> <ul> <li><code>s3</code> \u2014 this option supports any S3-like storage system, including AWS S3, which makes it versatile and adaptable to various cloud-based storage solutions.</li> <li><code>directory</code> \u2014 this is the standard choice, representing the ordinary filesystem directory for local storage.</li> </ul> <p>Note</p> <p>If you have suggestions for additional storage options that would be valuable to implement, feel free to share your ideas with us. Greenmask aims to accommodate a wide range of storage preferences to suit diverse backup needs.</p>"},{"location":"architecture/#restoration-process","title":"Restoration process","text":"<p>In the restoration process, Greenmask combines the capabilities of different tools:</p> <ul> <li>For schema restoration Greenmask utilizes <code>pg_restore</code> to restore the database schema. This ensures that the schema is accurately reconstructed.</li> <li>For data restoration Greenmask independently applies the data using the COPY protocol. This allows Greenmask to handle the data efficiently, especially when working with various storage solutions. Greenmask is aware of the restoration metadata, which enables it to download only the necessary data. This feature is particularly useful for partial restoration scenarios, such as restoring a single table from a complete backup.</li> </ul> <p>Greenmask also supports parallel restoration, which can significantly reduce the time required to complete the restoration process. This parallel execution enhances the efficiency of restoring large datasets.</p>"},{"location":"architecture/#data-obfuscation-and-validation","title":"Data obfuscation and validation","text":"<p>Greenmask works with COPY lines, collects schema metadata using the Golang driver, and employs this driver in the encoding and decoding process. The validate command offers a way to assess the impact on both schema (validation warnings) and data (transformation and displaying differences). This command allows you to validate the schema and data transformations, ensuring the desired outcomes during the obfuscation process.</p>"},{"location":"architecture/#customization","title":"Customization","text":"<p>If your table schema relies on functional dependencies between columns, you can address this challenge using the TemplateRecord transformer. This transformer enables you to define transformation logic for entire tables, offering type-safe operations when assigning new values.</p> <p>Greenmask provides a framework for creating your custom transformers, which can be reused efficiently. These transformers can be seamlessly integrated without requiring recompilation, thanks to the PIPE (stdin/stdout) interaction.</p> <p>Note</p> <p>Furthermore, Greenmask's architecture is designed to be highly extensible, making it possible to introduce other interaction protocols, such as HTTP or Socket, for conducting obfuscation procedures.</p>"},{"location":"architecture/#postgresql-version-compatibility","title":"PostgreSQL version compatibility","text":"<p>Greenmask is compatible with PostgreSQL versions 11 and higher.</p>"},{"location":"commands/","title":"Commands","text":""},{"location":"commands/#introduction","title":"Introduction","text":"Greenmask available commands<pre><code>greenmask \\\n  --log-format=[json|text] \\\n  --log-level=[debug|info|error] \\\n  --config=config.yml \\\n  [dump|list-dumps|delete|list-transformers|show-transformer|restore|show-dump]`\n</code></pre> <p>You can use the following commands within Greenmask:</p> <ul> <li><code>dump</code> \u2014 initiates the data dumping process</li> <li><code>list-dumps</code> \u2014 lists all available dumps stored in the system</li> <li><code>delete</code> \u2014 deletes a specific dump from the storage</li> <li><code>list-transformers</code> \u2014 displays a list of available transformers along with their documentation</li> <li><code>show-transformer</code> \u2014 displays information about the specified transformer</li> <li><code>restore</code> \u2014 restores data to the target database either by specifying a <code>dumpId</code> or using the latest available dump</li> <li><code>show-dump</code> \u2014 provides metadata information about a particular dump, offering insights into its structure and   attributes</li> </ul> <p>For any of the commands mentioned above, you can include the following common flags:</p> <ul> <li><code>--log-format</code> \u2014 specifies the desired format for log output, which can be either <code>json</code> or <code>text</code>. This parameter is   optional, with the default format set to <code>text</code>.</li> <li><code>--log-level</code> \u2014 sets the desired level for log output, which can be one of <code>debug</code>, <code>info</code>, or <code>error</code>. This parameter   is optional, with the default log level being <code>info</code>.</li> <li><code>--config</code> \u2014 requires the specification of a configuration file in YAML format. This configuration file is mandatory   for Greenmask to operate correctly.</li> <li><code>--help</code> \u2014 displays comprehensive help information for Greenmask, providing guidance on its usage and available   commands.</li> </ul>"},{"location":"commands/#validate","title":"validate","text":"<p>The <code>validate</code> command allows you to perform a validation procedure and compare data transformations.</p> <p>Below is a list of all supported flags for the <code>validate</code> command:</p> Supported flags<pre><code>Usage:\n  greenmask validate [flags]\n\nFlags:\n      --data                  Perform test dump for --rows-limit rows and print it pretty\n      --diff                  Find difference between original and transformed data\n      --format string         Format of output. possible values [text|json] (default \"text\")\n      --rows-limit uint       Check tables dump only for specific tables (default 10)\n      --schema                Make a schema diff between previous dump and the current state\n      --table strings         Check tables dump only for specific tables\n      --table-format string   Format of table output (only for --format=text). Possible values [vertical|horizontal] (default \"vertical\")\n      --transformed-only      Print only transformed column and primary key\n      --warnings              Print warnings\n</code></pre> <p>Validate command can exit with non-zero code when:</p> <ul> <li>Any error occurred</li> <li>Validate was called with <code>--warings</code> flag and there are warnings</li> <li>Validate was called with <code>--schema</code> flag and there are schema differences</li> </ul> <p>All of those cases may be used for CI/CD pipelines to stop the process when something went wrong. This is especially useful when <code>--schema</code> flag is used - this allows to avoid data leakage when schema changed.</p> <p>You can use the <code>--table</code> flag multiple times to specify the tables you want to check. Tables can be written with or without schema names (e. g., <code>public.table_name</code> or <code>table_name</code>). If you specify multiple tables from different schemas, an error will be thrown.</p> <p>To start validation, use the following command:</p> <pre><code>greenmask --config=config.yml validate \\\n  --warnings \\\n  --data \\\n  --diff \\\n  --schema \\\n  --format=text \\\n  --table-format=vertical \\\n  --transformed-only \\\n  --rows-limit=1\n</code></pre> Validation output example<pre><code>2024-03-15T19:46:12+02:00 WRN ValidationWarning={\"hash\":\"aa808fb574a1359c6606e464833feceb\",\"meta\":{\"ColumnName\":\"birthdate\",\"ConstraintDef\":\"CHECK (birthdate \\u003e= '1930-01-01'::date AND birthdate \\u003c= (now() - '18 years'::interval))\",\"ConstraintName\":\"humanresources\",\"ConstraintSchema\":\"humanresources\",\"ConstraintType\":\"Check\",\"ParameterName\":\"column\",\"SchemaName\":\"humanresources\",\"TableName\":\"employee\",\"TransformerName\":\"NoiseDate\"},\"msg\":\"possible constraint violation: column has Check constraint\",\"severity\":\"warning\"}\n</code></pre> <p>The validation output will provide detailed information about potential constraint violations and schema issues. Each line contains nested JSON data under the <code>ValidationWarning</code> key, offering insights into the affected part of the configuration and potential constraint violations.</p> <p>Pretty formatted validation warning<pre><code>{ \n  \"hash\": \"aa808fb574a1359c6606e464833feceb\", // (13)\n  \"meta\": { // (1)\n    \"ColumnName\": \"birthdate\", // (2)\n    \"ConstraintDef\": \"CHECK (birthdate &gt;= '1930-01-01'::date AND birthdate &lt;= (now() - '18 years'::interval))\", // (3)\n    \"ConstraintName\": \"humanresources\", // (4)\n    \"ConstraintSchema\": \"humanresources\", // (5)\n    \"ConstraintType\": \"Check\", // (6)\n    \"ParameterName\": \"column\", // (7)\n    \"SchemaName\": \"humanresources\", // (8)\n    \"TableName\": \"employee\", // (9)\n    \"TransformerName\": \"NoiseDate\" // (10)\n  },\n  \"msg\": \"possible constraint violation: column has Check constraint\", // (11)\n  \"severity\": \"warning\" // (12)\n}\n</code></pre></p> <ol> <li>Detailed metadata. The validation output provides comprehensive metadata to pinpoint the source of problems.</li> <li>Column name indicates the name of the affected column.</li> <li>Constraint definition specifies the definition of the constraint that may be violated.</li> <li>Constraint name identifies the name of the constraint that is potentially violated.</li> <li>Constraint schema name indicates the schema in which the constraint is defined.</li> <li>Type of constraint represents the type of constraint and can be one of the following:    <pre><code>* ForeignKey\n* Check\n* NotNull\n* PrimaryKey\n* PrimaryKeyReferences\n* Unique\n* Length\n* Exclusion\n* TriggerConstraint\n</code></pre></li> <li>Table schema name specifies the schema name of the affected table.</li> <li>Table name identifies the name of the table where the problem occurs.</li> <li>Transformer name indicates the name of the transformer responsible for the transformation.</li> <li>Name of affected parameter typically, this is the name of the column parameter that is relevant to the     validation warning.</li> <li>Validation warning description provides a detailed description of the validation warning and the reason behind     it.</li> <li>Severity of validation warning indicates the severity level of the validation warning and can be one of the     following:     <pre><code>* error\n* warning\n* info\n* debug\n</code></pre></li> <li>Hash is a unique identifier of the validation warning. It is used to resolve the warning in the config file</li> </ol> <p>Note</p> <p>A validation warning with a severity level of <code>\"error\"</code> is considered critical and must be addressed before the dump operation can proceed. Failure to resolve such warnings will prevent the dump operation from being executed.</p> Schema diff changed output example<pre><code>2024-03-15T19:46:12+02:00 WRN Database schema has been changed Hint=\"Check schema changes before making new dump\" PreviousDumpId=1710520855501\n2024-03-15T19:46:12+02:00 WRN Column renamed Event=ColumnRenamed Signature={\"CurrentColumnName\":\"id1\",\"PreviousColumnName\":\"id\",\"TableName\":\"test\",\"TableSchema\":\"public\"}\n2024-03-15T19:46:12+02:00 WRN Column type changed Event=ColumnTypeChanged Signature={\"ColumnName\":\"id\",\"CurrentColumnType\":\"bigint\",\"CurrentColumnTypeOid\":\"20\",\"PreviousColumnType\":\"integer\",\"PreviousColumnTypeOid\":\"23\",\"TableName\":\"test\",\"TableSchema\":\"public\"}\n2024-03-15T19:46:12+02:00 WRN Column created Event=ColumnCreated Signature={\"ColumnName\":\"name\",\"ColumnType\":\"text\",\"TableName\":\"test\",\"TableSchema\":\"public\"}\n2024-03-15T19:46:12+02:00 WRN Table created Event=TableCreated Signature={\"SchemaName\":\"public\",\"TableName\":\"test1\",\"TableOid\":\"20563\"}\n</code></pre> <p>Example of validation diff:</p> <p></p> <p>The validation diff is presented in a neatly formatted table. In this table:</p> <ul> <li>Columns that are affected by the transformation are highlighted with a red background.</li> <li>The pre-transformation values are displayed in green.</li> <li>The post-transformation values are shown in red.</li> <li>The result in <code>--format=text</code> can be displayed in either horizontal (<code>--table-format=horizontal</code>) or    vertical (<code>--table-format=vertical</code>) format, making it easy to visualize and understand the    differences between the original and transformed data.</li> </ul> <p>The whole validate command may be run in json format including logging making easy to parse the structure. </p> <pre><code>greenmask --config=config.yml validate \\\n  --warnings \\\n  --data \\\n  --diff \\\n  --schema \\\n  --format=json \\\n  --table-format=vertical \\\n  --transformed-only \\\n  --rows-limit=1 \\\n  --log-format=json\n</code></pre> <p>The json object result</p> The validation warningSchema diff eventsTransformation diff line <pre><code>{\n  \"level\": \"warn\",\n  \"ValidationWarning\": {\n    \"msg\": \"possible constraint violation: column has Check constraint\",\n    \"severity\": \"warning\",\n    \"meta\": {\n      \"ColumnName\": \"birthdate\",\n      \"ConstraintDef\": \"CHECK (birthdate &gt;= '1930-01-01'::date AND birthdate &lt;= (now() - '18 years'::interval))\",\n      \"ConstraintName\": \"humanresources\",\n      \"ConstraintSchema\": \"humanresources\",\n      \"ConstraintType\": \"Check\",\n      \"ParameterName\": \"column\",\n      \"SchemaName\": \"humanresources\",\n      \"TableName\": \"employee\",\n      \"TransformerName\": \"NoiseDate\"\n    },\n    \"hash\": \"aa808fb574a1359c6606e464833feceb\"\n  },\n  \"time\": \"2024-03-15T20:01:51+02:00\"\n}\n</code></pre> <pre><code>{\n  \"level\": \"warn\",\n  \"PreviousDumpId\": \"1710520855501\",\n  \"Diff\": [\n    {\n      \"event\": \"ColumnRenamed\",\n      \"signature\": {\n        \"CurrentColumnName\": \"id1\",\n        \"PreviousColumnName\": \"id\",\n        \"TableName\": \"test\",\n        \"TableSchema\": \"public\"\n      }\n    },\n    {\n      \"event\": \"ColumnTypeChanged\",\n      \"signature\": {\n        \"ColumnName\": \"id\",\n        \"CurrentColumnType\": \"bigint\",\n        \"CurrentColumnTypeOid\": \"20\",\n        \"PreviousColumnType\": \"integer\",\n        \"PreviousColumnTypeOid\": \"23\",\n        \"TableName\": \"test\",\n        \"TableSchema\": \"public\"\n      }\n    },\n    {\n      \"event\": \"ColumnCreated\",\n      \"signature\": {\n        \"ColumnName\": \"name\",\n        \"ColumnType\": \"text\",\n        \"TableName\": \"test\",\n        \"TableSchema\": \"public\"\n      }\n    },\n    {\n      \"event\": \"TableCreated\",\n      \"signature\": {\n        \"SchemaName\": \"public\",\n        \"TableName\": \"test1\",\n        \"TableOid\": \"20563\"\n      }\n    }\n  ],\n  \"Hint\": \"Check schema changes before making new dump\",\n  \"time\": \"2024-03-15T20:01:51+02:00\",\n  \"message\": \"Database schema has been changed\"\n}\n</code></pre> <pre><code>{\n  \"schema\": \"humanresources\",\n  \"name\": \"employee\",\n  \"primary_key_columns\": [\n    \"businessentityid\"\n  ],\n  \"with_diff\": true,\n  \"transformed_only\": true,\n  \"records\": [\n    {\n      \"birthdate\": {\n        \"original\": \"1969-01-29\",\n        \"transformed\": \"1964-10-20\",\n        \"equal\": false,\n        \"implicit\": true\n      },\n      \"businessentityid\": {\n        \"original\": \"1\",\n        \"transformed\": \"1\",\n        \"equal\": true,\n        \"implicit\": true\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"commands/#dump","title":"dump","text":"<p>The <code>dump</code> command operates in the following way:</p> <ol> <li>Dumps the data from the source database.</li> <li>Validates the data for potential issues.</li> <li>Applies the defined transformations.</li> <li>Stores the transformed data in the specified storage location.</li> </ol> Supported flags<pre><code>Usage:\n  greenmask dump [flags]\n\nFlags:\n  -b, --blobs                           include large objects in dump\n  -c, --clean                           clean (drop) database objects before recreating\n  -Z, --compress int                    compression level for compressed formats (default -1)\n  -C, --create                          include commands to create database in dump\n  -a, --data-only                       dump only the data, not the schema\n  -d, --dbname string                   database to dump (default \"postgres\")\n      --disable-dollar-quoting          disable dollar quoting, use SQL standard quoting\n      --disable-triggers                disable triggers during data-only restore\n      --enable-row-security             enable row security (dump only content user has access to)\n  -E, --encoding string                 dump the data in encoding ENCODING\n  -N, --exclude-schema strings          dump the specified schema(s) only\n  -T, --exclude-table strings           do NOT dump the specified table(s)\n      --exclude-table-data strings      do NOT dump data for the specified table(s)\n  -e, --extension strings               dump the specified extension(s) only\n      --extra-float-digits string       override default setting for extra_float_digits\n  -f, --file string                     output file or directory name\n  -h, --host string                     database server host or socket directory (default \"/var/run/postgres\")\n      --if-exists                       use IF EXISTS when dropping objects\n      --include-foreign-data strings    use IF EXISTS when dropping objects\n  -j, --jobs int                        use this many parallel jobs to dump (default 1)\n      --load-via-partition-root         load partitions via the root table\n      --lock-wait-timeout int           fail after waiting TIMEOUT for a table lock (default -1)\n  -B, --no-blobs                        exclude large objects in dump\n      --no-comments                     do not dump comments\n  -O, --no-owner string                 skip restoration of object ownership in plain-text format\n  -X, --no-privileges                   do not dump privileges (grant/revoke)\n      --no-publications                 do not dump publications\n      --no-security-labels              do not dump security label assignments\n      --no-subscriptions                do not dump subscriptions\n      --no-sync                         do not wait for changes to be written safely to dis\n      --no-synchronized-snapshots       do not use synchronized snapshots in parallel jobs\n      --no-tablespaces                  do not dump tablespace assignments\n      --no-toast-compression            do not dump TOAST compression methods\n      --no-unlogged-table-data          do not dump unlogged table data\n      --on-conflict-do-nothing          add ON CONFLICT DO NOTHING to INSERT commands\n  -p, --port int                        database server port number (default 5432)\n      --quote-all-identifiers           quote all identifiers, even if not key words\n  -n, --schema strings                  dump the specified schema(s) only\n  -s, --schema-only string              dump only the schema, no data\n      --section string                  dump named section (pre-data, data, or post-data)\n      --serializable-deferrable         wait until the dump can run without anomalies\n      --snapshot string                 use given snapshot for the dump\n      --strict-names                    require table and/or schema include patterns to match at least one entity each\n  -S, --superuser string                superuser user name to use in plain-text format\n  -t, --table strings                   dump the specified table(s) only\n      --test string                     connect as specified database user (default \"postgres\")\n      --use-set-session-authorization   use SET SESSION AUTHORIZATION commands instead of ALTER OWNER commands to set ownership\n  -U, --username string                 connect as specified database user (default \"postgres\")\n  -v, --verbose string                  verbose mode\n</code></pre>"},{"location":"commands/#list-dumps","title":"list-dumps","text":"<p>The <code>list-dumps</code> command provides a list of all dumps stored in the storage. The list includes the following attributes:</p> <ul> <li><code>ID</code> \u2014 the unique identifier of the dump, used for operations like <code>restore</code>, <code>delete</code>, and <code>show-dump</code></li> <li><code>DATE</code> \u2014 the date when the snapshot was created</li> <li><code>DATABASE</code> \u2014 the name of the database associated with the dump</li> <li><code>SIZE</code> \u2014 the original size of the dump</li> <li><code>COMPRESSED SIZE</code> \u2014 the size of the dump after compression</li> <li><code>DURATION</code> \u2014 the duration of the dump procedure</li> <li><code>TRANSFORMED</code> \u2014 indicates whether the dump has been transformed</li> <li><code>STATUS</code> \u2014 the status of the dump, which can be one of the following:<ul> <li><code>done</code> \u2014 the dump was completed successfully</li> <li><code>unknown</code> or <code>failed</code> \u2014 the dump might be in progress or failed. Failed dumps are not deleted automatically.</li> </ul> </li> </ul> <p>Example of <code>list-dumps</code> output: </p>"},{"location":"commands/#list-transformers","title":"list-transformers","text":"<p>The <code>list-transformers</code> command provides a list of all the allowed transformers, including both standard and advanced transformers. This list can be helpful for searching for an appropriate transformer for your data transformation needs.</p> <p>To show a list of available transformers, use the following command:</p> <pre><code>greenmask --config=config.yml list-transformers\n</code></pre> <p>Supported flags:</p> <ul> <li><code>--format</code> \u2014 allows to select the output format. There are two options available: <code>text</code> or <code>json</code>. The   default setting is <code>text</code>.</li> </ul> <p>Example of <code>list-transformers</code> output:</p> <p></p> <p>When using the <code>list-transformers</code> command, you receive a list of available transformers with essential information about each of them. Below are the key parameters for each transformer:</p> <ul> <li><code>NAME</code> \u2014 the name of the transformer</li> <li><code>DESCRIPTION</code> \u2014 a brief description of what the transformer does</li> <li><code>COLUMN PARAMETER NAME</code> \u2014 name of a column or columns affected by transformation</li> <li><code>SUPPORTED TYPES</code> \u2014 list the supported value types</li> </ul> <p>The JSON call <code>greenmask --config=config.yml list-transformers --format=json</code> has the same attributes:</p> JSON format output<pre><code>[\n  {\n    \"name\": \"Cmd\",\n    \"description\": \"Transform data via external program using stdin and stdout interaction\",\n    \"parameters\": [\n      {\n        \"name\": \"columns\",\n        \"supported_types\": [\n          \"any\"\n        ]\n      }\n    ]\n  },\n  {\n    \"name\": \"Dict\",\n    \"description\": \"Replace values matched by dictionary keys\",\n    \"parameters\": [\n      {\n        \"name\": \"column\",\n        \"supported_types\": [\n          \"any\"\n        ]\n      }\n    ]\n  }\n]\n</code></pre>"},{"location":"commands/#show-transformer","title":"show-transformer","text":"<p>This command prints out detailed information about a transformer by a provided name, including specific attributes to help you understand and configure the transformer effectively.</p> <p>To show detailed information about a transformer, use the following command:</p> <pre><code>greenmask --config=config.yml show-transformer TRANSFORMER_NAME\n</code></pre> <p>Supported flags:</p> <ul> <li><code>--format</code> \u2014 allows to select the output format. There are two options available: <code>text</code> or <code>json</code>. The   default setting is <code>text</code>.</li> </ul> <p>Example of <code>show-transformer</code> output:</p> <p></p> <p>When using the <code>show-transformer</code> command, you receive detailed information about the transformer and its parameters and their possible attributes. Below are the key parameters for each transformer:</p> <ul> <li><code>Name</code> \u2014 the name of the transformer</li> <li><code>Description</code> \u2014 a brief description of what the transformer does</li> <li> <p><code>Parameters</code> \u2014 a list of transformer parameters, each with its own set of attributes. Possible attributes include:</p> <ul> <li><code>description</code> \u2014 a brief description of the parameter's purpose</li> <li><code>required</code> \u2014 a flag indicating whether the parameter is required when configuring the transformer</li> <li><code>link_parameter</code> \u2014 specifies whether the value of the parameter will be encoded using a specific parameter type   encoder. For example, if a parameter named <code>column</code> is linked to another parameter <code>start</code>, the <code>start</code>   parameter's value will be encoded according to the <code>column</code> type when the transformer is initialized.</li> <li><code>cast_db_type</code> \u2014 indicates that the value should be encoded according to the database type. For example, when   dealing with the INTERVAL data type, you must provide the interval value in PostgreSQL format.</li> <li><code>default_value</code> \u2014 the default value assigned to the parameter if it's not provided during configuration.</li> <li><code>column_properties</code> \u2014 if a parameter represents the name of a column, it may contain additional properties,   including:<ul> <li><code>nullable</code> \u2014 indicates whether the transformer may produce NULL values, potentially violating the NOT NULL   constraint</li> <li><code>unique</code> \u2014 specifies whether the transformer guarantees unique values for each call. If set to <code>true</code>, it   means that the transformer cannot produce duplicate values, ensuring compliance with the UNIQUE constraint.</li> <li><code>affected</code> \u2014 indicates whether the column is affected during the transformation process. If not affected, the   column's value might still be required for transforming another column.</li> <li><code>allowed_types</code> \u2014 a list of data types that are compatible with this parameter</li> <li><code>skip_original_data</code> \u2014 specifies whether the original value of the column, before transformation, is relevant   for the transformation process</li> <li><code>skip_on_null</code> \u2014 indicates whether the transformer should skip the transformation when the input column value   is NULL. If the column value is NULL, interaction with the transformer is unnecessary.</li> </ul> </li> </ul> </li> </ul> <p>Warning</p> <p>The default value in JSON format is base64 encoded. This might be changed in later version of Greenmask.</p> JSON output example<pre><code>[\n  {\n    \"properties\": {\n      \"name\": \"NoiseFloat\",\n      \"description\": \"Make noise float for int\",\n      \"is_custom\": false\n    },\n    \"parameters\": [\n      {\n        \"name\": \"column\",\n        \"description\": \"column name\",\n        \"required\": true,\n        \"is_column\": true,\n        \"is_column_container\": false,\n        \"column_properties\": {\n          \"max_length\": -1,\n          \"affected\": true,\n          \"allowed_types\": [\n            \"float4\",\n            \"float8\",\n            \"numeric\"\n          ],\n          \"skip_on_null\": true\n        }\n      },\n      {\n        \"name\": \"ratio\",\n        \"description\": \"max random percentage for noise\",\n        \"required\": false,\n        \"is_column\": false,\n        \"is_column_container\": false,\n        \"default_value\": \"MC4x\"\n      },\n      {\n        \"name\": \"precision\",\n        \"description\": \"precision of noised float value (number of digits after coma)\",\n        \"required\": false,\n        \"is_column\": false,\n        \"is_column_container\": false,\n        \"default_value\": \"NA==\"\n      }\n    ]\n  }\n]\n</code></pre>"},{"location":"commands/#restore","title":"restore","text":"<p>To perform a dump restoration with the provided dump ID, use the following command:</p> <pre><code>greenmask --config=config.yml restore DUMP_ID\n</code></pre> <p>Alternatively, to restore the latest completed dump, use the following command:</p> <pre><code>greenmask --config=config.yml restore latest\n</code></pre> <p>Note that the <code>restore</code> command shares the same parameters and environment variables as <code>pg_restore</code>, allowing you to configure the restoration process as needed.</p> Supported flags<pre><code>Flags:\n  -c, --clean                           clean (drop) database objects before recreating\n  -C, --create                          create the target database\n  -a, --data-only                       restore only the data, no schema\n  -d, --dbname string                   connect to database name (default \"postgres\")\n      --disable-triggers                disable triggers during data-only restore\n      --enable-row-security             enable row security\n  -N, --exclude-schema strings          do not restore objects in this schema\n  -e, --exit-on-error                   exit on error, default is to continue\n  -f, --file string                     output file name (- for stdout)\n  -P, --function strings                restore named function\n  -h, --host string                     database server host or socket directory (default \"/var/run/postgres\")\n      --if-exists                       use IF EXISTS when dropping objects\n  -i, --index strings                   restore named index\n  -j, --jobs int                        use this many parallel jobs to restore (default 1)\n      --list-format string              use table of contents in format of text, json or yaml (default \"text\")\n      --no-comments                     do not restore comments\n      --no-data-for-failed-tables       do not restore data of tables that could not be created\n  -O, --no-owner string                 skip restoration of object ownership\n  -X, --no-privileges                   skip restoration of access privileges (grant/revoke)\n      --no-publications                 do not restore publications\n      --no-security-labels              do not restore security labels\n      --no-subscriptions                ddo not restore subscriptions\n      --no-table-access-method          do not restore table access methods\n      --no-tablespaces                  do not restore tablespace assignments\n  -p, --port int                        database server port number (default 5432)\n  -n, --schema strings                  restore only objects in this schema\n  -s, --schema-only string              restore only the schema, no data\n      --section string                  restore named section (pre-data, data, or post-data)\n  -1, --single-transaction              restore as a single transaction\n      --strict-names                    restore named section (pre-data, data, or post-data) match at least one entity each\n  -S, --superuser string                superuser user name to use for disabling triggers\n  -t, --table strings                   restore named relation (table, view, etc.)\n  -T, --trigger strings                 restore named trigger\n  -L, --use-list string                 use table of contents from this file for selecting/ordering output\n      --use-set-session-authorization   use SET SESSION AUTHORIZATION commands instead of ALTER OWNER commands to set ownership\n  -U, --username string                 connect as specified database user (default \"postgres\")\n  -v, --verbose string                  verbose mode\n</code></pre>"},{"location":"commands/#show-dump","title":"show-dump","text":"<p>This command provides details about all objects and data that can be restored, similar to the <code>pg_restore -l</code> command in PostgreSQL. It helps you inspect the contents of the dump before performing the actual restoration.</p> <p>Parameters:</p> <ul> <li><code>--format</code> \u2014 format of printing. Can be <code>text</code> or <code>json</code>.</li> </ul> <p>To display metadata information about a dump, use the following command:</p> <pre><code>greenmask --config=config.yml show-dump dumpID\n</code></pre> Text output example <pre><code>;\n; Archive created at 2023-10-30 12:52:38 UTC\n; dbname: demo\n; TOC Entries: 17\n; Compression: -1\n; Dump Version: 15.4\n; Format: DIRECTORY\n; Integer: 4 bytes\n; Offset: 8 bytes\n; Dumped from database version: 15.4\n; Dumped by pg_dump version: 15.4\n;\n;\n; Selected TOC Entries:\n;\n3444; 0 0 ENCODING - ENCODING\n3445; 0 0 STDSTRINGS - STDSTRINGS\n3446; 0 0 SEARCHPATH - SEARCHPATH\n3447; 1262 24970 DATABASE - demo postgres\n3448; 0 0 DATABASE PROPERTIES - demo postgres\n222; 1259 24999 TABLE bookings flights postgres\n223; 1259 25005 SEQUENCE bookings flights_flight_id_seq postgres\n3460; 0 0 SEQUENCE OWNED BY bookings flights_flight_id_seq postgres\n3281; 2604 25030 DEFAULT bookings flights flight_id postgres\n3462; 0 24999 TABLE DATA bookings flights postgres\n3289; 2606 25044 CONSTRAINT bookings flights flights_flight_no_scheduled_departure_key postgres\n3291; 2606 25046 CONSTRAINT bookings flights flights_pkey postgres\n3287; 1259 42848 INDEX bookings flights_aircraft_code_status_idx postgres\n3292; 1259 42847 INDEX bookings flights_status_aircraft_code_idx postgres\n3293; 2606 25058 FK CONSTRAINT bookings flights flights_aircraft_code_fkey postgres\n3294; 2606 25063 FK CONSTRAINT bookings flights flights_arrival_airport_fkey postgres\n3295; 2606 25068 FK CONSTRAINT bookings flights flights_departure_airport_fkey postgres\n</code></pre> JSON output example <p><pre><code>{\n  \"startedAt\": \"2023-10-29T20:50:19.948017+02:00\", // (1)\n  \"completedAt\": \"2023-10-29T20:50:22.19333+02:00\", // (2)\n  \"originalSize\": 4053842, // (3)\n  \"compressedSize\": 686557, // (4)\n  \"transformers\": [ // (5)\n    {\n      \"Schema\": \"bookings\", // (6)\n      \"Name\": \"flights\", // (7)\n      \"Query\": \"\", // (8)\n      \"Transformers\": [ // (9)\n        {\n          \"Name\": \"RandomDate\", // (10)\n          \"Params\": { // (11)\n            \"column\": \"c2NoZWR1bGVkX2RlcGFydHVyZQ==\",\n            \"max\": \"MjAyMy0wMS0wMiAwMDowMDowMC4wKzAz\",\n            \"min\": \"MjAyMy0wMS0wMSAwMDowMDowMC4wKzAz\"\n          }\n        }\n      ],\n      \"ColumnsTypeOverride\": null // (12)\n    }\n  ],\n  \"header\": { // (13)\n    \"creationDate\": \"2023-10-29T20:50:20+02:00\",\n    \"dbName\": \"demo\",\n    \"tocEntriesCount\": 15,\n    \"dumpVersion\": \"16.0 (Homebrew)\",\n    \"format\": \"TAR\",\n    \"integer\": 4,\n    \"offset\": 8,\n    \"dumpedFrom\": \"16.0 (Debian 16.0-1.pgdg120+1)\",\n    \"dumpedBy\": \"16.0 (Homebrew)\",\n    \"tocFileSize\": 8090,\n    \"compression\": 0\n  },\n  \"entries\": [ // (14)\n    {\n      \"dumpId\": 3416,\n      \"databaseOid\": 0,\n      \"objectOid\": 0,\n      \"objectType\": \"ENCODING\",\n      \"schema\": \"\",\n      \"name\": \"ENCODING\",\n      \"owner\": \"\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": null\n    },\n    {\n      \"dumpId\": 3417,\n      \"databaseOid\": 0,\n      \"objectOid\": 0,\n      \"objectType\": \"STDSTRINGS\",\n      \"schema\": \"\",\n      \"name\": \"STDSTRINGS\",\n      \"owner\": \"\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": null\n    },\n    {\n      \"dumpId\": 3418,\n      \"databaseOid\": 0,\n      \"objectOid\": 0,\n      \"objectType\": \"SEARCHPATH\",\n      \"schema\": \"\",\n      \"name\": \"SEARCHPATH\",\n      \"owner\": \"\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": null\n    },\n    {\n      \"dumpId\": 3419,\n      \"databaseOid\": 16384,\n      \"objectOid\": 1262,\n      \"objectType\": \"DATABASE\",\n      \"schema\": \"\",\n      \"name\": \"demo\",\n      \"owner\": \"postgres\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": null\n    },\n    {\n      \"dumpId\": 3420,\n      \"databaseOid\": 0,\n      \"objectOid\": 0,\n      \"objectType\": \"DATABASE PROPERTIES\",\n      \"schema\": \"\",\n      \"name\": \"demo\",\n      \"owner\": \"postgres\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": null\n    },\n    {\n      \"dumpId\": 222,\n      \"databaseOid\": 16414,\n      \"objectOid\": 1259,\n      \"objectType\": \"TABLE\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights\",\n      \"owner\": \"postgres\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": null\n    },\n    {\n      \"dumpId\": 223,\n      \"databaseOid\": 16420,\n      \"objectOid\": 1259,\n      \"objectType\": \"SEQUENCE\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights_flight_id_seq\",\n      \"owner\": \"postgres\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        222\n      ]\n    },\n    {\n      \"dumpId\": 3432,\n      \"databaseOid\": 0,\n      \"objectOid\": 0,\n      \"objectType\": \"SEQUENCE OWNED BY\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights_flight_id_seq\",\n      \"owner\": \"postgres\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        223\n      ]\n    },\n    {\n      \"dumpId\": 3254,\n      \"databaseOid\": 16445,\n      \"objectOid\": 2604,\n      \"objectType\": \"DEFAULT\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights flight_id\",\n      \"owner\": \"postgres\",\n      \"section\": \"PreData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        223,\n        222\n      ]\n    },\n    {\n      \"dumpId\": 3434,\n      \"databaseOid\": 16414,\n      \"objectOid\": 0,\n      \"objectType\": \"TABLE DATA\",\n      \"schema\": \"\\\"bookings\\\"\",\n      \"name\": \"\\\"flights\\\"\",\n      \"owner\": \"\\\"postgres\\\"\",\n      \"section\": \"Data\",\n      \"originalSize\": 4045752,\n      \"compressedSize\": 678467,\n      \"fileName\": \"3434.dat.gz\",\n      \"dependencies\": []\n    },\n    {\n      \"dumpId\": 3261,\n      \"databaseOid\": 16461,\n      \"objectOid\": 2606,\n      \"objectType\": \"CONSTRAINT\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights flights_flight_no_scheduled_departure_key\",\n      \"owner\": \"postgres\",\n      \"section\": \"PostData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        222,\n        222\n      ]\n    },\n    {\n      \"dumpId\": 3263,\n      \"databaseOid\": 16463,\n      \"objectOid\": 2606,\n      \"objectType\": \"CONSTRAINT\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights flights_pkey\",\n      \"owner\": \"postgres\",\n      \"section\": \"PostData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        222\n      ]\n    },\n    {\n      \"dumpId\": 3264,\n      \"databaseOid\": 16477,\n      \"objectOid\": 2606,\n      \"objectType\": \"FK CONSTRAINT\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights flights_aircraft_code_fkey\",\n      \"owner\": \"postgres\",\n      \"section\": \"PostData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        222\n      ]\n    },\n    {\n      \"dumpId\": 3265,\n      \"databaseOid\": 16482,\n      \"objectOid\": 2606,\n      \"objectType\": \"FK CONSTRAINT\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights flights_arrival_airport_fkey\",\n      \"owner\": \"postgres\",\n      \"section\": \"PostData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        222\n      ]\n    },\n    {\n      \"dumpId\": 3266,\n      \"databaseOid\": 16487,\n      \"objectOid\": 2606,\n      \"objectType\": \"FK CONSTRAINT\",\n      \"schema\": \"bookings\",\n      \"name\": \"flights flights_departure_airport_fkey\",\n      \"owner\": \"postgres\",\n      \"section\": \"PostData\",\n      \"originalSize\": 0,\n      \"compressedSize\": 0,\n      \"fileName\": \"\",\n      \"dependencies\": [\n        222\n      ]\n    }\n  ]\n}\n</code></pre></p> <ol> <li>The date when the backup has been initiated, also indicating the snapshot date.</li> <li>The date when the backup process was successfully completed.</li> <li>The original size of the backup in bytes.</li> <li>The size of the backup after compression in bytes.</li> <li>A list of tables that underwent transformation during the backup.</li> <li>The schema name of the table.</li> <li>The name of the table.</li> <li>Custom query override, if applicable.</li> <li>A list of transformers that were applied during the backup.</li> <li>The name of the transformer.</li> <li>The parameters provided for the transformer.</li> <li>A mapping of overridden column types.</li> <li>The header information in the table of contents file. This provides the same details as the <code>--format=text</code> output in the previous snippet.</li> <li>The list of restoration entries. This offers the same information as the <code>--format=text</code> output in the previous snippet.</li> </ol> <p>Note</p> <p>The <code>json</code> format provides more detailed information compared to the <code>text</code> format. The <code>text</code> format is primarily used for backward compatibility and for generating a restoration list that can be used with <code>pg_restore -L listfile</code>. On the other hand, the <code>json</code> format provides comprehensive metadata about the dump, including information about the applied transformers and their parameters. The <code>json</code> format is especially useful for detailed dump introspection.</p>"},{"location":"configuration/","title":"Configuration","text":"<pre><code># Configuration\n</code></pre> <p>The configuration is organized into six sections:</p> <ul> <li><code>common</code> \u2014 settings that can be used for both the <code>dump</code> and <code>restore</code> commands</li> <li><code>log</code> \u2014 settings for the logging subsystem</li> <li><code>storage</code> \u2014 settings for the storage locations where dumps are stored</li> <li><code>dump</code> \u2014 settings for the <code>dump</code> command. This section includes <code>pg_dump</code> options and transformation parameters.</li> <li><code>restore</code> \u2014 settings for the <code>restore</code> command. It contains <code>pg_restore</code> options and additional restoration   scripts.</li> <li><code>custom_transformers</code> \u2014 definitions of the custom transformers that interact through <code>stdin</code> and <code>stdout</code>. Once a custom transformer is configured, it becomes accessible via the <code>greenmask list-transformers</code> command.</li> </ul>"},{"location":"configuration/#common-section","title":"<code>common</code> section","text":"<p>In the <code>common</code> section of the configuration, you can specify the following settings:</p> <ul> <li><code>pg_bin_path</code> \u2014 path to the PostgreSQL binaries. Note that the PostgreSQL server version must match the provided binaries.</li> <li><code>tmp_dir</code> \u2014 temporary directory for storing the table of contents files. Default value is <code>/tmp</code></li> </ul> <p>Note</p> <p>Greenmask exclusively manages data dumping and data restoration processes, delegating schema dumping to the <code>pg_dump</code>utility and schema restoration to the <code>pg_restore</code> utility. Both <code>pg_dump</code> and <code>pg_restore</code> rely on a <code>toc.dat</code> file located in a specific directory, which contains metadata and object definitions. Therefore, the <code>tmp_dir</code> parameter is essential for storing the <code>toc.dat</code> file during the dumping or restoration procedure. It is important to note that all artifacts in this directory will be automatically deleted once the Greenmask command is completed.</p>"},{"location":"configuration/#log-section","title":"<code>log</code> section","text":"<p>In the <code>log</code> section of the configuration, you can specify the following settings:</p> <ul> <li><code>level</code> \u2014 specifies the level of logging, which can be one of the following: <code>debug</code>, <code>info</code>, or <code>error</code>. The default level is <code>info</code>.</li> <li><code>format</code> \u2014 defines the logging format, which can be either <code>json</code> or <code>text</code>. The default format is <code>text</code>.</li> </ul>"},{"location":"configuration/#storage-section","title":"<code>storage</code> section","text":"<p>In the <code>storage</code> section, you can configure the storage driver for storing the dumped data. Currently, two storage <code>type</code> options are supported: <code>directory</code> and <code>s3</code>.</p> <code>directory</code> option<code>s3</code> option <p>The directory storage option refers to a filesystem directory where the dump data will be stored.</p> <p>Parameters include <code>path</code> which specifies the path to the directory in the filesystem where the dumps will be stored.</p> directory storage config example<pre><code>storage:\n  type: \"directory\"\n  directory:\n    path: \"/home/user_name/storage_dir\" # (1)\n</code></pre> <p>By choosing the <code>s3</code> storage option, you can store dump data in an S3-like remote storage service, such as Amazon S3 or Azure Blob Storage. Here are the parameters you can configure for S3 storage:</p> <ul> <li><code>endpoint</code> \u2014 overrides the default AWS endpoint to a custom one for making requests</li> <li><code>bucket</code> \u2014 the name of the bucket where the dump data will be stored</li> <li><code>prefix</code> \u2014 a prefix for objects in the bucket, specified in path format</li> <li><code>region</code> \u2014 the S3 service region</li> <li><code>storage_class</code> \u2014 the storage class for performing object requests</li> <li><code>no_verify_ssl</code> \u2014 disable SSL certificate verification</li> <li><code>access_key_id</code> \u2014 access key for authentication</li> <li><code>secret_access_key</code> \u2014 secret access key for authentication</li> <li><code>session_token</code> \u2014 session token for authentication</li> <li><code>role_arn</code> \u2014 Amazon resource name for role-based authentication</li> <li><code>session_name</code> \u2014 role session name to uniquely identify a session</li> <li><code>max_retries</code> \u2014 the number of retries on request failures</li> <li><code>cert_file</code> \u2014 the path to the SSL certificate for making requests</li> <li><code>max_part_size</code> \u2014 the maximum part length for one request</li> <li><code>concurrency</code> \u2014 the number of goroutines to use in parallel for each upload call when sending parts</li> <li><code>use_list_objects_v1</code> \u2014 use the old v1 <code>ListObjects</code> request instead of v2 one</li> <li><code>force_path_style</code> \u2014 force the request to use path-style addressing (e. g., <code>http://s3.amazonaws.com/BUCKET/KEY</code>) instead of virtual hosted bucket addressing (e. g., <code>http://BUCKET.s3.amazonaws.com/KEY</code>)</li> <li><code>use_accelerate</code> \u2014 enable S3 Accelerate feature</li> </ul> s3 storage config example for Minio running in Docker<pre><code>storage:  \n  type: \"s3\"\n  s3:\n    endpoint: \"http://localhost:9000\"\n    bucket: \"testbucket\"\n    region: \"us-east-1\"\n    access_key_id: \"Q3AM3UQ867SPQQA43P2F\"\n    secret_access_key: \"zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\"\n</code></pre>"},{"location":"configuration/#dump-section","title":"<code>dump</code> section","text":"<p>In the <code>dump</code> section of the configuration, you configure the <code>greenmask dump</code> command. It includes the following parameters:</p> <ul> <li><code>pg_dump_options</code> \u2014 a map of <code>pg_dump</code> options to configure the behavior of the command itself. You can refer to the list of supported <code>pg_dump</code> options in the Greenmask dump command documentation.</li> <li> <p><code>transformation</code> \u2014 this section contains configuration for applying transformations to table columns during the dump operation. It includes the following sub-parameters:</p> <ul> <li><code>schema</code> \u2014 the schema name of the table</li> <li><code>name</code> \u2014 the name of the table</li> <li> <p><code>query</code> \u2014 an optional parameter for specifying a custom query to be used in the COPY command. By default, the entire table is dumped, but you can use this parameter to set a custom query.</p> <p>Warning</p> <p>Be cautious when using the <code>query</code> parameter, as it may lead to constraint violation errors during restoration, and Greenmask currently cannot handle query validation.</p> </li> <li> <p><code>columns_type_override</code> \u2014 allows you to override the column types explicitly. You can associate a column with another type that is supported by your transformer. This is useful when the transformer works strictly with specific types of columns. For example, if a column named <code>post_code</code> is of the TEXT type, but the <code>RandomInt</code> transformer works only with INT family types, you can override it as shown in the example provided.   column type overridden example<pre><code>  columns_type_override:\n    post_code: \"int4\"  # (1)\n</code></pre></p> <ol> <li>Change the data type of the post_code column to <code>INT4</code> (<code>INTEGER</code>)</li> </ol> </li> <li> <p><code>apply_for_inherited</code> \u2014 an optional parameter to apply the same transformation to all partitions if the table is partitioned. This can save you from defining the transformation for each partition manually.</p> <p>Warning</p> <p>It is recommended to use the <code>--load-via-partition-root</code> parameter when dealing with partitioned tables, as the partition key value might change.</p> </li> <li> <p><code>transformers</code> \u2014 a list of transformers to apply to the table, along with their parameters. Each transformation item includes the following sub-parameters:</p> <ul> <li><code>name</code> \u2014 the name of the transformer</li> <li><code>params</code> \u2014 a map of the provided transformer parameters</li> </ul> transformers config example<pre><code>   transformers:\n    - name: \"RandomDate\"\n      params:\n        min: \"2023-01-01 00:00:00.0+03\"\n        max: \"2023-01-02 00:00:00.0+03\"\n        column: \"scheduled_departure\"\n\n    - name: \"NoiseDate\"\n      params:\n        ratio: \"01:00:00\"\n        column: \"scheduled_arrival\"\n</code></pre> </li> </ul> </li> </ul> <p>Here is an example configuration for the <code>dump</code> section:</p> <p>dump section config example<pre><code>dump:\n  pg_dump_options:\n    dbname: \"host=/run/postgresql user=postgres dbname=demo\"\n    jobs: 10\n    exclude-schema: \"(\\\"teSt\\\"*|test*)\"\n    table: \"bookings.flights\"\n    load-via-partition-root: true\n\n  transformation:\n    - schema: \"bookings\"\n      name: \"flights\"\n      query: \"select * from bookings.flights3 limit 1000000\"\n      columns_type_override:\n        post_code: \"int4\" # (1)\n      transformers:\n        - name: \"RandomDate\"\n          params:\n            min: \"2023-01-01 00:00:00.0+03\"\n            max: \"2023-01-02 00:00:00.0+03\"\n            column: \"scheduled_departure\"\n\n        - name: \"NoiseDate\"\n          params:\n            ratio: \"01:00:00\"\n            column: \"scheduled_arrival\"\n\n        - name: \"RegexpReplace\"\n          params:\n            column: \"status\"\n            regexp: \"On Time\"\n            replace: \"Delayed\"\n\n        - name: \"RandomInt\" # (2)\n          params:\n            column: \"post_code\"\n            min: \"11\"\n            max: \"99\"\n\n    - schema: \"bookings\"\n      name: \"aircrafts_data\"\n      transformers:\n        - name: \"Json\"\n          params:\n            column: \"model\"\n            operations:\n              - operation: \"set\"\n                path: \"en\"\n                value: \"Boeing 777-300-2023\"\n              - operation: \"set\"\n                path: \"crewSize\"\n                value: 10\n\n        - name: \"NoiseInt\"\n          params:\n            ratio: 0.9\n            column: \"range\"\n</code></pre></p> <ol> <li>Override the <code>post_code</code> column type to <code>int4</code> (INTEGER). This is necessary because the <code>post_code</code> column    originally has a <code>TEXT</code> type, but it contains values that resemble integers. By explicitly overriding the type to <code>int4</code>, we ensure compatibility with transformers that work with integer types, such as <code>RandomInt</code>.</li> <li>After the type is overridden, we can apply a compatible transformer.</li> </ol>"},{"location":"configuration/#validate-section","title":"<code>validate</code> section","text":"<p>In the <code>validate</code> section of the configuration, you can specify parameters for the <code>greenmask validate</code> command. Here is an example of the validate section configuration:</p> <p>validate section config example<pre><code>validate:\n  tables: # (1)\n    - \"orders\"\n    - \"public.cart\"\n  data: true # (2)\n  diff: true # (3)\n  rows_limit: 10 # (4)\n  resolved_warnings: # (5)\n    - \"8d436fae67b2b82b36bd3afeb0c93f30\"\n  table_format: \"horizontal\" # (7)\n  format: \"text\" # (6)\n  schema: true # (8)\n  transformed_only: true # (9)\n  warnings: true # (10)\n</code></pre></p> <ol> <li>A list of tables to validate. If this list is not empty, the validation operation will only be performed for the specified tables. Tables can be written with or without the schema name (e. g., <code>\"public.cart\"</code> or <code>\"orders\"</code>).</li> <li>Specifies whether to perform data transformation for a limited set of rows. If set to <code>true</code>, data transformation will be performed, and the number of rows transformed will be limited to the value specified in the <code>rows_limit</code> parameter (default is <code>10</code>).</li> <li>Specifies whether to perform diff operations for the transformed data. If set to <code>true</code>, the validation process will find the differences between the original and transformed data. See more details in the validate command documentation.</li> <li>Limits the number of rows to be transformed during validation. The default limit is <code>10</code> rows, but you can change it by modifying this parameter.</li> <li>A hash list of resolved warnings. These warnings have been addressed and resolved in a previous validation run.</li> <li>Specifies the format of the transformation output. Possible values are <code>[horizontal|vertical]</code>. The default format is <code>horizontal</code>. You can choose the format that suits your needs. See more details in the validate command documentation.</li> <li>The output format (json or text)</li> <li>Specifies whether to validate the schema current schema with the previous and print the differences if any.</li> <li>If set to <code>true</code>, transformation output will be only with the transformed columns and primary keys</li> <li>If set to then all the warnings be printed</li> </ol>"},{"location":"configuration/#restore-section","title":"<code>restore</code> section","text":"<p>In the <code>restore</code> section of the configuration, you can specify parameters for the <code>greenmask restore</code> command. It contains <code>pg_restore</code> settings and custom script execution settings. Below you can find the available parameters:</p> <ul> <li><code>pg_restore_options</code> \u2014 a map of <code>pg_restore</code> options that are used to configure the behavior of   the <code>pg_restore</code> utility during the restoration process. You can refer to the list of supported <code>pg_restore</code> options in the Greenmask restore command documentation.</li> <li><code>scripts</code> \u2014 a map of custom scripts to be executed during different restoration stages. Each script is associated with a specific restoration stage and includes the following attributes:<ul> <li><code>[pre-data|data|post-data]</code> \u2014 the name of the restoration stage when the script should be executed; has the following parameters:<ul> <li><code>name</code> \u2014 the name of the script</li> <li><code>when</code> \u2014 specifies when to execute the script, which can be either <code>\"before\"</code> or <code>\"after\"</code> the   specified restoration stage</li> <li><code>query</code> \u2014 an SQL query string to be executed</li> <li><code>query_file</code> \u2014 the path to an SQL query file to be executed</li> <li><code>command</code> \u2014 a command with parameters to be executed. It is provided as a list, where the first item is the command name.</li> </ul> </li> </ul> </li> </ul> <p>As mentioned in the architecture, a backup contains three sections: pre-data, data, and post-data. The custom script execution allows you to customize and control the restoration process by executing scripts or commands at specific stages. The available restoration stages and their corresponding execution conditions are as follows:</p> <ul> <li><code>pre-data</code> \u2014 scripts or commands can be executed before or after restoring the pre-data section</li> <li><code>data</code> \u2014 scripts or commands can be executed before or after restoring the data section</li> <li><code>post-data</code> \u2014 scripts or commands can be executed before or after restoring the post-data section</li> </ul> <p>Each stage can have a <code>\"when\"</code> condition with one of the following possible values:</p> <ul> <li><code>before</code> \u2014 execute the script or SQL command before the mentioned restoration stage</li> <li><code>after</code> \u2014 execute the script or SQL command after the mentioned restoration stage</li> </ul> <p>Below you can one of the possible versions for the <code>scripts</code> part of the <code>restore</code> section:</p> <p>scripts definition example<pre><code>scripts:\n  pre-data: # (1)\n    - name: \"pre-data before script [1] with query\"\n      when: \"before\"\n      query: \"create table script_test(stage text)\"\n    - name: \"pre-data before script [2]\"\n      when: \"before\"\n      query: \"insert into script_test values('pre-data before')\"\n    - name: \"pre-data after test script [1]\"\n      when: \"after\"\n      query: \"insert into script_test values('pre-data after')\"\n    - name: \"pre-data after script with query_file [1]\"\n      when: \"after\"\n      query_file: \"pre-data-after.sql\"\n  data: # (2)\n    - name: \"data before script with command [1]\"\n      when: \"before\"\n      command: # (4)\n        - \"data-after.sh\"\n        - \"param1\"\n        - \"param2\"\n    - name: \"data after script [1]\"\n      when: \"after\"\n      query_file: \"data-after.sql\"\n  post-data: # (3)\n    - name: \"post-data before script [1]\"\n      when: \"before\"\n      query: \"insert into script_test values('post-data before')\"\n    - name: \"post-data after script with query_file [1]\"\n      when: \"after\"\n      query_file: \"post-data-after.sql\"\n</code></pre></p> <ol> <li>List of pre-data stage scripts. This section contains scripts that are executed before or after the restoration of the pre-data section. The scripts include SQL queries and query files.</li> <li>List of data stage scripts. This section contains scripts that are executed before or after the restoration of the data section. The scripts include shell commands with parameters and SQL query files.</li> <li>List of post-data stage scripts. This section contains scripts that are executed before or after the restoration of the post-data section. The scripts include SQL queries and query files.</li> <li>Command in the first argument and the parameters in the rest of the list. When specifying a command to be executed in the scripts section, you provide the command name as the first item in a list, followed by any parameters or arguments for that command. The command and its parameters are provided as a list within the script configuration.</li> </ol>"},{"location":"configuration/#environment-variable-configuration","title":"Environment variable configuration","text":"<p>It's also possible to configure Greenmask through environment variables. </p> <p>Greenmask will automatically parse any environment variable that matches the configuration in the config file by substituting the dot (<code>.</code>) separator for an underscore (<code>_</code>) and uppercasing it. As an example, the config file below would apply the same configuration as defining the <code>LOG_LEVEL=debug</code> environment variable</p> config.yaml<pre><code>log:\n  level: debug\n</code></pre>"},{"location":"configuration/#postgres-connection-variables","title":"Postgres connection variables","text":"<p>Additionaly, there are some environment variables exposed by the <code>dump</code> and <code>restore</code> commands to facilitate the connection configuration with a Postgres database</p> <ul> <li><code>PGHOST</code> - host used to connect to the postgres database</li> <li><code>PGPORT</code> - port where postgres is exposed</li> <li><code>PGDATABASE</code> - name of the database to dump/restore</li> <li><code>PGUSER</code> - username used to connect to the postgres database</li> <li><code>PGPASSWORD</code> - password used to authenticate to the postgres database</li> </ul>"},{"location":"getting-started/","title":"Getting started","text":"<p>This guide will help you to quickly get familiar with Greenmask by setting up Greenmask Playground and trying it in action. Greenmask Playground is a Docker Compose environment that includes the following components:</p> <ul> <li>Original database \u2014 the source database you'll be working with.</li> <li>Empty database for restoration \u2014 an empty database where the restored data will be placed.</li> <li>MinIO storage \u2014 used for storage purposes.</li> <li>Greenmask Utility \u2014 Greenmask itself, ready for use.</li> </ul> <p>Warning</p> <p>To complete this guide, you must have Docker and docker-compose installed.</p>"},{"location":"getting-started/#setting-up-greenmask-playground","title":"Setting up Greenmask Playground","text":"<ol> <li> <p>Clone the <code>greenmask</code> repository and navigate to its directory by running the following commands:</p> <pre><code>git clone git@github.com:GreenmaskIO/greenmask.git &amp;&amp; cd greenmask\n</code></pre> </li> <li> <p>Once you have cloned the repository, start the environment by running Docker Compose:</p> <pre><code>docker-compose run greenmask\n</code></pre> </li> </ol> <p>Tip</p> <p>If you're experiencing problems with pulling images from Docker Hub, you can build the Greenmask image from source by running the following command:</p> <pre><code>docker-compose run greenmask-from-source\n</code></pre> <p>Now you have Greenmask Playground up and running with a shell prompt inside the container. All further operations will be carried out within this container's shell.</p>"},{"location":"getting-started/#commands","title":"Commands","text":"<p>Before proceeding to configure Greenmask, let us explore some of the available Greenmask commands:</p> <pre><code>greenmask\n  --log-format=[json|text] \\\n  --log-level=[debug|info|error] \\\n  --config=config.yml \\\n  [dump | list-dumps | delete | list-transformers | restore | show-dump | validate | completion]\n</code></pre> <p>Below you can find a description for each command:</p> <ul> <li> <p><code>dump</code> \u2014 performs a logical data dump, transforms the data, and stores it in the designated storage.</p> </li> <li> <p><code>list-dumps</code> \u2014 retrieves a list of all stored dumps within the chosen storage.</p> </li> <li> <p><code>delete</code> \u2014 removes a dump with a specific ID from the storage.</p> </li> <li> <p><code>list-transformers</code> \u2014 displays a list of approved transformers and their documentation.</p> </li> <li> <p><code>restore</code> \u2014 restores a dump either by specifying its ID or using the latest available dump to the target database.</p> </li> <li> <p><code>show-dump</code> \u2014 presents metadata information about a specific dump (equivalent to <code>pg_restore -l ./</code>).</p> </li> <li> <p><code>validate</code> \u2014 executes a validation process and generates a data diff for the transformation.</p> </li> <li> <p><code>completion</code> \u2014 generates the autocompletion script for the specified shell.</p> </li> </ul> <p>Note that you can customize the logging format and level using the provided options. Specifying a configuration file (<code>config.yml</code>) is mandatory to guide the tool's behavior.</p>"},{"location":"getting-started/#building-configyml","title":"Building config.yml","text":""},{"location":"getting-started/#the-sample-database","title":"The sample database","text":"<p>Greenmask Playground uses the Microsoft AdventureWorks sample databases, that have been ported to PostgreSQL and sourced from morenoh149/postgresDBSamples.</p> <p>Within Playground, you'll find two predefined databases:</p> <pre><code>    Name     |  Owner    \n-------------+----------\n original    | postgres\n transformed | postgres\n</code></pre> <p>where:</p> <ul> <li><code>original</code> \u2014 a database that contains the deployed AdventureWorks sample databases as-is.</li> <li><code>transformed</code> \u2014 an empty database for restoring transformed dumps.</li> </ul> <p>Within the Greenmask container, you'll have access to the following commands:</p> <ul> <li><code>greenmask</code> \u2014 launches the Greenmask obfuscation utility.</li> <li><code>psql_o</code> \u2014 connects to the <code>original</code> database using the psql utility.</li> <li><code>psql_t</code> \u2014 connects to the <code>transformed</code> database using the psql utility.</li> <li><code>cleanup</code> \u2014 drops and recreates the <code>transformed</code> database as an empty container.</li> </ul> <p>If you are using an external Integrated Development Environment (IDE), you can connect using the following URIs:</p> <ul> <li>Original database: <code>postgresql://postgres:example@localhost:54316/original</code></li> <li>Transformed database: <code>postgresql://postgres:example@localhost:54316/transformed</code></li> </ul>"},{"location":"getting-started/#creating-a-simple-configuration","title":"Creating a simple configuration","text":"<p>The Greenmask utility container is configured with a volume attached to the <code>./playground</code> directory located at the root of the repository. Within this directory, there is a pre-defined configuration file called <code>config.yml</code>. You have the flexibility to modify this configuration as needed, making adjustments or adding additional transformations.</p> <p>Any changes made to this configuration file will be accessible within the container, allowing you to tailor Greenmask's behavior to your specific requirements.</p> <p>To build a basic configuration for Greenmask, you can follow these steps:</p> <ol> <li> <p>Get a list of currently available transformers by running the following command:</p> <pre><code>greenmask --config config.yml list-transformers\n</code></pre> <p></p> </li> </ol> <p>When building your configuration, ensure that you fill in all the required attributes, including the following sections:</p> <ul> <li>common</li> <li>storage</li> <li>dump</li> <li>restore</li> </ul> <p>Below is an example of a minimal configuration in YAML format:</p> <pre><code>common:\n  pg_bin_path: \"/usr/lib/postgresql/16/bin\"\n  tmp_dir: \"/tmp\"\n\nstorage:\n  s3:\n    endpoint: \"http://playground-storage:9000\"\n    bucket: \"adventureworks\"\n    region: \"us-east-1\"\n    access_key_id: \"Q3AM3UQ867SPQQA43P2F\"\n    secret_access_key: \"zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\"\n\nvalidate:\n#  resolved_warnings:\n#    - \"aa808fb574a1359c6606e464833feceb\"\n\ndump:\n  pg_dump_options: # pg_dump option that will be provided\n    dbname: \"host=playground-db user=postgres password=example dbname=original\"\n    jobs: 10\n\n  transformation: # List of tables to transform\n    - schema: \"humanresources\" # Table schema\n      name: \"employee\"  # Table name\n      transformers: # List of transformers to apply\n        - name: \"NoiseDate\" # name of transformers\n          params: # Transformer parameters\n            ratio: \"10 year 9 mon 1 day\"\n            column: \"birthdate\" # Column parameter - this transformer affects scheduled_departure column\n\nrestore:\n  pg_restore_options: # pg_restore option (you can use the same options as pg_restore has)\n    jobs: 10\n    dbname: \"host=playground-db user=postgres password=example dbname=transformed\"\n</code></pre> <p>This example demonstrates the essential components of a Greenmask configuration file in YAML format. Please ensure that you customize it according to your specific needs.</p> <p>In the config above applied only one transformer on table <code>humanresources.employee</code> called <code>NoiseDate</code> with the next parameters:</p> <ul> <li>ratio - add noise to the value up to \"10 year 9 mon 1 day\" eather before or after. For he current value is   <code>1976-12-03</code> and the transformer generated the noise value randomly <code>1 year 3 mon</code> and decided to increase that value.   The result will be <code>1978-02-033</code></li> <li>column - there is a column name that is going to be affected called <code>birthdate</code></li> </ul>"},{"location":"getting-started/#run-validation-procedure","title":"Run validation procedure","text":"<p>You can utilize the following command to initiate a validation procedure:</p> <pre><code>greenmask --config config.yml validate \\\n  --data \\\n  --diff \\\n  --format=vertical \\\n  --rows-limit=2\n</code></pre> <p>The validation result will be displayed as follows:</p> <p></p> <p>There is one warning; let's investigate it:</p> <pre><code>{\n  \"hash\": \"aa808fb574a1359c6606e464833feceb\",\n  \"meta\": {\n    \"ColumnName\": \"birthdate\",\n    \"ConstraintDef\": \"CHECK (birthdate &gt;= '1930-01-01'::date AND birthdate &lt;= (now() - '18 years'::interval))\",\n    \"ConstraintName\": \"humanresources\",\n    \"ConstraintSchema\": \"humanresources\",\n    \"ConstraintType\": \"Check\",\n    \"ParameterName\": \"column\",\n    \"SchemaName\": \"humanresources\",\n    \"TableName\": \"employee\",\n    \"TransformerName\": \"NoiseDate\"\n  },\n  \"msg\": \"possible constraint violation: column has Check constraint\",\n  \"severity\": \"warning\"\n}\n</code></pre> <p>The validation warnings include the following details:</p> <ul> <li>hash - A unique identifier for each validation warning, which can be used to exclude the warning from future   checks   by adding it to the <code>validate.resolved_warnings</code> configuration.</li> <li>meta - Contains essential information that helps identify the location in the configuration or the potentially   violated constraint.</li> <li>msg - A comprehensive message that provides a detailed explanation of the warning's cause</li> <li>severity - Indicates the severity of the warning, which can be either \"warning\" or \"error.\" In the case of an   error, Greenmask will exit immediately with a non-zero exit code.</li> </ul> <p>The next step in the validation procedure is to compare the data before and after the transformation. This comparison is presented in a table format. Columns with a red background indicate that they have been affected by the transformation. The green values represent the original data before the transformation, while the red values depict the data after the transformation.</p> <p>To exclude a warning from future runs, you can uncomment the resolved_warning attribute in the configuration file.</p> <pre><code>validate:\n  resolved_warnings:\n    - \"aa808fb574a1359c6606e464833feceb\"\n</code></pre> <p>By adding the hash of a warning to the <code>validate.resolved_warnings</code> configuration in your <code>config.yml</code> file, you can effectively exclude that specific warning from being displayed in subsequent runs of the validation process using the command:</p> <pre><code>greenmask --config config.yml validate\n</code></pre>"},{"location":"getting-started/#dumping-procedure","title":"Dumping procedure","text":"<p>To perform the data dumping procedure, follow these steps:</p> <ol> <li> <p>Execute the following command to initiate the dump using your configured settings:     <pre><code>greenmask --config config.yml dump\n</code></pre></p> </li> <li> <p>Once the dumping process is complete, you will find the dump with an associated ID in the designated storage.    To list all available dumps, use the following command:     <pre><code>greenmask --config config.yml list-dumps\n</code></pre> </p> </li> <li> <p>If you wish to examine the data that is scheduled for restoration, you can use the show dump command.    Provide the <code>dumpId</code> in your call to access the details:</p> </li> </ol> <pre><code> greenmask --config config.yml show-dump 1702489882319\n</code></pre> <p>In the output below, you can observe the portion of objects that will be restored:</p> <pre><code> ;\n ; Archive created at 2023-12-13 17:51:22 UTC\n ;     dbname: original\n ;     TOC Entries: 986\n ;     Compression: 0\n ;     Dump Version: 16.1 (Ubuntu 16.1-1.pgdg22.04&amp;#43;1)\n ;     Format: DIRECTORY\n ;     Integer: 4 bytes\n ;     Offset: 8 bytes\n ;     Dumped from database version: 16.0 (Debian 16.0-1.pgdg120&amp;#43;1)\n ;     Dumped by pg_dump version: 16.1 (Ubuntu 16.1-1.pgdg22.04&amp;#43;1)\n ;\n ;\n ; Selected TOC Entries:\n ;\n 4666; 0 0 ENCODING - ENCODING\n 4667; 0 0 STDSTRINGS - STDSTRINGS\n 4668; 0 0 SEARCHPATH - SEARCHPATH\n 4669; 1262 16384 DATABASE - original postgres\n 14; 2615 18396 SCHEMA - hr postgres\n 9; 2615 16524 SCHEMA - humanresources postgres\n 4670; 0 0 COMMENT - SCHEMA humanresources postgres\n 13; 2615 18343 SCHEMA - pe postgres\n 8; 2615 16429 SCHEMA - person postgres\n 4671; 0 0 COMMENT - SCHEMA person postgres\n 15; 2615 18421 SCHEMA - pr postgres\n 10; 2615 16586 SCHEMA - production postgres\n 4672; 0 0 COMMENT - SCHEMA production postgres\n 16; 2615 18523 SCHEMA - pu postgres\n 11; 2615 17034 SCHEMA - purchasing postgres\n 4673; 0 0 COMMENT - SCHEMA purchasing postgres\n\n...\n...\n...\n4427; 2606 18157 FK CONSTRAINT sales shoppingcartitem FK_ShoppingCartItem_Product_ProductID postgres\n4428; 2606 18162 FK CONSTRAINT sales specialofferproduct FK_SpecialOfferProduct_Product_ProductID postgres\n4429; 2606 18167 FK CONSTRAINT sales specialofferproduct FK_SpecialOfferProduct_SpecialOffer_SpecialOfferID postgres\n4430; 2606 18182 FK CONSTRAINT sales store FK_Store_BusinessEntity_BusinessEntityID postgres\n4431; 2606 18187 FK CONSTRAINT sales store FK_Store_SalesPerson_SalesPersonID postgres\n</code></pre>"},{"location":"getting-started/#restoration-procedure","title":"Restoration Procedure","text":"<p>To restore data to the target database, you can use the following commands:</p> <ol> <li> <p>To restore data from a specific dump (identified by its dumpId), execute the following command:    <pre><code>   greenmask --config config.yml restore [dumpId]\n</code></pre>    Replace [dumpId] with the appropriate dump identifier.</p> </li> <li> <p>Alternatively, you can restore the latest available dump by using the reserved word latest like this:    <pre><code> greenmask --config config.yml restore latest\n</code></pre></p> </li> <li> <p>After the restoration process is complete, you can verify the restored data by running the following PostgreSQL    command:    <pre><code> psql_t -xc 'select * from humanresources.employee limit 2;'\n</code></pre>    This command will display the first two rows of the \"flights\" table in the target database, showing the restored    data.</p> <pre><code>-[ RECORD 1 ]----+-------------------------------------\nbusinessentityid | 1\nnationalidnumber | 295847284\nloginid          | adventure-works\\ken0\njobtitle         | Chief Executive Officer\nbirthdate        | 1968-12-18\nmaritalstatus    | S\ngender           | M\nhiredate         | 2009-01-14\nsalariedflag     | t\nvacationhours    | 99\nsickleavehours   | 69\ncurrentflag      | t\nrowguid          | f01251e5-96a3-448d-981e-0f99d789110d\nmodifieddate     | 2014-06-30 00:00:00\norganizationnode | /\n-[ RECORD 2 ]----+-------------------------------------\nbusinessentityid | 2\nnationalidnumber | 245797967\nloginid          | adventure-works\\terri0\njobtitle         | Vice President of Engineering\nbirthdate        | 1970-05-04\nmaritalstatus    | S\ngender           | F\nhiredate         | 2008-01-31\nsalariedflag     | t\nvacationhours    | 1\nsickleavehours   | 20\ncurrentflag      | t\nrowguid          | 45e8f437-670d-4409-93cb-f9424a40d6ee\nmodifieddate     | 2014-06-30 00:00:00\norganizationnode | /1/\n</code></pre> </li> </ol>"},{"location":"getting-started/#deleting-a-dump","title":"Deleting a Dump","text":"<p>To remove a specific dump from the storage, use the delete command with the appropriate dumpId. Here's how to do it:</p> <pre><code>greenmask --config config.yml delete 1702489882319\n</code></pre> <p>After executing this command, the specified dump will be deleted from the storage.</p> <p>To verify the changes, you can list the available dumps using the following command:</p> <p>The result</p> <pre><code>greenmask --config config.yml list-dumps\n</code></pre> <p>The list displayed dumps will not include the deleted dump with the previously provided dumpId.</p> <pre><code>+----+------+----------+------+-----------------+----------+-------------+--------+\n| ID | DATE | DATABASE | SIZE | COMPRESSED SIZE | DURATION | TRANSFORMED | STATUS |\n+----+------+----------+------+-----------------+----------+-------------+--------+\n+----+------+----------+------+-----------------+----------+-------------+--------+\n</code></pre>"},{"location":"getting-started/#conclusion","title":"Conclusion","text":"<p>This is a straightforward example of using Greenmask. If you wish to explore more advanced transformation cases and delve deeper into the documentation.</p> <p>Additionally, if you have any questions or require further assistance, don't hesitate to reach out via Discord, Telegram, or by emailing us at support@greenmask.io. Our team is here to help and provide guidance as needed.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Ensure that you have PostgreSQL utilities preinstalled, matching the major version   of your destination server.</p> </li> <li> <p>If you are building Greenmask from source, make sure you have the <code>make</code> utility installed.</p> </li> </ul>"},{"location":"installation/#from-github-binaries","title":"From GitHub binaries","text":"<p>The easiest way to install Greenmask is by using the latest release's binary. Follow these steps:</p> <ol> <li>Check the latest Greenmask release.</li> <li>From Assets, download the required binary.</li> <li>Execute the downloaded binary to start using Greenmask.</li> </ol>"},{"location":"installation/#additional-instructions-for-macos-users","title":"Additional instructions for macOS users","text":"<p>For those downloading <code>greenmask-macos-amd64</code> or <code>greenmask-macos-arm64</code>, additional steps are required to ensure proper execution.</p> <ol> <li> <p>In your terminal, move to the directory where the Greenmask binary is located.</p> </li> <li> <p>Change the file permissions to make it executable by using the following command:</p> <pre><code>chmod 777 greenmask-macos-[version]\n</code></pre> </li> <li> <p>Remove a quarantine attribute, which macOS may have applied, by using the following command:</p> <pre><code>xattr -d com.apple.quarantine greenmask-macos-[version]\n</code></pre> <p>Info</p> <p>In both commands above, replace <code>[version]</code> with <code>amd64</code> or <code>arm64</code> according to your download.</p> </li> </ol>"},{"location":"installation/#from-source","title":"From source","text":"<ol> <li> <p>Clone the Greenmask repository by using the following command:</p> <pre><code>git clone git@github.com:GreenmaskIO/greenmask.git\n</code></pre> </li> <li> <p>Once the repository is cloned, execute the following command to build Greenmask:</p> <pre><code>make build\n</code></pre> </li> </ol> <p>After completing the build process, you will find the binary named <code>greenmask</code> in the root directory of the repository. Execute the binary to start using Greenmask.</p>"},{"location":"playground/","title":"Greenmask Playground","text":"<p>Greenmask Playground is a sandbox environment in Docker with sample databases included to help you try Greenmask without any additional actions. It includes the following components:</p> <ul> <li>Original database \u2014 the source database you'll be working with.</li> <li>Empty database for restoration \u2014 an empty database where the restored data will be placed.</li> <li>MinIO storage \u2014 used for storage purposes.</li> <li>Greenmask Utility \u2014 Greenmask itself, ready for use.</li> </ul> <p>Warning</p> <p>To complete this guide, you must have Docker and docker-compose installed.</p>"},{"location":"playground/#setting-up-greenmask-playground","title":"Setting up Greenmask Playground","text":"<ol> <li> <p>Clone the <code>greenmask</code> repository and navigate to its directory by running the following commands:</p> <pre><code>git clone git@github.com:GreenmaskIO/greenmask.git &amp;&amp; cd greenmask\n</code></pre> </li> <li> <p>Once you have cloned the repository, start the environment by running Docker Compose:</p> <pre><code>docker-compose run greenmask\n</code></pre> </li> </ol> <p>Tip</p> <p>If you're experiencing problems with pulling images from Docker Hub, you can build the Greenmask image from source by running the following command:</p> <pre><code>docker-compose run greenmask-from-source\n</code></pre> <p>Now you have Greenmask Playground up and running with a shell prompt inside the container. All further operations will be carried out within this container's shell.</p>"},{"location":"playground/#commands","title":"Commands","text":"<p>Below you can see Greenmask commands:</p> <ul> <li> <p><code>dump</code> \u2014 performs a logical data dump, transforms the data, and stores it in the designated storage.</p> </li> <li> <p><code>list-dumps</code> \u2014 retrieves a list of all stored dumps within the chosen storage.</p> </li> <li> <p><code>delete</code> \u2014 removes a dump with a specific ID from the storage.</p> </li> <li> <p><code>list-transformers</code> \u2014 displays a list of approved transformers and their documentation.</p> </li> <li> <p><code>restore</code> \u2014 restores a dump either by specifying its ID or using the latest available dump to the target database.</p> </li> <li> <p><code>show-dump</code> \u2014 presents metadata information about a specific dump (equivalent to <code>pg_restore -l ./</code>).</p> </li> <li> <p><code>validate</code> \u2014 executes a validation process and generates a data diff for the transformation.</p> </li> <li> <p><code>completion</code> \u2014 generates the autocompletion script for the specified shell.</p> </li> </ul> <p>To learn more about them, see Commands.</p>"},{"location":"playground/#transformers","title":"Transformers","text":"<p>A configuration file is mandatory for Greenmask functioning. The pre-defined configuration file is stored at the repository root directory (<code>./playground/config.yml</code>). It also serves to define transformers which you can update to your liking in order to use Greenmask Playground more effectively and to get better understanding of the tool itself. To learn how to customize a configuration file, see Configuration</p> <p>The pre-defined configuration file uses the NoiseDate transformer as an example. To learn more about other transformers and how to use them, see Transformers.</p>"},{"location":"built_in_transformers/","title":"About transformers","text":"<p>Transformers in Greenmask are methods which are applied to obfuscate sensitive data. All Greenmask transformers are split into the following groups:</p> <ul> <li>Standard transformers \u2014 transformers that require only an input of parameters.</li> <li>Advanced transformers \u2014 transformers that can be modified according to user's needs with the help of custom functions.</li> <li>Custom transformers \u2014 coming soon...</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/","title":"Advanced transformers","text":"<p>Advanced transformers are modifiable obfuscation methods that users can adjust based on their needs by using custom functions.</p> <p>Below you can find an index of all advanced transformers currently available in Greenmask.</p> <ol> <li>Json \u2014 changes a JSON content by using <code>delete</code> and <code>set</code> operations.</li> <li>Template \u2014 executes a Go template of your choice and applies the result to a specified column.</li> <li>TemplateRecord \u2014 modifies records by using a Go template of your choice and applies the changes via the PostgreSQL driver.</li> </ol>"},{"location":"built_in_transformers/advanced_transformers/json/","title":"Json","text":"<p>Change a JSON document using <code>delete</code> and <code>set</code> operations. <code>NULL</code> values are kept.</p>"},{"location":"built_in_transformers/advanced_transformers/json/#parameters","title":"Parameters","text":"Name Properties Description Default Required Supported DB types column The name of the column to be affected Yes json, jsonb operations A list of operations that contains editing <code>delete</code> and <code>set</code> Yes - \u221f operation Specifies the operation type: <code>set</code> or <code>delete</code> Yes - \u221f path The path to an object to be modified. See path syntax below. Yes - \u221f value A value to be assigned to the provided path No - \u221f value_template A Golang template to be assigned to the provided path. See the list of template functions below. No - \u221f error_not_exist Throws an error if the key does not exist by the provided path. Disabled by default. <code>false</code> No -"},{"location":"built_in_transformers/advanced_transformers/json/#description","title":"Description","text":"<p>The <code>Json</code> transformer applies a sequence of changing operations (<code>set</code> and/or <code>delete</code>) to a JSON document. The value can be static or dynamic. For the <code>set</code> operation type, a static value is provided in the <code>value</code> parameter, while a dynamic value is provided in the <code>value_template</code> parameter, taking the data received after template execution as a result. Both the <code>value</code> and <code>value_template</code> parameters are mandatory for the <code>set</code> operation.</p>"},{"location":"built_in_transformers/advanced_transformers/json/#path-syntax","title":"Path syntax","text":"<p>The Json transformer is based on tidwall/sjson and supports the same path syntax. See their documentation for syntax rules.</p>"},{"location":"built_in_transformers/advanced_transformers/json/#template-functions","title":"Template functions","text":"Function Description Signature <code>.GetPath</code> Returns the current path to which the operation is being applied <code>.GetPath() (path string)</code> <code>.GetOriginalValue</code> Returns the original value to which the current operation path is pointing. If the value at the specified path does not exist, it returns  <code>nil</code>. <code>.GetOriginalValue() (value any)</code> <code>.OriginalValueExists</code> Returns a boolean value indicating whether the specified path exists or not. <code>.OriginalValueExists() (exists bool)</code> <code>.GetColumnValue</code> Returns an encoded into Golang type value for a specified column or throws an error. A value can be any of <code>int</code>, <code>float</code>, <code>time</code>, <code>string</code>, <code>bool</code>, or <code>slice</code> or <code>map</code>. <code>.GetColumnValue(name string) (value any, err error)</code> <code>.GetRawColumnValue</code> Returns a raw value for a specified column as a string or throws an error <code>.GetRawColumnValue(name string) (value string, err error)</code> <code>.EncodeValueByColumn</code> Encodes a value of any type into its raw string representation using the specified column name. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValueByColumn(name string, value any) (res any, err error)</code> <code>.DecodeValueByColumn</code> Decodes a value from its raw string representation to a Golang type using the specified column name. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByColumn(name string, value any) (res any, err error)</code> <code>.EncodeValueByType</code> Encodes a value of any type into its string representation using the specified type name. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValueByType(name string, value any) (res any, err error)</code> <code>.DecodeValueByType</code> Decodes a value from its raw string representation to a Golang type using the specified type name. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByType(name string, value any) (res any, err error)</code>"},{"location":"built_in_transformers/advanced_transformers/json/#example-changing-json-document","title":"Example: Changing JSON document","text":"Json transformer example<pre><code>- schema: \"bookings\"\n  name: \"aircrafts_data\"\n  transformers:\n    - name: \"Json\"\n      params:\n        column: \"model\"\n        operations:\n          - operation: \"set\"\n            path: \"en\"\n            value: \"Boeing 777-300-2023\"\n          - operation: \"set\"\n            path: \"seats\"\n            error_not_exist: True\n            value_template: \"{{ randomInt 100 400 }}\"\n          - operation: \"set\"\n            path: \"details.preperties.1\"\n            value: {\"name\": \"somename\", \"description\": null}\n          - operation: \"delete\"\n            path: \"values.:2\"\n</code></pre>"},{"location":"built_in_transformers/advanced_transformers/template/","title":"Template","text":"<p>Execute a Go template and automatically apply the result to a specified column.</p>"},{"location":"built_in_transformers/advanced_transformers/template/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes any template A Go template string Yes - validate Validates the template result using the PostgreSQL driver decoding procedure. Throws an error if a custom type does not have an encode-decoder implementation. false No -"},{"location":"built_in_transformers/advanced_transformers/template/#description","title":"Description","text":"<p>The <code>Template</code> transformer executes Go templates and automatically applies the template result to a specified column. Go template system is designed to be extensible, enabling developers to access data objects and incorporate custom functions programmatically. For more information, you can refer to the official Go Template documentation.</p> <p>With the <code>Template</code> transformer, you can implement complicated transformation logic using basic or custom template functions. Below you can get familiar with the basic template functions for the <code>Template</code> transformer. For more information about available custom template functions, see Custom functions.</p> <p>Warning</p> <p>Pay attention to the whitespaces in templates. Use dash-wrapped - brackets <code>{{- -}}</code> for trimming the spaces. For example, the value <code>\"2023-12-19\"</code> is not the same as <code>\" 2023-12-19  \"</code> and it may throw an error when restoring.</p>"},{"location":"built_in_transformers/advanced_transformers/template/#template-functions","title":"Template functions","text":"Function Description Signature <code>.GetColumnType</code> Returns a string with the column type. <code>.GetColumnType(name string) (typeName string, err error)</code> <code>.GetValue</code> Returns the column value for column assigned in the <code>column</code> parameter, encoded by the PostgreSQL driver into any type along with any associated error. Supported types include <code>int</code>, <code>float</code>, <code>time</code>, <code>string</code>, <code>bool</code>, as well as <code>slice</code> or <code>map</code> of any type. <code>.GetValue() (value any, err error)</code> <code>.GetRawValue</code> Returns a raw value as a string for column assigned in the <code>column</code> parameter. <code>.GetRawColumnValue(name string) (value string, err error)</code> <code>.GetColumnValue</code> Returns an encoded value for a specified column or throws an error. A value can be any of <code>int</code>, <code>float</code>, <code>time</code>, <code>string</code>, <code>bool</code>, or <code>slice</code> or <code>map</code>. <code>.GetColumnValue(name string) (value any, err error)</code> <code>.GetRawColumnValue</code> Returns a raw value for a specified column as a string or throws an error <code>.GetRawColumnValue(name string) (value string, err error)</code> <code>.EncodeValue</code> Encodes a value of any type into its string representation using the type assigned to the table column specified in the <code>column</code> parameter. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValue(value any) (res any, err error)</code> <code>.DecodeValue</code> Decodes a value from its raw string representation to a Golang type using the data type assigned to the table column specified in the <code>column</code> parameter. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByColumn(value any) (res any, err error)</code> <code>.EncodeValueByColumn</code> Encodes a value of any type into its raw string representation using the specified column name. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValueByColumn(name string, value any) (res any, err error)</code> <code>.DecodeValueByColumn</code> Decodes a value from its raw string representation to a Golang type using the specified column name. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByColumn(name string, value any) (res any, err error)</code> <code>.EncodeValueByType</code> Encodes a value of any type into its string representation using the specified type name. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValueByType(name string, value any) (res any, err error)</code> <code>.DecodeValueByType</code> Decodes a value from its raw string representation to a Golang type using the specified type name. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByType(name string, value any) (res any, err error)</code>"},{"location":"built_in_transformers/advanced_transformers/template/#example-update-the-firstname-column","title":"Example: Update the <code>firstname</code> column","text":"<p>Below you can see the table structure:</p> <p></p>"},{"location":"built_in_transformers/advanced_transformers/template/#change-rule","title":"Change rule","text":"<p>The goal is to modify the <code>firstname</code> column based on the following conditions:</p> <ul> <li>If the current value of the <code>firstname</code> column is equal to <code>Terri</code>, replace it with <code>Mary</code>.</li> <li>For all other cases, generate a random name and append <code>Jr</code>.</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/template/#using-a-template-function","title":"Using a template function","text":"<p>To generate random names, you can use the <code>fakerFirstName</code> template function, which is designed to create synthetic names.</p> Template transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformation:\n    - name: \"Template\"\n      params:\n        column: \"firstname\"\n        template: &gt;\n          {{- if eq .GetValue \"Terri\" -}}\n            Mary\n          {{- else -}}\n            {{- fakerFirstName -}} Jr\n          {{- end -}}\n\n        validate: true\n</code></pre> <p>Expected result:</p> Value = TerryValue != Terri column name original value transformed firstname Terri Mary column name original value transformed firstname Ken Jr Mike"},{"location":"built_in_transformers/advanced_transformers/template_record/","title":"TemplateRecord","text":"<p>Modify records using a Go template and apply changes by using the PostgreSQL driver functions. This transformer provides a way to implement custom transformation logic.</p>"},{"location":"built_in_transformers/advanced_transformers/template_record/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types columns A list of columns to be affected by the template. The list of columns will be checked for constraint violations. No any template A Go template string Yes - validate Validate the template result via PostgreSQL driver decoding procedure. Throws an error if a custom type does not have an encode-decoder implementation. false No -"},{"location":"built_in_transformers/advanced_transformers/template_record/#description","title":"Description","text":"<p><code>TemplateRecord</code> uses Go templates to change data. However, while the Template transformer operates with a single column and automatically applies results, the <code>TemplateRecord</code> transformer can make changes to a set of columns in the string, and using driver functions <code>.SetValue</code> or <code>.SetRawValue</code> is mandatory to do that.</p> <p>With the <code>TemplateRecord</code> transformer, you can implement complicated transformation logic using basic or custom template functions. Below you can get familiar with the basic template functions for the <code>TemplateRecord</code> transformer. For more information about available custom template functions, see Custom functions.</p>"},{"location":"built_in_transformers/advanced_transformers/template_record/#template-functions","title":"Template functions","text":"Function Description Signature <code>.GetColumnType</code> Returns a string with the column type. <code>.GetColumnType(name string) (typeName string, err error)</code> <code>.GetColumnValue</code> Returns an encoded value for a specified column or throws an error. A value can be any of <code>int</code>, <code>float</code>, <code>time</code>, <code>string</code>, <code>bool</code>, or <code>slice</code> or <code>map</code>. <code>.GetColumnValue(name string) (value any, err error)</code> <code>.GetRawColumnValue</code> Returns a raw value for a specified column as a string or throws an error <code>.GetRawColumnValue(name string) (value string, err error)</code> <code>.SetColumnValue</code> Sets a new value of a specific data type to the column. The value assigned must be compatible with the PostgreSQL data type of the column. For example, it is allowed to assign an <code>int</code> value to an <code>INTEGER</code> column, but you cannot assign a <code>float</code> value to a <code>timestamptz</code> column. <code>SetColumnValue(name string, v any) (bool, error)</code> <code>.SetRawColumnValue</code> Sets a new raw value for a column, inheriting the column's existing data type, without performing data type validation. This can lead to errors when restoring the dump if the assigned value is not compatible with the column type. To ensure compatibility, consider using the <code>.DecodeValueByColumn</code> function followed by <code>.SetColumnValue</code>, for example, <code>{{ \"13\" \\| .DecodeValueByColumn \"items_amount\" \\| .SetColumnValue \"items_amount\" }}</code>. <code>.SetRawColumnValue(name string, value any) (err error)</code> <code>.EncodeValueByColumn</code> Encodes a value of any type into its raw string representation using the specified column name. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValueByColumn(name string, value any) (res any, err error)</code> <code>.DecodeValueByColumn</code> Decodes a value from its raw string representation to a Golang type using the specified column name. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByColumn(name string, value any) (res any, err error)</code> <code>.EncodeValueByType</code> Encodes a value of any type into its string representation using the specified type name. Encoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.EncodeValueByType(name string, value any) (res any, err error)</code> <code>.DecodeValueByType</code> Decodes a value from its raw string representation to a Golang type using the specified type name. Decoding is performed through the PostgreSQL driver. Throws an error if types are incompatible. <code>.DecodeValueByType(name string, value any) (res any, err error)</code>"},{"location":"built_in_transformers/advanced_transformers/template_record/#example-generate-a-random-created_at-and-updated_at-dates","title":"Example: Generate a random <code>created_at</code> and <code>updated_at</code> dates","text":"<p>Below you can see the table structure:</p> <p></p> <p>The goal is to modify the <code>\"created_at\"</code> and <code>\"updated_at\"</code> columns based on the following rules:</p> <ul> <li>Do not change the value if the <code>created_at</code> is Null.</li> <li>If the <code>created_at</code> is not Null, generate the current time and use it as the minimum threshold for randomly   generating the <code>updated_at</code> value.</li> <li>Assign all generated values using the <code>.SetColumnValue</code> function.</li> </ul> Template transformer example<pre><code>- name: \"TemplateRecord\"\n  params:\n    columns:\n      - \"created_at\"\n      - \"updated_at\"\n    template: &gt;\n      {{ $val := .GetColumnValue \"created_at\" }}\n      {{ if isNotNull $val }}\n          {{ $createdAtValue := now }}\n          {{ $maxUpdatedDate := date_modify \"24h\" $createdAtValue }}\n          {{ $updatedAtValue := randomDate $createdAtValue $maxUpdatedDate }}\n          {{ .SetColumnValue \"created_at\" $createdAtValue }}\n          {{ .SetColumnValue \"updated_at\" $updatedAtValue }}\n      {{ end }}\n    validate: true\n</code></pre> <p>Expected result:</p> column name original value transformed created_at 2021-01-20 07:01:00.513325+00 2023-12-17 19:37:29.910054Z updated_at 2021-08-09 21:27:00.513325+00 2023-12-18 10:05:25.828498Z"},{"location":"built_in_transformers/advanced_transformers/custom_functions/","title":"Template custom functions","text":"<p>Within Greenmask, custom functions play a crucial role, providing a wide array of options for implementing diverse logic. Under the hood, the custom functions are based on the sprig Go's template functions. Greenmask enhances this capability by introducing additional functions and transformation functions. These extensions mirror the logic found in the standard transformers but offer you the flexibility to implement intricate and comprehensive logic tailored to your specific needs.</p> <p>Currently, you can use template custom functions for the advanced transformers:</p> <ul> <li>Json</li> <li>Template</li> <li>TemplateRecord</li> </ul> <p>Custom functions are arbitrarily divided into 2 groups:</p> <ul> <li>Core functions \u2014 custom functions that vary in purpose and include PostgreSQL driver, JSON output, testing, and transformation functions.</li> <li>Faker functions \u2014 custom function of a faker type which generate synthetic data.</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/","title":"Core functions","text":"<p>Below you can find custom core functions which are divided into categories based on the transformation purpose.</p>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#postgresql-driver-functions","title":"PostgreSQL driver functions","text":"Function Description <code>null</code> Returns the <code>NULL</code> value that can be used for the driver encoding-decoding operations <code>isNull</code> Returns <code>true</code> if the checked value is <code>NULL</code> <code>isNotNull</code> Returns <code>true</code> if the checked value is not <code>NULL</code> <code>sqlCoalesce</code> Works as a standard SQL <code>coalesce</code> function. It allows you to choose the first non-NULL argument from the list."},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#json-output-function","title":"JSON output function","text":"Function Description <code>jsonExists</code> Checks if the path value exists in JSON. Returns <code>true</code> if the path exists. <code>mustJsonGet</code> Gets the JSON attribute value by path and throws an error if the path does not exist <code>mustJsonGetRaw</code> Gets the JSON attribute raw value by path and throws an error if the path does not exist <code>jsonGet</code> Gets the JSON attribute value by path and returns nil if the path does not exist <code>jsonGetRaw</code> Gets the JSON attribute raw value by path and returns nil if the path does not exist <code>jsonSet</code> Sets the value for the JSON document by path <code>jsonSetRaw</code> Sets the raw value for the JSON document by path <code>jsonDelete</code> Deletes an attribute from the JSON document by path <code>jsonValidate</code> Validates the JSON document syntax and throws an error if there are any issues <code>jsonIsValid</code> Checks the JSON document for validity and returns <code>true</code> if it is valid <code>toJsonRawValue</code> Casts any type of value to the raw JSON value"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#testing-functions","title":"Testing functions","text":"Function Description <code>isInt</code> Checks if the value of an integer type <code>isFloat</code> Checks if the value of a float type <code>isNil</code> Checks if the value is nil <code>isString</code> Checks if the value of a string type <code>isMap</code> Checks if the value of a map type <code>isSlice</code> Checks if the value of a slice type <code>isBool</code> Checks if the value of a boolean type"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#transformation-and-generators","title":"Transformation and generators","text":""},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#masking","title":"masking","text":"<p>Replaces characters with asterisk <code>*</code> symbols depending on the provided masking rule. If the value is <code>NULL</code>, it is kept unchanged. This function is based on ggwhite/go-masker.</p> Masking rulesSignatureParametersReturn values Rule Description Example input Example output <code>default</code> Returns the sequence of <code>*</code> symbols of the same length <code>test1234</code> <code>********</code> <code>name</code> Masks the second and the third letters <code>ABCD</code> <code>A**D</code> <code>password</code> Always returns a sequence of <code>*</code> <code>address</code> Keeps first 6 letters, masks the rest <code>Larnaca, makarios st</code> <code>Larnac*************</code> <code>email</code> Keeps a domain and the first 3 letters, masks the rest <code>ggw.chang@gmail.com</code> <code>ggw****@gmail.com</code> <code>mobile</code> Masks 3 digits starting from the 4th digit <code>0987654321</code> <code>0987***321</code> <code>telephone</code> Removes <code>(</code>, <code>)</code>, <code></code>, <code>-</code> symbols, masks last 4 digits of a telephone number, and formats it to <code>(??)????-????</code> <code>0227993078</code> <code>(02)2799-****</code> <code>id</code> Masks last 4 digits of an ID <code>A123456789</code> <code>A12345****</code> <code>credit_card</code> Masks 6 digits starting from the 7th digit <code>1234567890123456</code> <code>123456******3456</code> <code>url</code> Masks the password part of the URL (if applicable) <code>http://admin:mysecretpassword@localhost:1234/uri</code> <code>http://admin:xxxxx@localhost:1234/uri</code> <p><code>masking(dataType string, value string) (res string, err error)</code></p> <ul> <li><code>dataType</code> \u2014 one of the masking rules (see previous tab)</li> <li><code>value</code> \u2014 the original string value</li> </ul> <ul> <li><code>res</code> \u2014 a masked string</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#truncatedate","title":"truncateDate","text":"<p>Truncates datetime up to the provided <code>part</code>.</p> SignatureParametersReturn values <p><code>truncateDate(part string, original time.Time) (res time.Time, err error)</code></p> <ul> <li><code>part</code> \u2014 the truncation part. Must be one of <code>nano</code>, <code>second</code>, <code>minute</code>, <code>hour</code>, <code>day</code>, <code>month</code>, or <code>year</code></li> <li><code>original</code> \u2014 the original datetime value</li> </ul> <ul> <li><code>res</code> \u2014 a truncated datetime</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#noisedatepginterval","title":"noiseDatePgInterval","text":"<p>Adds or subtracts a random duration in the provided <code>interval</code> to or from the original date value.</p> SignatureParametersReturn values <p><code>noiseDate(interval string, original time.Time) (res time.Time, err error)</code></p> <ul> <li><code>interval</code> \u2014 the maximum value of <code>ratio</code> that is added to the original value. The format is the same as in the PostgreSQL interval format.</li> <li><code>original</code> \u2014 the original time value</li> </ul> <ul> <li><code>res</code> \u2014 a noised date</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#noisefloat","title":"noiseFloat","text":"<p>Adds or subtracts a random fraction to or from the original float value. Multiplies the original float value by a provided random value that is not higher than the <code>ratio</code> parameter and adds it to the original value with the option to specify the precision via the <code>precision</code> parameter.</p> SignatureParametersReturn values <p><code>noiseFloat(ratio float, precision int, value float) (res float64, err error)</code></p> <ul> <li><code>ratio</code> \u2014 the maximum multiplier value in the interval (0:1). The value will be randomly generated up to <code>ratio</code>, multiplied by the original value, and the result will be added to the original value.</li> <li><code>precision</code> \u2014 the precision of the resulted value</li> <li><code>value</code> \u2014 the original value</li> </ul> <ul> <li><code>res</code> \u2014 a noised float value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#noiseint","title":"noiseInt","text":"<p>Adds or subtracts a random fraction to or from the original integer value. Multiplies the original integer value by a provided random value that is not higher than the <code>ratio</code> parameter and adds it to the original value.</p> SignatureParametersReturn values <p><code>noiseInt(ratio float, value float) (res int, err error)</code></p> <ul> <li><code>ratio</code> \u2014 the max multiplier value in the interval (0:1). The value will be generated randomly up to <code>ratio</code>, multiplied by the original value, and the result will be added to the original value.</li> <li><code>value</code> \u2014 the original value</li> </ul> <ul> <li><code>res</code> \u2014 a noised integer value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#randombool","title":"randomBool","text":"<p>Generates a random boolean value.</p>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#randomdate","title":"randomDate","text":"<p>Generates a random date within the provided interval.</p> SignatureParametersReturn values <p><code>randomDate(min time.Time, max time.Time) (res time.Time, err error)</code></p> <ul> <li><code>min</code> \u2014 the minimum random value threshold</li> <li><code>max</code> \u2014 the maximum random value threshold</li> </ul> <ul> <li><code>res</code> \u2014 a randomly generated date value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#randomfloat","title":"randomFloat","text":"<p>Generates a random float value within the provided interval.</p> SignatureParametersReturn values <p><code>randomFloat(min any, max any, precision int) (res float, err error)</code></p> <ul> <li><code>min</code> \u2014 the minimum random value threshold</li> <li><code>max</code> \u2014 the maximum random value threshold</li> <li><code>precision</code> \u2014 the precision of the resulted value</li> </ul> <ul> <li><code>res</code> \u2014 a randomly generated float value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#randomint","title":"randomInt","text":"<p>Generates a random integer value within the provided interval.</p> SignatureParametersReturn values <p><code>randomInt(min int, max int) (res int, err error)</code></p> <ul> <li><code>min</code> \u2014 the minimum random value threshold</li> <li><code>max</code> \u2014 the maximum random value threshold</li> </ul> <ul> <li><code>res</code> \u2014 a randomly generated int value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#randomstring","title":"randomString","text":"<p>Generates a random string using the provided characters within the specified length range.</p> SignatureParametersReturn values <p><code>randomString(minLength int, maxLength int, symbols string) (res string, err error)</code></p> <ul> <li><code>minLength</code> \u2014 the minimum string length</li> <li><code>maxLength</code> \u2014 the maximum string length</li> <li><code>symbols</code> \u2014 a string with a set of symbols which can be used. The default value is   <code>abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890</code></li> </ul> <ul> <li><code>res</code> \u2014 a randomly generated string value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/core_functions/#roundfloat","title":"roundFloat","text":"<p>Rounds a float value up to provided precision.</p> SignatureParametersReturn values <p><code>roundFloat(precision int, original float) (res float, err error)</code></p> <ul> <li><code>precision</code> \u2014 the precision of the value</li> <li><code>original</code> \u2014 the original float value</li> </ul> <ul> <li><code>res</code> \u2014 a rounded float value</li> <li><code>err</code> \u2014 an error if there is an issue</li> </ul>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/","title":"Faker functions","text":"<p>Greenmask uses go-faker/faker under the hood for generating of synthetic data.</p>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-address","title":"Faker functions: Address","text":"Function Description Signature <code>fakerRealAddress</code> Generates a random real-world address that includes: city, state, postal code, latitude, and longitude <code>fakerRealAddress() (res ReadAddress)</code> <code>fakerLatitude</code> Generates random fake latitude <code>fakerLatitude() (res float64)</code> <code>fakerLongitude</code> Generates random fake longitude <code>fakerLongitude() (res float64)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-datetime","title":"Faker functions: Datetime","text":"Function Description Signature <code>fakerUnixTime</code> Generates random Unix time in seconds <code>fakerLongitude() (res int64)</code> <code>fakerDate</code> Generates random date with the pattern of <code>YYYY-MM-DD</code> <code>fakerDate() (res string)</code> <code>fakerTimeString</code> Generates random time <code>fakerTimeString() (res string)</code> <code>fakerMonthName</code> Generates a random month <code>fakerMonthName() (res string)</code> <code>fakerYearString</code> Generates a random year <code>fakerYearString() (res string)</code> <code>fakerDayOfWeek</code> Generates a random day of a week <code>fakerDayOfWeek() (res string)</code> <code>fakerDayOfMonth</code> Generates a random day of a month <code>fakerDayOfMonth() (res string)</code> <code>fakerTimestamp</code> Generates a random timestamp with the pattern of <code>YYYY-MM-DD HH:MM:SS</code> <code>fakerTimestamp() (res string)</code> <code>fakerCentury</code> Generates a random century <code>fakerCentury() (res string)</code> <code>fakerTimezone</code> Generates a random timezone name <code>fakerTimezone() (res string)</code> <code>fakerTimeperiod</code> Generates a random time period with the patter of either <code>AM</code> or <code>PM</code> <code>fakerTimeperiod() (res string)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-internet","title":"Faker functions: Internet","text":"Function Description Signature <code>fakerEmail</code> Generates a random email <code>fakerEmail() (res string)</code> <code>fakerMacAddress</code> Generates a random MAC address <code>fakerMacAddress() (res string)</code> <code>fakerDomainName</code> Generates a random domain name <code>fakerDomainName() (res string)</code> <code>fakerURL</code> Generates a random URL with the pattern of <code>https://www.domainname.some/somepath</code> <code>fakerURL() (res string)</code> <code>fakerUsername</code> Generates a random username <code>fakerUsername() (res string)</code> <code>fakerIPv4</code> Generates a random IPv4 address <code>fakerIPv4() (res string)</code> <code>fakerIPv6</code> Generates a random IPv6 address <code>fakerIPv6() (res string)</code> <code>fakerPassword</code> Generates a random password <code>fakerPassword() (res string)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-words-and-sentences","title":"Faker functions: words and sentences","text":"Function Description Signature <code>fakerWord</code> Generates a random word <code>fakerWord() (res string)</code> <code>fakerSentence</code> Generates a random sentence <code>fakerSentence() (res string)</code> <code>fakerParagraph</code> Generates a random sequence of sentences as a paragraph <code>fakerParagraph() (res string)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-payment","title":"Faker functions: Payment","text":"Function Description Signature <code>fakerCCType</code> Generates a random credit card type, e.g. VISA, MasterCard, etc. <code>fakerCCType() (res string)</code> <code>fakerCCNumber</code> Generates a random credit card number <code>fakerCCNumber() (res string)</code> <code>fakerCurrency</code> Generates a random currency name <code>fakerCurrency() (res string)</code> <code>fakerAmountWithCurrency</code> Generates random amount preceded with random currency <code>fakerAmountWithCurrency() (res string)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-person","title":"Faker functions: Person","text":"Function Description Signature <code>fakerTitleMale</code> Generates a random male title from the predefined list <code>fakerTitleMale() (res string)</code> <code>fakerTitleFemale</code> Generates a random female title from the predefined list <code>fakerTitleFemale() (res string)</code> <code>fakerFirstName</code> Generates a random first name <code>fakerFirstName() (res string)</code> <code>fakerFirstNameMale</code> Generates a random male first name <code>fakerFirstNameMale() (res string)</code> <code>fakerFirstNameFemale</code> Generates a random female first name <code>fakerFirstNameFemale() (res string)</code> <code>fakerFirstLastName</code> Generates a random last name <code>fakerFirstLastName() (res string)</code> <code>fakerName</code> Generates a random full name preceded with a title <code>fakerName() (res string)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-phone","title":"Faker functions: Phone","text":"Function Description Signature <code>fakerPhoneNumber</code> Generates a random phone number <code>fakerPhoneNumber() (res string)</code> <code>fakerTollFreePhoneNumber</code> Generates a random phone number with the pattern of <code>(123) 456-7890</code> <code>fakerTollFreePhoneNumber() (res string)</code> <code>fakerE164PhoneNumber</code> Generates a random phone number with the pattern of <code>+12345678900</code> <code>fakerE164PhoneNumber() (res string)</code>"},{"location":"built_in_transformers/advanced_transformers/custom_functions/faker_function/#faker-functions-uuid","title":"Faker functions: UUID","text":"Function Description Signature <code>fakerUUIDHyphenated</code> Generates a random unique user ID separated by hyphens <code>fakerUUID() (res string)</code> <code>fakerUUIDDigit</code> Generates a random unique user ID in the HEX format <code>fakerUUIDDigit() (res string)</code>"},{"location":"built_in_transformers/standard_transformers/","title":"Standard transformers","text":"<p>Standard transformers are ready-to-use methods that require no customization and perform with just as little as parameters input. Below you can find an index of all standard transformers currently available in Greenmask.</p> <ol> <li>Cmd \u2014 transforms data via external program using <code>stdin</code> and <code>stdout</code> interaction.</li> <li>Dict \u2014 replaces values matched by dictionary keys.</li> <li>Hash \u2014 generates a hash of the text value.</li> <li>Masking \u2014 masks a value using one of the masking behaviors depending on your domain.</li> <li>NoiseDate \u2014 randomly adds or subtracts a duration within the provided ratio interval to the original date value.</li> <li>NoiseFloat \u2014 adds or subtracts a random fraction to the original float value.</li> <li>NoiseInt \u2014 adds or subtracts a random fraction to the original integer value.</li> <li>RandomBool \u2014 generates random boolean values.</li> <li>RandomChoice \u2014 replaces values randomly chosen from a provided list.</li> <li>RandomDate \u2014 generates a random date in a specified interval.</li> <li>RandomFloat \u2014 generates a random float within the provided interval.</li> <li>RandomInt \u2014 generates a random integer within the provided interval.</li> <li>RandomString \u2014 generates a random string using the provided characters within the specified length range.</li> <li>RandomUuid \u2014 generates a random unique user ID.</li> <li>RandomLatitude \u2014 generates a random latitude value.</li> <li>RandomLongitude \u2014 generates a random longitude value.</li> <li>RandomUnixTime \u2014 generates a random Unix timestamp.</li> <li>RandomDayOfWeek \u2014 generates a random day of the week.</li> <li>RandomDayOfMonth \u2014 generates a random day of the month.</li> <li>RandomMonthName \u2014 generates the name of a random month.</li> <li>RandomYearString \u2014 generates a random year as a string.</li> <li>RandomCentury \u2014 generates a random century.</li> <li>RandomTimezone \u2014 generates a random timezone.</li> <li>RandomEmail \u2014 generates a random email address.</li> <li>RandomUsername \u2014 generates a random username.</li> <li>RandomPassword \u2014 generates a random password.</li> <li>RandomMacAddress \u2014 generates a random MAC address.</li> <li>RandomDomainName \u2014 generates a random domain name.</li> <li>RandomURL \u2014 generates a random URL.</li> <li>RandomIPv4 \u2014 generates a random IPv4 address.</li> <li>RandomIPv6 \u2014 generates a random IPv6 address.</li> <li>RandomWord \u2014 generates a random word.</li> <li>RandomSentence \u2014 generates a random sentence.</li> <li>RandomParagraph \u2014 generates a random paragraph.</li> <li>RandomCCType \u2014 generates a random credit card type.</li> <li>RandomCCNumber \u2014 generates a random credit card number.</li> <li>RandomCurrency \u2014 generates a random currency code.</li> <li>RandomAmountWithCurrency \u2014 generates a random monetary amount with currency.</li> <li>RandomName \u2014 generates a full random name.</li> <li>RandomLastName \u2014 generates a random last name.</li> <li>RandomFirstName \u2014 generates a random first name.</li> <li>RandomFirstNameMale \u2014 generates a random male first name.</li> <li>RandomFirstNameFemale \u2014 generates a random female first name.</li> <li>RandomTitleMale \u2014 generates a random male title.</li> <li>RandomTitleFemale \u2014 generates a random female title.</li> <li>RandomPhoneNumber \u2014 generates a random phone number.</li> <li>RandomTollFreePhoneNumber \u2014 generates a random toll-free phone number.</li> <li>RandomE164PhoneNumber \u2014 generates a random phone number in E.164 format.</li> <li>RealAddress \u2014 generates a real address.</li> <li>RegexpReplace \u2014 replaces a string using a regular expression.</li> <li>Replace \u2014 replaces an original value by the provided one.</li> <li>SetNull \u2014 sets <code>NULL</code> value to the column.</li> </ol>"},{"location":"built_in_transformers/standard_transformers/cmd/","title":"Cmd","text":"<p>Transform data via external program using <code>stdin</code> and <code>stdout</code> interaction.</p>"},{"location":"built_in_transformers/standard_transformers/cmd/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types columns A list of column names to be affected. If empty, the entire tuple is used. Read about the structure further. Yes Any executable The path to the <code>executable</code> parameter file Yes - args A list of parameters for the executable No - driver The row driver with parameters that is used for interacting with cmd. See details below. <code>{\"name\": \"csv\"}</code> No - validate Performs a decoding operation using the PostgreSQL driver for data received from the command to ensure the data format is correct <code>false</code> No - timeout Timeout for sending and receiving data from the external command <code>2s</code> No - expected_exit_code The expected exit code on SIGTERM signal. If the exit code is unexpected, the transformation exits with an error. <code>0</code> No - skip_on_behaviour Skips transformation call if one of the provided columns has a <code>null</code> value (<code>any</code>) or each of the provided columns has <code>null</code> values (<code>all</code>). This option works together with the <code>skip_on_null_input</code> parameter on columns. Possible values: <code>all</code>, <code>any</code>. <code>all</code> No - <p>Warning</p> <p>The parameter <code>validate_output=true</code> may cause an error if the type does not have a PostgreSQL driver decoder  implementation. Most of the types, such as <code>int</code>, <code>float</code>, <code>text</code>, <code>varchar</code>, <code>date</code>, <code>timestamp</code>, etc., have  encoders and decoders, as well as inherited types like domain types based on them.</p>"},{"location":"built_in_transformers/standard_transformers/cmd/#description","title":"Description","text":"<p>The <code>Cmd</code> transformer allows you to send original data to an external program via <code>stdin</code> and receive transformed data from <code>stdout</code>. It supports various interaction formats such as <code>json</code>, <code>csv</code>, or plain <code>text</code> for one-column transformations. The interaction is performed line by line, so at the end of each sent data, a new line symbol <code>\\n</code> must be included.</p>"},{"location":"built_in_transformers/standard_transformers/cmd/#types-of-interaction-modes","title":"Types of interaction modes","text":""},{"location":"built_in_transformers/standard_transformers/cmd/#text","title":"text","text":"<p>Textual driver that is used only for one column transformation, thus you cannot provide here more than one column. The value encodes into string laterally. For example, <code>2023-01-03 01:00:00.0+03</code>.</p>"},{"location":"built_in_transformers/standard_transformers/cmd/#json","title":"json","text":"<p>JSON line driver. It has two formats that can be passed through <code>driver.json_data_format</code>: <code>[text|bytes]</code>. Use the <code>bytes</code> format for binary datatypes. Use the <code>text</code> format for non-binary datatypes and for those that can be represented as string literals. The default <code>json_data_format</code> is <code>text</code>.</p> Text format with indexesBytes format with indexes <pre><code>{\n  \"column1\": {\n    \"d\": \"some_value1\",\n    \"n\": false,\n  },\n  \"column2\": {\n    \"d\": \"some_value2\",\n    \"n\": false,\n  }\n}\n</code></pre> <pre><code>{\n  \"column1\": {\n    \"d\": \"aGVsbG8gd29ybHNeODcxMjE5MCUlJSUlJQ==\",\n    \"n\": false,\n  },\n  \"column2\": {\n    \"d\": \"aGVsbG8gd29ybHNeODcxMjE5MCUlJSUlJQ==\",\n    \"n\": false,\n  }\n}\n</code></pre> <p>where:</p> <ul> <li>Each line is a JSON line with a map of attribute numbers to their values</li> <li><code>d</code> \u2014 the raw data represented as base64 encoding for the bytes format or Unicode text for the text format. The base64   encoding is needed because data can be binary.</li> <li><code>n</code> \u2014 indicates if NULL is present</li> </ul>"},{"location":"built_in_transformers/standard_transformers/cmd/#csv","title":"csv","text":"<p>CSV driver (comma-separated). The number of attributes is the same as the number of table columns, but the columns that were not mentioned in the <code>columns</code> list are empty. The <code>NULL</code> value is represented as <code>\\N</code>. Each attribute is escaped by a quote (<code>\"</code>). For example, if the transformed table has attributes <code>id</code>, <code>title</code>, and <code>created_at</code>, and only <code>id</code> and <code>created_at</code> require transformation, then the CSV line will look as follows:</p> csv line example<pre><code>\"123\",\"\",\"2023-01-03 01:00:00.0+03\"\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/cmd/#column-object-attributes","title":"Column object attributes","text":"<ul> <li><code>name</code> \u2014 the name of the column. This value is required. Depending on the attributes that follows further, this column   may be used just as a value and is not affected in any way.</li> <li><code>not_affected</code> \u2014 indicates whether the column is affected in the transformation. This attribute is required for the   validation procedure when Greenmask is called with <code>greenmask dump --validate</code>. Setting <code>not_affected=true</code> can be   helpful when the command transformer transforms data depending on the value of another column. For example, if you   want to generate an <code>updated_at</code> column value depending on the <code>created_at</code> column value, you can set <code>created_at</code>   to <code>not_affected=true</code>. The default value is <code>false</code>.</li> <li><code>skip_original_data</code> \u2014 indicates whether the original data is required for the transformer. This attribute can be   helpful for decreasing the interaction time. One use case is when the command works as a generator and returns the   value without relying on the original data. The default value is <code>false</code>.</li> <li><code>skip_on_null_input</code> \u2014 specifies whether to skip transformation when the original value is <code>null</code>. This attribute   works in conjunction with the <code>skip_on_behaviour</code> parameter. For example, if you have two affected columns   with <code>skip_on_null_input=true</code> and one column is <code>null</code>, then, if <code>skip_on_behaviour=any</code>, the transformation will be   skipped, or, if <code>skip_on_behaviour=and</code>, the transformation will be performed. The default is <code>false</code>.</li> </ul>"},{"location":"built_in_transformers/standard_transformers/cmd/#example-apply-transformation-performed-by-external-command-in-text-format","title":"Example: Apply transformation performed by external command in TEXT format","text":"<p>In the following example, <code>jobtitle</code> columns is transformed via external command transformer.</p> External transformer in python example<pre><code>#!/usr/bin/env python3\nimport signal\nimport sys\n\nsignal.signal(signal.SIGTERM, lambda sig, frame: exit(0))\n\n\n# If we want to implement a simple generator, we need read the line from stdin and write any result to stdout\nfor _ in sys.stdin:\n    # Writing the result to stdout with new line and flushing the buffer\n    sys.stdout.write(\"New Job Title\")\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()\n</code></pre> Cmd transformer config example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"Cmd\"\n      params:\n        driver:\n          name: \"text\"\n        expected_exit_code: -1\n        skip_on_null_input: true\n        validate: true\n        skip_on_behaviour: \"any\"\n        timeout: 60s\n        executable: \"/var/lib/playground/test.py\"\n        columns:\n          - name: \"jobtitle\"\n            skip_original_data: true\n            skip_on_null_input: true \n</code></pre>"},{"location":"built_in_transformers/standard_transformers/cmd/#example-apply-transformation-performed-by-external-command-in-json-format","title":"Example: Apply transformation performed by external command in JSON format","text":"<p>In the following example, <code>jobtitle</code> and <code>loginid</code> columns are transformed via external command transformer.</p> External transformer in python example<pre><code>#!/usr/bin/env python3\nimport json\nimport signal\nimport sys\n\nsignal.signal(signal.SIGTERM, lambda sig, frame: exit(0))\n\nfor line in sys.stdin:\n    res = json.loads(line)\n    # Setting dummy values\n    res[\"jobtitle\"] = {\"d\": \"New Job Title\", \"n\": False}\n    res[\"loginid\"][\"d\"] = \"123\"\n\n    # Writing the result to stdout with new line and flushing the buffer\n    sys.stdout.write(json.dumps(res))\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()\n</code></pre> Cmd transformer config example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"Cmd\"\n      params:\n        driver:\n          name: \"json\" # (1)\n          json_data_format: \"text\" # (4)\n        expected_exit_code: -1\n        skip_on_null_input: true\n        validate: true\n        skip_on_behaviour: \"any\" # (2)\n        timeout: 60s\n        executable: \"/var/lib/playground/test.py\"\n        columns:\n          - name: \"jobtitle\"\n            skip_original_data: true\n            skip_on_null_input: true # (3)\n          - name: \"loginid\"\n            skip_original_data: false # (5)\n            skip_on_null_input: true # (3)\n</code></pre> <p>{ .annotate }</p> <ol> <li>Validate the received data via decode procedure using the PostgreSQL driver. Note that this may cause an error if the    type is not supported in the PostgreSQL driver.</li> <li>Skip transformation (keep the values) if one of the affected columns (<code>not_affected=false</code>) has a null value.</li> <li>If a column has a null value, then skip it. This works in conjunction with <code>skip_on_behaviour</code>. Since it has the    value any, if one of the columns (<code>jobtitle</code> or <code>loginid</code>) has a <code>null</code> value, then skip the    transformation call.</li> <li>The format of JSON can be either <code>text</code> or <code>bytes</code>. The default value is <code>text</code>.</li> <li>The <code>skip_original_data</code> attribute is set to <code>true</code> the date will not be transfered to the command. This column    will contain the empty original data</li> </ol>"},{"location":"built_in_transformers/standard_transformers/dict/","title":"Dict","text":"<p>Replace values matched by dictionary keys.</p>"},{"location":"built_in_transformers/standard_transformers/dict/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes any values Value replace mapping as in: <code>{\"string\": \"string\"}</code>. The string with value <code>\"\\N\"</code> is considered NULL. No - default Shown if no value has been matched with dict. The string with value <code>\"\\N\"</code> is considered NULL. By default is empty. No - fail_not_matched When no value is matched with the dict, fails the replacement process if set to <code>true</code>, or keeps the current value, if set to <code>false</code>. <code>true</code> No - validate Performs the encode-decode procedure using column type to ensure that values have correct type <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/dict/#description","title":"Description","text":"<p>The <code>Dict</code> transformer uses a user-provided key-value dictionary to replace values based on matches specified in the <code>values</code> parameter mapping. These provided values must align with the PostgreSQL type format. To validate the values format before application, you can utilize the <code>validate</code> parameter, triggering a decoding procedure via the PostgreSQL driver.</p> <p>If there are no matches by key, an error will be raised according to a default <code>fail_not_matched: true</code> parameter. You can change this behaviour by providing the <code>default</code> parameter, value from which will be shown in case of a missing match.</p> <p>In certain cases where the driver type does not support the validation operation, an error may occur. For setting or matching a NULL value, use a string with the <code>\\N</code> sequence.</p>"},{"location":"built_in_transformers/standard_transformers/dict/#example-replace-marital-status","title":"Example: Replace marital status","text":"<p>The following example replaces marital status from <code>S</code> to <code>M</code> or from <code>M</code> to <code>S</code> and raises an error if there is no match:</p> Dict transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"Dict\"\n      params:\n        column: \"maritalstatus\"\n        values:\n          \"S\": \"M\"\n          \"M\": \"S\"\n        validate: true\n        fail_not_matched: true\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/hash/","title":"Hash","text":"<p>Generate a hash of the text value using the <code>Scrypt</code> hash function under the hood. <code>NULL</code> values are kept.</p>"},{"location":"built_in_transformers/standard_transformers/hash/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar salt Hex encoded salt string. This value may be provided via environment variable <code>GREENMASK_GLOBAL_SALT</code> Yes text, varchar function Hash algorithm to obfuscate data. Can be any of <code>md5</code>, <code>sha1</code>, <code>sha256</code>, <code>sha512</code>, <code>sha3-224</code>, <code>sha3-254</code>, <code>sha3-384</code>, <code>sha3-512</code>. <code>sha1</code> No - max_length Indicates whether to truncate the hash tail and specifies at what length. Can be any integer number, where <code>0</code> means \"no truncation\". <code>0</code> No -"},{"location":"built_in_transformers/standard_transformers/hash/#example-generate-hash-from-job-title","title":"Example: Generate hash from job title","text":"<p>The following example generates a hash from the <code>jobtitle</code> into sha1 and truncates the results after the 10th character.</p> <p>We can set the salt via the environment variable <code>GREENMASK_GLOBAL_SALT</code>:</p> <pre><code>export GREENMASK_GLOBAL_SALT=\"12343567baaa\"\n</code></pre> Hash transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"Hash\"\n      params:\n        column: \"jobtitle\"\n        function: \"sha1\"\n        max_length: 10\n</code></pre> Expected result<pre><code>| column name | original value                   | transformed |\n|-------------|----------------------------------|-------------|\n| jobtitle    | Research and Development Manager | 3a456da5c5  |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/masking/","title":"Masking","text":"<p>Mask a value using one of the masking rules depending on your domain. <code>NULL</code> values are kept.</p>"},{"location":"built_in_transformers/standard_transformers/masking/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar type Data type of attribute (<code>default</code>, <code>password</code>, <code>name</code>, <code>addr</code>, <code>email</code>, <code>mobile</code>, <code>tel</code>, <code>id</code>, <code>credit</code>, <code>url</code>) <code>default</code> No -"},{"location":"built_in_transformers/standard_transformers/masking/#description","title":"Description","text":"<p>The <code>Masking</code> transformer replaces characters with asterisk <code>*</code> symbols depending on the provided data type. If the value is <code>NULL</code>, it is kept unchanged. It is based on ggwhite/go-masker and supports the following masking rules:</p> Type Description default Returns <code>*</code> symbols with the same length, e.g. input: <code>test1234</code> output: <code>********</code> name Masks the second letter the third letter in a word, e. g. input: <code>ABCD</code> output: <code>A**D</code> password Always returns <code>************</code> address Keeps first 6 letters, masks the rest, e. g. input: <code>Larnaca, makarios st</code> output: <code>Larnac*************</code> email Keeps a domain and the first 3 letters, masks the rest, e. g. input: <code>ggw.chang@gmail.com</code> output: <code>ggw****@gmail.com</code> mobile Masks 3 digits starting from the 4th digit, e. g. input: <code>0987654321</code> output: <code>0987***321</code> telephone Removes <code>(</code>, <code>)</code>, <code></code>, <code>-</code> chart, and masks last 4 digits of telephone number, then formats it to <code>(??)????-????</code>, e. g. input: <code>0227993078</code> output: <code>(02)2799-****</code> id Masks last 4 digits of ID number, e. g. input: <code>A123456789</code> output: <code>A12345****</code> credit_cart Masks 6 digits starting from the 7th digit, e. g. input <code>1234567890123456</code> output <code>123456******3456</code> url Masks the password part of the URL, if applicable, e. g. <code>http://admin:mysecretpassword@localhost:1234/uri</code> output: <code>http://admin:xxxxx@localhost:1234/uri</code>"},{"location":"built_in_transformers/standard_transformers/masking/#example-masking-employee-national-id-number","title":"Example: Masking employee national ID number","text":"<p>In the following example, the national ID number of an employee is masked.</p> Masking transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"Masking\"\n      params:\n        column: \"nationalidnumber\"\n        type: \"id\"\n</code></pre> Expected result<pre><code>| column name      | original value | transformed |\n|------------------|----------------|-------------|\n| nationalidnumber | 295847284      | 295847****  |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/noise_date/","title":"NoiseDate","text":"<p>Randomly add or subtract a duration within the provided <code>ratio</code> interval to the original date value.</p>"},{"location":"built_in_transformers/standard_transformers/noise_date/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes date, timestamp, timestamptz ratio The maximum random duration for noise. The value must be in PostgreSQL interval format, e. g. 1 year 2 mons 3 day \u2014 <code>04:05:06.07</code> Yes - truncate Truncate the date to the specified part (<code>nano</code>, <code>second</code>, <code>minute</code>, <code>hour</code>, <code>day</code>, <code>month</code>, <code>year</code>). The truncate operation is not applied by default. No -"},{"location":"built_in_transformers/standard_transformers/noise_date/#description","title":"Description","text":"<p>The <code>NoiseDate</code> transformer randomly generates duration within the specified <code>ratio</code> parameter and adds it to or subtracts it from the original date value. The <code>ratio</code> parameter must be written in the PostgreSQL interval format. You can also truncate the date up to a specified part by setting the <code>truncate</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/noise_date/#example-adding-noise-to-the-modified-date","title":"Example: Adding noise to the modified date","text":"<p>In the following example, the original <code>timestamp</code> value of <code>modifieddate</code> will be noised up to <code>1 year 2 months 3 days 4 hours 5 minutes 6 seconds and 7 milliseconds</code> with truncation up to the <code>nano</code> part.</p> NoiseDate transformer example<pre><code>- schema: \"humanresources\"\n  name: \"jobcandidate\"\n  transformers:\n    - name: \"NoiseDate\"\n      params:\n        column: \"modifieddate\"\n        ratio: \"1 year 2 mons 3 day 04:05:06.07\"\n        truncate: \"nano\"\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/noise_float/","title":"NoiseFloat","text":"<p>Add or subtract a random fraction to the original float value.</p>"},{"location":"built_in_transformers/standard_transformers/noise_float/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes float4 (real), float8 (double precision), numeric ratio The maximum random percentage for noise, from <code>0</code> to <code>1</code>, e. g. <code>0.1</code> means \"add noise up to 10%\" Yes - precision The precision of the noised float value (number of digits after the decimal point) <code>4</code> No -"},{"location":"built_in_transformers/standard_transformers/noise_float/#description","title":"Description","text":"<p>The <code>NoiseFloat</code> transformer multiplies the original float value by a provided random value that is not higher than the <code>ratio</code> parameter and adds it to or subtracts it from the original value. Additionally, you can specify the number of decimal digits by using the <code>precision</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/noise_float/#example-adding-noise-to-the-purchase-price","title":"Example: Adding noise to the purchase price","text":"<p>In this example, the original value of <code>standardprice</code> will be noised up to <code>50%</code> and rounded up to <code>2</code> decimals.</p> NoiseFloat transformer example<pre><code>- schema: \"purchasing\"\n  name: \"productvendor\"\n  transformers:\n    - name: \"NoiseFloat\"\n      params:\n        column: \"standardprice\"\n        ratio: 0.5\n        precision: 2\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/noise_int/","title":"NoiseInt","text":"<p>Add or subtract a random fraction to the original integer value.</p>"},{"location":"built_in_transformers/standard_transformers/noise_int/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes int2, int4, int8 ratio The maximum random percentage for noise, from <code>0</code> to <code>1</code> Yes -"},{"location":"built_in_transformers/standard_transformers/noise_int/#description","title":"Description","text":"<p>The <code>NoiseInt</code> transformer multiplies the original integer value by a provided random value that is not higher than the <code>ratio</code> parameter and adds it to or subtracts it from the original value.</p>"},{"location":"built_in_transformers/standard_transformers/noise_int/#example-noise-vacation-hours-of-an-employee","title":"Example: Noise vacation hours of an employee","text":"<p>In the following example, the original value of <code>vacationhours</code> will be noised up to 40%.</p> NoiseInt transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"NoiseInt\"\n      params:\n        column: \"vacationhours\"\n        ratio: 0.4\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_amount_with_currency/","title":"RandomAmountWithCurrency","text":"<p>The <code>RandomAmountWithCurrency</code> transformer is specifically designed to populate specified database columns with random financial amounts accompanied by currency codes. Ideal for applications requiring the simulation of financial transactions, this utility enhances the realism of financial datasets by introducing variability in amounts and currencies.</p>"},{"location":"built_in_transformers/standard_transformers/random_amount_with_currency/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_amount_with_currency/#description","title":"Description","text":"<p>This transformer automatically generates random financial amounts along with corresponding global currency codes (e. g., <code>250.00 USD</code>, <code>300.00 EUR</code>), injecting them into the designated database column. It provides a straightforward solution for populating financial records with varied and realistic data, suitable for testing payment systems, data anonymization, and simulation of economic models.</p>"},{"location":"built_in_transformers/standard_transformers/random_amount_with_currency/#example-populate-the-payments-table-with-random-amounts-and-currencies","title":"Example: Populate the <code>payments</code> table with random amounts and currencies","text":"<p>This example shows how to configure the <code>RandomAmountWithCurrency</code> transformer to populate the <code>payment_details</code> column in the <code>payments</code> table with random amounts and currencies. It is an effective approach to simulating a diverse range of payment transactions.</p> RandomAmountWithCurrency transformer example<pre><code>- schema: \"public\"\n  name: \"payments\"\n  transformers:\n    - name: \"RandomAmountWithCurrency\"\n      params:\n        column: \"payment_details\"\n        keep_null: false\n</code></pre> <p>In this setup, the <code>payment_details</code> column will be updated with random financial amounts and currency codes for each entry, replacing any existing non-NULL values. The <code>keep_null</code> parameter, when set to <code>true</code>, ensures that existing NULL values in the column remain unchanged, preserving the integrity of records without specified payment details.</p>"},{"location":"built_in_transformers/standard_transformers/random_bool/","title":"RandomBool","text":"<p>Generate random boolean values.</p>"},{"location":"built_in_transformers/standard_transformers/random_bool/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes bool keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/random_bool/#description","title":"Description","text":"<p>The <code>RandomBool</code> transformer generates a random boolean value. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_bool/#example-generate-a-random-boolean-for-a-column","title":"Example: Generate a random boolean for a column","text":"<p>In the following example, the <code>RandomBool</code> transformer generates a random boolean value for the <code>salariedflag</code> column.</p> RandomBool transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"RandomBool\"\n      params:\n        column: \"salariedflag\"\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_cc_number/","title":"RandomCCNumber","text":"<p>The <code>RandomCCNumber</code> transformer is specifically designed to populate specified database columns with random credit card numbers. This utility is crucial for applications that involve simulating financial data, testing payment systems, or anonymizing real credit card numbers in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_cc_number/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_cc_number/#description","title":"Description","text":"<p>By leveraging algorithms capable of generating plausible credit card numbers that adhere to standard credit card validation rules (such as the Luhn algorithm), the <code>RandomCCNumber</code> transformer injects random credit card numbers into the designated database column. This approach ensures the generation of credit card numbers that are realistic for testing and development purposes, without compromising real-world applicability and security.</p>"},{"location":"built_in_transformers/standard_transformers/random_cc_number/#example-populate-random-credit-card-numbers-for-the-payment_information-table","title":"Example: Populate random credit card numbers for the <code>payment_information</code> table","text":"<p>This example demonstrates configuring the <code>RandomCCNumber</code> transformer to populate the <code>cc_number</code> column in the <code>payment_information</code> table with random credit card numbers. It is an effective strategy for creating a realistic set of payment data for application testing or data anonymization.</p> RandomCCNumber transformer example<pre><code>- schema: \"public\"\n  name: \"payment_information\"\n  transformers:\n    - name: \"RandomCCNumber\"\n      params:\n        column: \"cc_number\"\n        keep_null: false\n</code></pre> <p>With this setup, the <code>cc_number</code> column will be updated with random credit card numbers for each entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, it will ensure that existing NULL values in the column are preserved, maintaining the integrity of records where credit card information is not applicable or available.</p>"},{"location":"built_in_transformers/standard_transformers/random_cc_type/","title":"RandomCCType","text":"<p>The <code>RandomCCType</code> transformer is designed to populate specified database columns with random credit card types. This tool is essential for applications that require the simulation of financial transaction data, testing payment processing systems, or anonymizing credit card type information in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_cc_type/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_cc_type/#description","title":"Description","text":"<p>Utilizing a predefined list of credit card types (e.g., VISA, MasterCard, American Express, Discover), the <code>RandomCCType</code> transformer injects random credit card type names into the designated database column. This feature allows for the creation of realistic and varied financial transaction datasets by simulating a range of credit card types without using real card data.</p>"},{"location":"built_in_transformers/standard_transformers/random_cc_type/#example-populate-random-credit-card-types-for-the-transactions-table","title":"Example: Populate random credit card types for the <code>transactions</code> table","text":"<p>This example shows how to configure the <code>RandomCCType</code> transformer to populate the <code>card_type</code> column in the <code>transactions</code> table with random credit card types. It is a straightforward method for simulating diverse payment methods across transactions.</p> RandomCCType transformer example<pre><code>- schema: \"public\"\n  name: \"transactions\"\n  transformers:\n    - name: \"RandomCCType\"\n      params:\n        column: \"card_type\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>card_type</code> column will be updated with random credit card types for each entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, maintaining the integrity of records where card type information is not applicable.</p>"},{"location":"built_in_transformers/standard_transformers/random_century/","title":"RandomCentury","text":"<p>The <code>RandomCentury</code> transformer is crafted to populate specified database columns with random century values. It is ideal for applications that require historical data simulation, such as generating random years within specific centuries for historical databases, testing datasets with temporal dimensions, or anonymizing dates in historical research data.</p>"},{"location":"built_in_transformers/standard_transformers/random_century/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_century/#description","title":"Description","text":"<p>The <code>RandomCentury</code> transformer utilizes an algorithm or a library function (hypothetical in this context) to generate random century values. Each value represents a century (e.g., <code>19th</code>, <code>20th</code>, <code>21st</code>), providing a broad temporal range that can be used to enhance datasets requiring a distribution across different historical periods without the need for precise date information.</p>"},{"location":"built_in_transformers/standard_transformers/random_century/#example-populate-random-centuries-for-the-historical_artifacts-table","title":"Example: Populate random centuries for the <code>historical_artifacts</code> table","text":"<p>This example shows how to configure the <code>RandomCentury</code> transformer to populate the <code>century</code> column in a <code>historical_artifacts</code> table with random century values, adding an element of variability and historical context to the dataset.</p> RandomCentury transformer example<pre><code>- schema: \"public\"\n  name: \"historical_artifacts\"\n  transformers:\n    - name: \"RandomCentury\"\n      params:\n        column: \"century\"\n        keep_null: false\n</code></pre> <p>In this setup, the <code>century</code> column will be filled with random century values, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, then existing NULL values in the column will remain untouched, preserving the original dataset's integrity where no temporal data is available.</p>"},{"location":"built_in_transformers/standard_transformers/random_choice/","title":"RandomChoice","text":"<p>Replace values randomly chosen from a provided list.</p>"},{"location":"built_in_transformers/standard_transformers/random_choice/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes any values A list of values in any format. The string with value <code>\\N</code> is considered NULL. Yes - validate Performs a decoding procedure via the PostgreSQL driver using the column type to ensure that values have correct type <code>true</code> No keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No"},{"location":"built_in_transformers/standard_transformers/random_choice/#description","title":"Description","text":"<p>The <code>RandomChoice</code> transformer replaces one randomly chosen value from the list provided in the <code>values</code> parameter. You can use the <code>validate</code> parameter to ensure that values are correct before applying the transformation. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_choice/#example-choosing-randomly-from-provided-dates","title":"Example: Choosing randomly from provided dates","text":"<p>In this example, the provided values undergo validation through PostgreSQL driver decoding, and one value is randomly chosen from the list.</p> RandomChoice transformer example<pre><code>    - schema: \"humanresources\"\n      name: \"jobcandidate\"\n      transformers:\n        - name: \"RandomChoice\"\n          params:\n            column: \"modifieddate\"\n            validate: true\n            values:\n              - \"2023-12-21 07:41:06.891\"\n              - \"2023-12-21 07:41:06.896\"\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_currency/","title":"RandomCurrency","text":"<p>The <code>RandomCurrency</code> transformer is tailored to populate specified database columns with random currency codes. This tool is highly beneficial for applications involving the simulation of international financial data, testing currency conversion features, or anonymizing currency information in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_currency/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_currency/#description","title":"Description","text":"<p>Utilizing a comprehensive list of global currency codes (e.g., USD, EUR, JPY), the <code>RandomCurrency</code> transformer injects random currency codes into the designated database column. This feature allows for the creation of diverse and realistic financial transaction datasets by simulating a variety of currencies without relying on actual financial data.</p>"},{"location":"built_in_transformers/standard_transformers/random_currency/#example-populate-random-currency-codes-for-the-transactions-table","title":"Example: Populate random currency codes for the <code>transactions</code> table","text":"<p>This example outlines configuring the <code>RandomCurrency</code> transformer to populate the <code>currency_code</code> column in a <code>transactions</code> table with random currency codes. It is an effective way to simulate international transactions across multiple currencies.</p> RandomCurrency transformer example<pre><code>- schema: \"public\"\n  name: \"transactions\"\n  transformers:\n    - name: \"RandomCurrency\"\n      params:\n        column: \"currency_code\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>currency_code</code> column will be updated with random currency codes for each entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where currency data may not be applicable.</p>"},{"location":"built_in_transformers/standard_transformers/random_date/","title":"RandomDate","text":"<p>Generate a random date in a specified interval.</p>"},{"location":"built_in_transformers/standard_transformers/random_date/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column Name of the column to be affected Yes date, timestamp, timestamptz min The minimum threshold date for the random value. The format depends on the column type. Yes - max The maximum threshold date for the random value. The format depends on the column type. Yes - truncate Truncate the date to the specified part (<code>nano</code>, <code>second</code>, <code>minute</code>, <code>hour</code>, <code>day</code>, <code>month</code>, <code>year</code>). The truncate operation is not applied by default. No - keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/random_date/#description","title":"Description","text":"<p>The <code>RandomDate</code> transformer generates a random date within the provided interval, starting from <code>min</code> to <code>max</code>. It can also perform date truncation up to the specified part of the date. The format of dates in the <code>min</code> and <code>max</code> parameters must adhere to PostgreSQL types, including <code>DATE</code>, <code>TIMESTAMP WITHOUT TIMEZONE</code>, or <code>TIMESTAMP WITH TIMEZONE</code>. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_date/#example-generate-modifieddate","title":"Example: Generate <code>modifieddate</code>","text":"<p>In the following example, a random timestamp without timezone is generated for the <code>modifieddate</code> column within the range from <code>2011-05-31 00:00:00</code> to <code>2013-05-31 00:00:00</code>, and the part of the random value after <code>day</code> is truncated.</p> RandomDate transformer example<pre><code>- schema: \"sales\"\n  name: \"salesorderdetail\"\n  transformers:\n    - name: \"RandomDate\"\n      params:\n        column: \"modifieddate\"\n        keep_null: false\n        min: \"2011-05-31 00:00:00\"\n        max: \"2013-05-31 00:00:00\"\n        truncate: \"day\"\n</code></pre> Expected result<pre><code>| column name  | original value      | transformed         |\n|--------------|---------------------|---------------------|\n| modifieddate | 2007-06-23 00:00:00 | 2005-12-08 00:00:00 |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_day_of_month/","title":"RandomDayOfMonth","text":"<p>The <code>RandomDayOfMonth</code> transformer is designed to populate specified database columns with random day-of-the-month values. It is particularly useful for scenarios requiring the simulation of dates, such as generating random event dates, user sign-up dates, or any situation where the specific day of the month is needed without reference to the actual month or year.</p>"},{"location":"built_in_transformers/standard_transformers/random_day_of_month/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar, int2, int4, int8, numeric keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_day_of_month/#description","title":"Description","text":"<p>Utilizing the <code>faker</code> library, the <code>RandomDayOfMonth</code> transformer generates random numerical values representing days of the month, ranging from 1 to 31. This allows for the easy insertion of random but plausible day-of-the-month data into a database, enhancing realism or anonymizing actual dates.</p>"},{"location":"built_in_transformers/standard_transformers/random_day_of_month/#example-populate-random-days-of-the-month-for-the-events-table","title":"Example: Populate random days of the month for the <code>events</code> table","text":"<p>This example illustrates how to configure the <code>RandomDayOfMonth</code> transformer to fill the <code>event_day</code> column in the <code>events</code> table with random day-of-the-month values, facilitating the simulation of varied event scheduling.</p> RandomDayOfMonth transformer example<pre><code>- schema: \"public\"\n  name: \"events\"\n  transformers:\n    - name: \"RandomDayOfMonth\"\n      params:\n        column: \"event_day\"\n        keep_null: false\n</code></pre> <p>With this setup, the <code>event_day</code> column will be updated with random day-of-the-month values, replacing any existing non-NULL values. Setting <code>keep_null</code> to <code>true</code> ensures that NULL values in the column are left unchanged, maintaining any existing gaps in the data.</p>"},{"location":"built_in_transformers/standard_transformers/random_day_of_week/","title":"RandomDayOfWeek","text":"<p>The <code>RandomDayOfWeek</code> transformer is specifically designed to fill specified database columns with random day-of-the-week names. It is particularly useful for applications that require simulated weekly schedules, random event planning, or any scenario where the day of the week is relevant but the specific date is not.</p>"},{"location":"built_in_transformers/standard_transformers/random_day_of_week/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_day_of_week/#description","title":"Description","text":"<p>Utilizing the <code>faker</code> library, the <code>RandomDayOfWeek</code> transformer generates names of days (e. g., Monday, Tuesday) at random. This transformer can be applied to any text or varchar column in a database, introducing variability and realism into data sets that need to represent days of the week in a non-specific manner.</p>"},{"location":"built_in_transformers/standard_transformers/random_day_of_week/#example-populate-random-days-of-the-week-for-the-work_schedule-table","title":"Example: Populate random days of the week for the <code>work_schedule</code> table","text":"<p>This example demonstrates configuring the <code>RandomDayOfWeek</code> transformer to populate the <code>work_day</code> column in the <code>work_schedule</code> table with random days of the week. This setup can help simulate a diverse range of work schedules without tying them to specific dates.</p> RandomDayOfWeek transformer example<pre><code>- schema: \"public\"\n  name: \"work_schedule\"\n  transformers:\n    - name: \"RandomDayOfWeek\"\n      params:\n        column: \"work_day\"\n        keep_null: false\n</code></pre> <p>In this configuration, every entry in the <code>work_day</code> column will be updated with a random day of the week, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, then existing NULL values within the column will remain unchanged.</p>"},{"location":"built_in_transformers/standard_transformers/random_domain_name/","title":"RandomDomainName","text":"<p>The <code>RandomDomainName</code> transformer is designed to populate specified database columns with random domain names. This tool is invaluable for simulating web data, testing applications that interact with domain names, or anonymizing real domain information in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_domain_name/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_domain_name/#description","title":"Description","text":"<p>By leveraging an algorithm or library capable of generating believable domain names, the <code>RandomDomainName</code> transformer introduces random domain names into the specified database column. Each generated domain name includes a second-level domain (SLD) and a top-level domain (TLD), such as \"example.com\" or \"website.org,\" providing a wide range of plausible web addresses for database enrichment.</p>"},{"location":"built_in_transformers/standard_transformers/random_domain_name/#example-populate-random-domain-names-for-the-websites-table","title":"Example: Populate random domain names for the <code>websites</code> table","text":"<p>This example demonstrates configuring the <code>RandomDomainName</code> transformer to populate the <code>domain</code> column in the <code>websites</code> table with random domain names. This approach facilitates the creation of a diverse and realistic set of web addresses for testing, simulation, or data anonymization purposes.</p> RandomDomainName transformer example<pre><code>- schema: \"public\"\n  name: \"websites\"\n  transformers:\n    - name: \"RandomDomainName\"\n      params:\n        column: \"domain\"\n        keep_null: false\n</code></pre> <p>In this setup, the <code>domain</code> column will be updated with random domain names for each entry, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, the transformer will preserve existing NULL values in the column, maintaining the integrity of data where domain information is not applicable.</p>"},{"location":"built_in_transformers/standard_transformers/random_e164_phone_number/","title":"RandomE164PhoneNumber","text":"<p>The <code>RandomE164PhoneNumber</code> transformer is developed to populate specified database columns with random E.164 phone numbers. This tool is essential for applications requiring the simulation of contact information, testing phone number validation systems, or anonymizing phone number data in datasets while focusing on E.164 numbers.</p>"},{"location":"built_in_transformers/standard_transformers/random_e164_phone_number/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_e164_phone_number/#description","title":"Description","text":"<p>The <code>RandomE164PhoneNumber</code> transformer utilizes algorithms capable of generating random E.164 phone numbers with the standard international format and injects them into the designated database column. This feature allows for the creation of diverse and realistic contact information in datasets for development, testing, or data anonymization purposes.</p>"},{"location":"built_in_transformers/standard_transformers/random_e164_phone_number/#example-populate-random-e164-phone-numbers-for-the-contact_information-table","title":"Example: Populate random E.164 phone numbers for the <code>contact_information</code> table","text":"<p>This example demonstrates configuring the <code>RandomE164PhoneNumber</code> transformer to populate the <code>phone_number</code> column in the <code>contact_information</code> table with random E.164 phone numbers. It is an effective method for simulating a variety of contact information entries with E.164 numbers.</p> RandomE164PhoneNumber transformer example<pre><code>- schema: \"public\"\n  name: \"contact_information\"\n  transformers:\n    - name: \"RandomE164PhoneNumber\"\n      params:\n        column: \"phone_number\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>phone_number</code> column will be updated with random E.164 phone numbers for each contact information entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where E.164 phone number information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_email/","title":"RandomEmail","text":"<p>The <code>RandomEmail</code> transformer is designed to populate specified database columns with random email addresses. This transformer is especially useful for applications requiring the simulation of user contact data, testing email functionalities, or anonymizing real user email addresses in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_email/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_email/#description","title":"Description","text":"<p>Leveraging a method or library capable of generating plausible email address strings, the <code>RandomEmail</code> transformer injects random email addresses into the specified database column. It generates email addresses with varied domains and user names, offering a realistic range of email patterns suitable for filling user tables, contact lists, or any other dataset requiring email addresses without utilizing real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_email/#example-populate-random-email-addresses-for-the-users-table","title":"Example: Populate random email addresses for the <code>users</code> table","text":"<p>This example illustrates configuring the <code>RandomEmail</code> transformer to populate the <code>email</code> column in the <code>users</code> table with random email addresses, thereby simulating a diverse user base without exposing real contact information.</p> RandomEmail transformer example<pre><code>- schema: \"public\"\n  name: \"users\"\n  transformers:\n    - name: \"RandomEmail\"\n      params:\n        column: \"email\"\n        keep_null: false\n</code></pre> <p>In this setup, the <code>email</code> column will receive random email addresses for each entry, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, then the transformer will preserve existing NULL values, maintaining the integrity of the original dataset where email information is absent.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name/","title":"RandomFirstName","text":"<p>The <code>RandomFirstName</code> transformer is designed to populate specified database columns with random first names. This tool is indispensable for applications requiring the simulation of user profiles, testing user registration systems, or anonymizing user data in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_first_name/#description","title":"Description","text":"<p>The <code>RandomFirstName</code> transformer utilizes a comprehensive list of first names to inject random first names into the designated database column. This feature allows for the creation of diverse and realistic user profiles by simulating a variety of first names without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name/#example-populate-random-first-names-for-the-user_profiles-table","title":"Example: Populate random first names for the <code>user_profiles</code> table","text":"<p>This example demonstrates configuring the <code>RandomFirstName</code> transformer to populate the <code>first_name</code> column in the <code>user_profiles</code> table with random first names. It is an effective method for simulating a variety of user profiles with diverse first names.</p> RandomFirstName transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomFirstName\"\n      params:\n        column: \"first_name\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>first_name</code> column will be updated with random first names for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where first name information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name_female/","title":"RandomFirstNameFemale","text":"<p>The <code>RandomFirstNameFemale</code> transformer is designed to populate specified database columns with random female first names. This tool is crucial for applications requiring the simulation of user profiles, testing gender-specific features, or anonymizing user data in datasets while focusing on female names.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name_female/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_first_name_female/#description","title":"Description","text":"<p>The <code>RandomFirstNameFemale</code> transformer utilizes a comprehensive list of female first names to inject random female first names into the designated database column. This feature allows for the creation of diverse and realistic user profiles with a focus on female names without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name_female/#example-populate-random-female-first-names-for-the-user_profiles-table","title":"Example: Populate random female first names for the <code>user_profiles</code> table","text":"<p>This example demonstrates configuring the <code>RandomFirstNameFemale</code> transformer to populate the <code>first_name</code> column in the <code>user_profiles</code> table with random female first names. It is an effective method for simulating a variety of user profiles with diverse female first names.</p> RandomFirstNameFemale transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomFirstNameFemale\"\n      params:\n        column: \"first_name\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>first_name</code> column will be updated with random female first names for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where female first name information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name_male/","title":"RandomFirstNameMale","text":"<p>The <code>RandomFirstNameMale</code> transformer is developed to populate specified database columns with random male first names. This tool is essential for applications requiring the simulation of user profiles, testing gender-specific features, or anonymizing user data in datasets while focusing on male names.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name_male/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_first_name_male/#description","title":"Description","text":"<p>The <code>RandomFirstNameMale</code> transformer utilizes a comprehensive list of male first names to inject random male first names into the designated database column. This feature allows for the creation of diverse and realistic user profiles with a focus on male names without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_first_name_male/#example-populate-random-male-first-names-for-the-user_profiles-table","title":"Example: Populate random male first names for the <code>user_profiles</code> table","text":"<p>This example demonstrates configuring the <code>RandomFirstNameMale</code> transformer to populate the <code>first_name</code> column in the <code>user_profiles</code> table with random male first names. It is an effective method for simulating a variety of user profiles with diverse male first names.</p> RandomFirstNameMale transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomFirstNameMale\"\n      params:\n        column: \"first_name\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>first_name</code> column will be updated with random male first names for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where male first name information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_float/","title":"RandomFloat","text":"<p>Generate a random float within the provided interval.</p>"},{"location":"built_in_transformers/standard_transformers/random_float/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes float4 (real), float8 (double precision), numeric min The minimum threshold for the random value. The value range depends on the column type. Yes - max The maximum threshold for the random value. The value range depends on the column type. Yes - precision The precision of the random float value (number of digits after the decimal point) <code>4</code> No - keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/random_float/#description","title":"Description","text":"<p>The <code>RandomFloat</code> transformer generates a random float value within the provided interval, starting from <code>min</code> to <code>max</code>, with the option to specify the number of decimal digits by using the <code>precision</code> parameter. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_float/#example-generate-random-price","title":"Example: Generate random price","text":"<p>In this example, the <code>RandomFloat</code> transformer generates random prices in the range from <code>0.1</code> to <code>7000</code> while maintaining a precision of up to 2 digits.</p> RandomFloat transformer example<pre><code>- schema: \"sales\"\n  name: \"salesorderdetail\"\n  transformers:\n    - name: \"RandomFloat\"\n      params:\n        column: \"unitprice\"\n        min: 0.1\n        max: 7000\n        precision: 2\n</code></pre> Expected result<pre><code>| column name | original value | transformed |\n|-------------|----------------|-------------|\n| unitprice   | 2024.994       | 6806.5      |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_int/","title":"RandomInt","text":"<p>Generate a random integer within the provided interval.</p>"},{"location":"built_in_transformers/standard_transformers/random_int/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes int2 (smallint), int4 (int), int8 (bigint), numeric min The minimum threshold for the random value. The value range depends on the column type. Yes - max The maximum threshold for the random value. The value range depends on the column type. Yes - keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/random_int/#description","title":"Description","text":"<p>The <code>RandomInt</code> transformer generates a random integer within the specified <code>min</code> and <code>max</code> thresholds. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_int/#example-generate-random-item-quantity","title":"Example: Generate random item quantity","text":"<p>In the following example, the <code>RandomInt</code> transformer generates a random value in the range from <code>1</code> to <code>30</code> and assigns it to the <code>orderqty</code> column.</p> RandomInt transformer example<pre><code>- schema: \"sales\"\n  name: \"salesorderdetail\"\n  transformers:\n    - name: \"RandomInt\"\n      params:\n        column: \"orderqty\"\n        min: 1\n        max: 30\n</code></pre> Expected result<pre><code>| column name | original value | transformed |\n|-------------|----------------|-------------|\n| orderqty    | 1              | 8           |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_ipv4/","title":"RandomIPv4","text":"<p>The <code>RandomIPv4</code> transformer is designed to populate specified database columns with random IPv4 addresses. This utility is essential for applications requiring the simulation of network data, testing systems that utilize IP addresses, or anonymizing real IP addresses in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_ipv4/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar, inet keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_ipv4/#description","title":"Description","text":"<p>Utilizing a robust algorithm or library for generating IPv4 address strings, the <code>RandomIPv4</code> transformer injects random IPv4 addresses into the designated database column. Each generated address follows the standard IPv4 format, consisting of four octets separated by dots (e. g., \"192.168.1.1\"), ensuring a wide range of plausible network addresses for various use cases.</p>"},{"location":"built_in_transformers/standard_transformers/random_ipv4/#example-populate-random-ipv4-addresses-for-the-network_logs-table","title":"Example: Populate random IPv4 addresses for the <code>network_logs</code> table","text":"<p>This example shows how to configure the <code>RandomIPv4</code> transformer to populate the <code>source_ip</code> column in the <code>network_logs</code> table with random IPv4 addresses, simulating diverse network traffic sources for analysis or testing purposes.</p> RandomIPv4 transformer example<pre><code>- schema: \"public\"\n  name: \"network_logs\"\n  transformers:\n    - name: \"RandomIPv4\"\n      params:\n        column: \"source_ip\"\n        keep_null: false\n</code></pre> <p>With this setup, the <code>source_ip</code> column will be updated with random IPv4 addresses for each entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, it will ensure that existing NULL values in the column are preserved, accommodating scenarios where IP address data may be intentionally omitted.</p>"},{"location":"built_in_transformers/standard_transformers/random_ipv6/","title":"RandomIPv6","text":"<p>The <code>RandomIPv6</code> transformer is engineered to populate specified database columns with random IPv6 addresses. This tool is particularly useful for simulating modern network environments, testing systems that operate with IPv6 addresses, or anonymizing datasets containing real IPv6 addresses.</p>"},{"location":"built_in_transformers/standard_transformers/random_ipv6/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar, inet keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_ipv6/#description","title":"Description","text":"<p>Employing advanced algorithms or libraries capable of generating IPv6 address strings, the <code>RandomIPv6</code> transformer introduces random IPv6 addresses into the specified database column. IPv6 addresses, represented as eight groups of four hexadecimal digits separated by colons (e. g., \"2001:0db8:85a3:0000:0000:8a2e:0370:7334\"), provide a vast range of possible addresses, reflecting the extensive addressing capacity of the IPv6 standard.</p>"},{"location":"built_in_transformers/standard_transformers/random_ipv6/#example-populate-random-ipv6-addresses-for-the-devices-table","title":"Example: Populate random IPv6 addresses for the <code>devices</code> table","text":"<p>This example illustrates configuring the <code>RandomIPv6</code> transformer to populate the <code>device_ip</code> column in the <code>devices</code> table with random IPv6 addresses, enhancing the dataset with a broad spectrum of network addresses for development, testing, or data protection purposes.</p> RandomIPv6 transformer example<pre><code>- schema: \"public\"\n  name: \"devices\"\n  transformers:\n    - name: \"RandomIPv6\"\n      params:\n        column: \"device_ip\"\n        keep_null: false\n</code></pre> <p>This configuration ensures that the <code>device_ip</code> column receives random IPv6 addresses for each entry, replacing any existing non-NULL values. Setting the <code>keep_null</code> parameter to <code>true</code> allows for the preservation of existing NULL values within the column, maintaining the integrity of records where IP address information is not applicable or available.</p>"},{"location":"built_in_transformers/standard_transformers/random_last_name/","title":"RandomLastName","text":"<p>The <code>RandomLastName</code> transformer is developed to populate specified database columns with random last names. This tool is essential for applications requiring the simulation of user profiles, testing user registration systems, or anonymizing user data in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_last_name/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_last_name/#description","title":"Description","text":"<p>The <code>RandomLastName</code> transformer utilizes a comprehensive list of last names to inject random last names into the designated database column. This feature allows for the creation of diverse and realistic user profiles by simulating a variety of last names without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_last_name/#example-populate-random-last-names-for-the-user_profiles-table","title":"Example: Populate random last names for the <code>user_profiles</code> table","text":"<p>This example demonstrates configuring the <code>RandomLastName</code> transformer to populate the <code>last_name</code> column in the <code>user_profiles</code> table with random last names. It is an effective method for simulating a variety of user profiles with diverse last names.</p> RandomLastName transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomLastName\"\n      params:\n        column: \"last_name\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>last_name</code> column will be updated with random last names for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where last name information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_latitude/","title":"RandomLatitude","text":"<p>The <code>RandomLatitude</code> transformer generates random latitude values for specified database columns. It is designed to support geographical data enhancements, particularly useful for applications requiring randomized but plausible geographical coordinates.</p>"},{"location":"built_in_transformers/standard_transformers/random_latitude/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes float4, float8, numeric keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_latitude/#description","title":"Description","text":"<p>The <code>RandomLatitude</code> transformer utilizes the <code>faker</code> library to produce random latitude values within the range of -90 to +90 degrees. This transformer can be applied to columns designated to store geographical latitude information, enhancing data sets with randomized latitude coordinates.</p>"},{"location":"built_in_transformers/standard_transformers/random_latitude/#example-populate-random-latitude-for-the-locations-table","title":"Example: Populate random latitude for the <code>locations</code> table","text":"<p>This example demonstrates configuring the <code>RandomLatitude</code> transformer to populate the <code>latitude</code> column in the <code>locations</code> table with random latitude values.</p> RandomLatitude transformer example<pre><code>- schema: \"public\"\n  name: \"locations\"\n  transformers:\n    - name: \"RandomLatitude\"\n      params:\n        column: \"latitude\"\n        keep_null: false\n</code></pre> <p>With this configuration, the <code>latitude</code> column will be filled with random latitude values, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, existing NULL values will be preserved.</p>"},{"location":"built_in_transformers/standard_transformers/random_longitude/","title":"RandomLongitude","text":"<p>The <code>RandomLongitude</code> transformer is designed to generate random longitude values for specified database columns, enhancing datasets with realistic geographic coordinates suitable for a wide range of applications, from testing location-based services to anonymizing real geographic data.</p>"},{"location":"built_in_transformers/standard_transformers/random_longitude/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes float4, float8, numeric keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_longitude/#description","title":"Description","text":"<p>The <code>RandomLongitude</code> transformer leverages the <code>faker</code> library to produce random longitude values within the globally accepted range of -180 to +180 degrees. This flexibility allows the transformer to be applied to any column intended for storing longitude data, providing a simple yet powerful tool for introducing randomized longitude coordinates into a database.</p>"},{"location":"built_in_transformers/standard_transformers/random_longitude/#example-populate-random-longitude-for-the-locations-table","title":"Example: Populate random longitude for the <code>locations</code> table","text":"<p>This example shows how to use the <code>RandomLongitude</code> transformer to fill the <code>longitude</code> column in the <code>locations</code> table with random longitude values.</p> RandomLongitude transformer example<pre><code>- schema: \"public\"\n  name: \"locations\"\n  transformers:\n    - name: \"RandomLongitude\"\n      params:\n        column: \"longitude\"\n        keep_null: false\n</code></pre> <p>This setup ensures that all entries in the <code>longitude</code> column receive a random longitude value, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, then existing NULL values in the column will remain unchanged.</p>"},{"location":"built_in_transformers/standard_transformers/random_mac_address/","title":"RandomMacAddress","text":"<p>The <code>RandomMacAddress</code> transformer is developed to populate specified database columns with random MAC (Media Access Control) addresses. This transformer is particularly useful for simulating network hardware data, testing applications that process MAC addresses, or anonymizing real network device identifiers in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_mac_address/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar, macaddr, macaddr8 keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_mac_address/#description","title":"Description","text":"<p>Utilizing a sophisticated algorithm or library for generating MAC address strings, the <code>RandomMacAddress</code> transformer injects random MAC addresses into the designated database column. Each generated MAC address follows the standard format of six groups of two hexadecimal digits, separated by colons (e. g., \"01:23:45:67:89:ab\"), ensuring plausible values for network device simulations.</p>"},{"location":"built_in_transformers/standard_transformers/random_mac_address/#example-populate-random-mac-addresses-for-the-network_devices-table","title":"Example: Populate random MAC addresses for the <code>network_devices</code> table","text":"<p>This example shows how to configure the <code>RandomMacAddress</code> transformer to populate the <code>mac_address</code> column in a <code>network_devices</code> table with random MAC addresses, enhancing the realism of simulated network device data.</p> RandomMacAddress transformer example<pre><code>- schema: \"public\"\n  name: \"network_devices\"\n  transformers:\n    - name: \"RandomMacAddress\"\n      params:\n        column: \"mac_address\"\n        keep_null: false\n</code></pre> <p>With this configuration, every entry in the <code>mac_address</code> column will be assigned a random MAC address, replacing any existing non-NULL values. Setting the <code>keep_null</code> parameter to <code>true</code> allows the preservation of existing NULL values within the column, accommodating scenarios where MAC address data may be intentionally absent.</p>"},{"location":"built_in_transformers/standard_transformers/random_month_name/","title":"RandomMonthName","text":"<p>The <code>RandomMonthName</code> transformer is crafted to populate specified database columns with random month names. This transformer is especially useful for scenarios requiring the simulation of time-related data, such as user birth months or event months, without relying on specific date values.</p>"},{"location":"built_in_transformers/standard_transformers/random_month_name/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_month_name/#description","title":"Description","text":"<p>The <code>RandomMonthName</code> transformer utilizes the <code>faker</code> library to generate the names of months at random. It can be applied to any textual column in a database to introduce variety and realism into data sets that require representations of months without the need for specific calendar dates.</p>"},{"location":"built_in_transformers/standard_transformers/random_month_name/#example-populate-random-month-names-for-the-user_profiles-table","title":"Example: Populate random month names for the <code>user_profiles</code> table","text":"<p>This example demonstrates how to configure the <code>RandomMonthName</code> transformer to fill the <code>birth_month</code> column in the <code>user_profiles</code> table with random month names, adding a layer of diversity to user data without using actual birthdates.</p> RandomMonthName transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomMonthName\"\n      params:\n        column: \"birth_month\"\n        keep_null: false\n</code></pre> <p>With this setup, the <code>birth_month</code> column will be updated with random month names, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, then existing NULL values within the column will remain untouched.</p>"},{"location":"built_in_transformers/standard_transformers/random_name/","title":"RandomName","text":"<p>The <code>RandomName</code> transformer is designed to populate specified database columns with random full names, including both first names and last names. This tool is indispensable for applications requiring the simulation of user profiles, testing user registration systems, or anonymizing user data in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_name/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_name/#description","title":"Description","text":"<p>The <code>RandomName</code> transformer utilizes a comprehensive list of first names and last names to inject random full names into the designated database column. This feature allows for the creation of diverse and realistic user profiles by simulating a variety of full names without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_name/#example-populate-random-full-names-for-the-user_profiles-table","title":"Example: Populate random full names for the <code>user_profiles</code> table","text":"<p>This example demonstrates configuring the <code>RandomName</code> transformer to populate the name column in the <code>user_profiles</code> table with random full names. It is an effective method for simulating a variety of user profiles with diverse full names.</p> RandomName transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomName\"\n      params:\n        column: \"name\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>name</code> column will be updated with random full names for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where full name information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_paragraph/","title":"RandomParagraph","text":"<p>The <code>RandomParagraph</code> transformer is crafted to populate specified database columns with random paragraphs. This utility is indispensable for applications that require the generation of extensive textual content, such as simulating articles, enhancing textual datasets for NLP systems, or anonymizing textual content in databases.</p>"},{"location":"built_in_transformers/standard_transformers/random_paragraph/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_paragraph/#description","title":"Description","text":"<p>Employing sophisticated text generation algorithms or libraries, the <code>RandomParagraph</code> transformer generates random paragraphs, injecting them into the designated database column. This transformer is designed to create varied and plausible paragraphs that simulate real-world textual content, providing a valuable tool for database enrichment, testing, and anonymization.</p>"},{"location":"built_in_transformers/standard_transformers/random_paragraph/#example-populate-random-paragraphs-for-the-articles-table","title":"Example: Populate random paragraphs for the <code>articles</code> table","text":"<p>This example illustrates configuring the <code>RandomParagraph</code> transformer to populate the <code>body</code> column in an <code>articles</code> table with random paragraphs. It is an effective way to simulate diverse article content for development, testing, or demonstration purposes.</p> RandomParagraph transformer example<pre><code>- schema: \"public\"\n  name: \"articles\"\n  transformers:\n    - name: \"RandomParagraph\"\n      params:\n        column: \"body\"\n        keep_null: false\n</code></pre> <p>With this setup, the <code>body</code> column will receive random paragraphs for each entry, replacing any existing non-NULL values. Setting the <code>keep_null</code> parameter to <code>true</code> allows for the preservation of existing NULL values within the column, maintaining the integrity of records where article content is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_password/","title":"RandomPassword","text":"<p>The <code>RandomPassword</code> transformer is designed to populate specified database columns with random passwords. This utility is vital for applications that require the simulation of secure user data, testing systems with authentication mechanisms, or anonymizing real passwords in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_password/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_password/#description","title":"Description","text":"<p>Employing sophisticated password generation algorithms or libraries, the <code>RandomPassword</code> transformer injects random passwords into the designated database column. This feature is particularly useful for creating realistic and secure user password datasets for development, testing, or demonstration purposes.</p>"},{"location":"built_in_transformers/standard_transformers/random_password/#example-populate-random-passwords-for-the-user_accounts-table","title":"Example: Populate random passwords for the <code>user_accounts</code> table","text":"<p>This example demonstrates how to configure the <code>RandomPassword</code> transformer to populate the <code>password</code> column in the <code>user_accounts</code> table with random passwords.</p> RandomPassword transformer example<pre><code>- schema: \"public\"\n  name: \"user_accounts\"\n  transformers:\n    - name: \"RandomPassword\"\n      params:\n        column: \"password\"\n        keep_null: false\n</code></pre> <p>In this configuration, every entry in the <code>password</code> column will be updated with a random password. Setting the <code>keep_null</code> parameter to <code>true</code> will preserve existing NULL values in the column, accommodating scenarios where password data may not be applicable.</p>"},{"location":"built_in_transformers/standard_transformers/random_phone_number/","title":"RandomPhoneNumber","text":"<p>The <code>RandomPhoneNumber</code> transformer is developed to populate specified database columns with random phone numbers. This tool is essential for applications requiring the simulation of contact information, testing phone number validation systems, or anonymizing phone number data in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_phone_number/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_phone_number/#description","title":"Description","text":"<p>The <code>RandomPhoneNumber</code> transformer utilizes algorithms capable of generating random phone numbers with various formats and injects them into the designated database column. This feature allows for the creation of diverse and realistic contact information in datasets for development, testing, or data anonymization purposes.</p>"},{"location":"built_in_transformers/standard_transformers/random_phone_number/#example-populate-random-phone-numbers-for-the-contact_information-table","title":"Example: Populate random phone numbers for the <code>contact_information</code> table","text":"<p>This example demonstrates configuring the <code>RandomPhoneNumber</code> transformer to populate the <code>phone_number</code> column in the <code>contact_information</code> table with random phone numbers. It is an effective method for simulating a variety of contact information entries.</p> RandomPhoneNumber transformer example<pre><code>- schema: \"public\"\n  name: \"contact_information\"\n  transformers:\n    - name: \"RandomPhoneNumber\"\n      params:\n        column: \"phone_number\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>phone_number</code> column will be updated with random phone numbers for each contact information entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where phone number information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_sentence/","title":"RandomSentence","text":"<p>The <code>RandomSentence</code> transformer is designed to populate specified database columns with random sentences. Ideal for simulating natural language text for user comments, testing NLP systems, or anonymizing textual data in databases.</p>"},{"location":"built_in_transformers/standard_transformers/random_sentence/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_sentence/#description","title":"Description","text":"<p>The <code>RandomSentence</code> transformer employs complex text generation algorithms or libraries to generate random sentences, injecting them into a designated database column without the need for specifying sentence length. This flexibility ensures the creation of varied and plausible text for a wide range of applications.</p>"},{"location":"built_in_transformers/standard_transformers/random_sentence/#example-populate-random-sentences-for-the-comments-table","title":"Example: Populate random sentences for the <code>comments</code> table","text":"<p>This example shows how to configure the <code>RandomSentence</code> transformer to populate the <code>comment</code> column in the <code>comments</code> table with random sentences. It is a straightforward method for simulating diverse user-generated content.</p> RandomSentence transformer example<pre><code>- schema: \"public\"\n  name: \"comments\"\n  transformers:\n    - name: \"RandomSentence\"\n      params:\n        column: \"comment\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>comment</code> column will be updated with random sentences for each entry, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, existing NULL values in the column will be preserved, maintaining the integrity of records where comments are not applicable.</p>"},{"location":"built_in_transformers/standard_transformers/random_string/","title":"RandomString","text":"<p>Generate a random string using the provided characters within the specified length range.</p>"},{"location":"built_in_transformers/standard_transformers/random_string/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar min_length The minimum length of the generated string Yes - max_length The maximum length of the generated string Yes - symbols The range of characters that can be used in the random string <code>abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ</code> No - keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/random_string/#description","title":"Description","text":"<p>The <code>RandomString</code> transformer generates a random string with a length between <code>min_length</code> and <code>max_length</code> using the characters specified in the symbols string as the possible set of characters. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_string/#example-generate-a-random-string-for-accountnumber","title":"Example: Generate a random string for <code>accountnumber</code>","text":"<p>In the following example, a random string is generated for the <code>accountnumber</code> column with a length range from <code>9</code> to <code>12</code>. The character set used for generation includes <code>1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ</code>.</p> RandomString transformer example<pre><code>- schema: \"purchasing\"\n  name: \"vendor\"\n  transformers:\n    - name: \"RandomString\"\n      params:\n        column: \"accountnumber\"\n        min_length: 9\n        max_length: 12\n        symbols: \"1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n</code></pre> Expected result<pre><code>| column name   | original value | transformed |\n|---------------|----------------|-------------|\n| accountnumber | AUSTRALI0001   | 96B82A65548 |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_timezone/","title":"RandomTimezone","text":"<p>The <code>RandomTimezone</code> transformer is designed to populate specified database columns with random timezone strings. This transformer is particularly useful for applications that require the simulation of global user data, testing of timezone-related functionalities, or anonymizing real user timezone information in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_timezone/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_timezone/#description","title":"Description","text":"<p>Utilizing a comprehensive library or algorithm for generating timezone data, the <code>RandomTimezone</code> transformer provides random timezone strings (e. g., \"America/New_York\", \"Europe/London\") for database columns. This feature enables the creation of diverse and realistic datasets by simulating timezone information for user profiles, event timings, or any other data requiring timezone context.</p>"},{"location":"built_in_transformers/standard_transformers/random_timezone/#example-populate-random-timezone-strings-for-the-user_accounts-table","title":"Example: Populate random timezone strings for  the <code>user_accounts</code> table","text":"<p>This example demonstrates how to configure the <code>RandomTimezone</code> transformer to populate the <code>timezone</code> column in the <code>user_accounts</code> table with random timezone strings, enhancing the dataset with varied global user representations.</p> RandomTimezone transformer example<pre><code>- schema: \"public\"\n  name: \"user_accounts\"\n  transformers:\n    - name: \"RandomTimezone\"\n      params:\n        column: \"timezone\"\n        keep_null: false\n</code></pre> <p>With this configuration, every entry in the <code>timezone</code> column will be updated with a random timezone string, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values within the column will remain unchanged, preserving the integrity of rows without specified timezone data.</p>"},{"location":"built_in_transformers/standard_transformers/random_title_female/","title":"RandomTitleFemale","text":"<p>The <code>RandomTitleFemale</code> transformer is designed to populate specified database columns with random female titles. This tool is crucial for applications that require the simulation of user profiles, testing gender-specific features, or anonymizing user data in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_title_female/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_title_female/#description","title":"Description","text":"<p>The <code>RandomTitleFemale</code> transformer utilizes a predefined list of female titles (e. g., Mrs., Dr., Prof.) to inject random female titles into the designated database column. This feature allows for the creation of diverse and realistic user profiles by simulating a variety of female titles without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_title_female/#example-populate-random-female-titles-for-the-user_profiles-table","title":"Example: Populate random female titles for the <code>user_profiles</code> table","text":"<p>This example demonstrates configuring the <code>RandomTitleFemale</code> transformer to populate the <code>title</code> column in the <code>user_profiles</code> table with random female titles. It is an effective method for simulating a variety of user profiles with female titles.</p> RandomTitleFemale transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomTitleFemale\"\n      params:\n        column: \"title\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>title</code> column will be updated with random female titles for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where title information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_title_male/","title":"RandomTitleMale","text":"<p>The <code>RandomTitleMale</code> transformer is developed to populate specified database columns with random male titles. This tool is essential for applications that require the simulation of user profiles, testing gender-specific features, or anonymizing user data in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_title_male/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_title_male/#description","title":"Description","text":"<p>The <code>RandomTitleMale</code> transformer utilizes a predefined list of male titles (e. g., Mr., Dr., Prof.) to inject random male titles into the designated database column. This feature allows for the creation of diverse and realistic user profiles by simulating a variety of male titles without using real user data.</p>"},{"location":"built_in_transformers/standard_transformers/random_title_male/#example-populate-random-male-titles-for-the-user_profile-table","title":"Example: Populate random male titles for the <code>user_profile</code> table","text":"<p>This example outlines configuring the <code>RandomTitleMale</code> transformer to populate the <code>title</code> column in a <code>user_profiles</code> table with random male titles. It is a straightforward method for simulating a variety of user profiles with male titles.</p> RandomTitleMale transformer example<pre><code>- schema: \"public\"\n  name: \"user_profiles\"\n  transformers:\n    - name: \"RandomTitleMale\"\n      params:\n        column: \"title\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>title</code> column will be updated with random male titles for each user profile entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where title information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_toll_free_phone_number/","title":"RandomTollFreePhoneNumber","text":"<p>The <code>RandomTollFreePhoneNumber</code> transformer is designed to populate specified database columns with random toll-free phone numbers. This tool is essential for applications requiring the simulation of contact information, testing phone number validation systems, or anonymizing phone number data in datasets while focusing on toll-free numbers.</p>"},{"location":"built_in_transformers/standard_transformers/random_toll_free_phone_number/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_toll_free_phone_number/#description","title":"Description","text":"<p>The <code>RandomTollFreePhoneNumber</code> transformer utilizes algorithms capable of generating random toll-free phone numbers with various formats and injects them into the designated database column. This feature allows for the creation of diverse and realistic toll-free contact information in datasets for development, testing, or data anonymization purposes.</p>"},{"location":"built_in_transformers/standard_transformers/random_toll_free_phone_number/#example-populate-random-toll-free-phone-numbers-for-the-contact_information-table","title":"Example: Populate random toll-free phone numbers for the <code>contact_information</code> table","text":"<p>This example demonstrates configuring the <code>RandomTollFreePhoneNumber</code> transformer to populate the <code>phone_number</code> column in the <code>contact_information</code> table with random toll-free phone numbers. It is an effective method for simulating a variety of contact information entries with toll-free numbers.</p> RandomTollFreePhoneNumber transformer example<pre><code>- schema: \"public\"\n  name: \"contact_information\"\n  transformers:\n    - name: \"RandomTollFreePhoneNumber\"\n      params:\n        column: \"phone_number\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>phone_number</code> column will be updated with random toll-free phone numbers for each contact information entry, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, existing NULL values in the column will be preserved, ensuring the integrity of records where toll-free phone number information is not applicable or provided.</p>"},{"location":"built_in_transformers/standard_transformers/random_unix_time/","title":"RandomUnixTime","text":"<p>The <code>RandomUnixTime</code> transformer generates random Unix time values (timestamps) for specified database columns. It is particularly useful for populating columns with timestamp data, simulating time-related data, or anonymizing actual timestamps in a dataset.</p>"},{"location":"built_in_transformers/standard_transformers/random_unix_time/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes int4, int8, numeric keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_unix_time/#description","title":"Description","text":"<p>The <code>RandomUnixTime</code> transformer uses the <code>faker</code> library to generate random Unix timestamps. Unix time, also known as POSIX time or Epoch time, is a system for describing points in time, defined as the number of seconds elapsed since midnight Coordinated Universal Time (UTC) of January 1, 1970, not counting leap seconds. This transformer allows for the generation of timestamps that can represent any moment from the Epoch to the present or even into the future, depending on the range of the <code>faker</code> library's implementation.</p>"},{"location":"built_in_transformers/standard_transformers/random_unix_time/#example-populate-random-timestamps-for-the-registration_dates-table","title":"Example: Populate random timestamps for the <code>registration_dates</code> table","text":"<p>This example configures the <code>RandomUnixTime</code> transformer to apply random Unix timestamps to the <code>registration_date</code> column in a <code>users</code> table, simulating user registration times.</p> RandomUnixTime transformer example<pre><code>- schema: \"public\"\n  name: \"users\"\n  transformers:\n    - name: \"RandomUnixTime\"\n      params:\n        column: \"registration_date\"\n        keep_null: false\n</code></pre> <p>In this configuration, every entry in the <code>registration_date</code> column is assigned a random Unix timestamp, replacing any existing non-NULL values. Setting <code>keep_null</code> to <code>true</code> would ensure that NULL values in the column are left unchanged.</p>"},{"location":"built_in_transformers/standard_transformers/random_url/","title":"RandomURL","text":"<p>The <code>RandomURL</code> transformer is designed to populate specified database columns with random URL (Uniform Resource Locator) addresses. This tool is highly beneficial for simulating web content, testing applications that require URL input, or anonymizing real web addresses in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_url/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_url/#description","title":"Description","text":"<p>Utilizing advanced algorithms or libraries for generating URL strings, the <code>RandomURL</code> transformer injects random, plausible URLs into the designated database column. Each generated URL is structured to include the protocol (e. g., \"http://\", \"https://\"), domain name, and path, offering a realistic range of web addresses for various applications.</p>"},{"location":"built_in_transformers/standard_transformers/random_url/#example-populate-random-urls-for-the-webpages-table","title":"Example: Populate random URLs for the <code>webpages</code> table","text":"<p>This example illustrates how to configure the <code>RandomURL</code> transformer to populate the <code>page_url</code> column in a <code>webpages</code> table with random URLs, providing a broad spectrum of web addresses for testing or data simulation purposes.</p> RandomURL transformer example<pre><code>- schema: \"public\"\n  name: \"webpages\"\n  transformers:\n    - name: \"RandomURL\"\n      params:\n        column: \"page_url\"\n        keep_null: false\n</code></pre> <p>With this configuration, the <code>page_url</code> column will be filled with random URLs for each entry, replacing any existing non-NULL values. Setting the <code>keep_null</code> parameter to <code>true</code> allows for the preservation of existing NULL values within the column, accommodating scenarios where URL data may be intentionally omitted.</p>"},{"location":"built_in_transformers/standard_transformers/random_username/","title":"RandomUsername","text":"<p>The <code>RandomUsername</code> transformer is crafted to populate specified database columns with random usernames. This utility is crucial for applications that require the simulation of user data, testing systems with user login functionality, or anonymizing real usernames in datasets.</p>"},{"location":"built_in_transformers/standard_transformers/random_username/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_username/#description","title":"Description","text":"<p>By employing sophisticated algorithms or libraries capable of generating believable usernames, the <code>RandomUsername</code> transformer introduces random usernames into the specified database column. Each generated username is designed to be unique and plausible, incorporating a mix of letters, numbers, and possibly special characters, depending on the generation logic used.</p>"},{"location":"built_in_transformers/standard_transformers/random_username/#example-populate-random-usernames-for-the-user_accounts-table","title":"Example: Populate random usernames for the <code>user_accounts</code> table","text":"<p>This example demonstrates configuring the <code>RandomUsername</code> transformer to populate the <code>username</code> column in a <code>user_accounts</code> table with random usernames. This setup is ideal for creating a diverse and realistic user base for development, testing, or demonstration purposes.</p> RandomUsername transformer example<pre><code>- schema: \"public\"\n  name: \"user_accounts\"\n  transformers:\n    - name: \"RandomUsername\"\n      params:\n        column: \"username\"\n        keep_null: false\n</code></pre> <p>In this configuration, every entry in the <code>username</code> column will be updated with a random username, replacing any existing non-NULL values. If the <code>keep_null</code> parameter is set to <code>true</code>, then the transformer will preserve existing NULL values within the column, maintaining data integrity where usernames are not applicable or available.</p>"},{"location":"built_in_transformers/standard_transformers/random_uuid/","title":"RandomUuid","text":"<p>Generate random unique user ID using version 4.</p>"},{"location":"built_in_transformers/standard_transformers/random_uuid/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar, uuid keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/random_uuid/#description","title":"Description","text":"<p>The <code>RandomUuid</code> transformer generates a random UUID. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/random_uuid/#example-updating-the-rowguid-column","title":"Example: Updating the <code>rowguid</code> column","text":"<p>The following example replaces original UUID values of the <code>rowguid</code> column to randomly generated ones.</p> RandomUuid transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n  - name: \"RandomUuid\"\n    params:\n      column: \"rowguid\"\n      keep_null: false\n</code></pre> Expected result<pre><code>| column name | original value                       | transformed                          |\n|-------------|--------------------------------------|--------------------------------------|\n| rowguid     | f01251e5-96a3-448d-981e-0f99d789110d | 0211629f-d197-4187-8a87-095ec4f51977 |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/random_word/","title":"RandomWord","text":"<p>The <code>RandomWord</code> transformer populates specified database columns with random words. Ideal for simulating textual content, enhancing linguistic datasets, or anonymizing text in databases.</p>"},{"location":"built_in_transformers/standard_transformers/random_word/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_word/#description","title":"Description","text":"<p>The <code>RandomWord</code> transformer employs a mechanism to inject random words into a designated database column, supporting the generation of linguistically plausible and contextually diverse text. This transformer is particularly beneficial for creating rich text datasets for development, testing, or educational purposes without specifying the language, focusing on versatility and ease of use.</p>"},{"location":"built_in_transformers/standard_transformers/random_word/#example-populate-random-words-for-the-content-table","title":"Example: Populate random words for the <code>content</code> table","text":"<p>This example demonstrates configuring the <code>RandomWord</code> transformer to populate the <code>tag</code> column in the <code>content</code> table with random words. It is a straightforward approach to adding varied textual data for tagging or content categorization.</p> RandomWord transformer example<pre><code>- schema: \"public\"\n  name: \"content\"\n  transformers:\n    - name: \"RandomWord\"\n      params:\n        column: \"tag\"\n        keep_null: false\n</code></pre> <p>In this setup, the <code>tag</code> column will be updated with random words for each entry, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, existing NULL values in the column will remain unchanged, maintaining data integrity for records where textual data is not applicable.</p>"},{"location":"built_in_transformers/standard_transformers/random_year_string/","title":"RandomYearString","text":"<p>The <code>RandomYearString</code> transformer is designed to populate specified database columns with random year strings. It is ideal for scenarios that require the representation of years without specific dates, such as manufacturing years of products, birth years of users, or any other context where only the year is relevant.</p>"},{"location":"built_in_transformers/standard_transformers/random_year_string/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar, int2, int4, int8, numeric keep_null Indicates whether NULL values should be preserved <code>false</code> No -"},{"location":"built_in_transformers/standard_transformers/random_year_string/#description","title":"Description","text":"<p>The <code>RandomYearString</code> transformer leverages the <code>faker</code> library to generate strings representing random years. This allows for the easy generation of year data in a string format, adding versatility and realism to datasets that need to simulate or anonymize year-related information.</p>"},{"location":"built_in_transformers/standard_transformers/random_year_string/#example-populate-random-year-strings-for-the-products-table","title":"Example: Populate random year strings for the <code>products</code> table","text":"<p>This example shows how to use the <code>RandomYearString</code> transformer to fill the <code>manufacturing_year</code> column in the <code>products</code> table with random year strings, simulating the diversity of manufacturing dates.</p> RandomYearString transformer example<pre><code>- schema: \"public\"\n  name: \"products\"\n  transformers:\n    - name: \"RandomYearString\"\n      params:\n        column: \"manufacturing_year\"\n        keep_null: false\n</code></pre> <p>In this configuration, the <code>manufacturing_year</code> column will be populated with random year strings, replacing any existing non-NULL values. If <code>keep_null</code> is set to <code>true</code>, then existing NULL values in the column will be preserved.</p>"},{"location":"built_in_transformers/standard_transformers/real_address/","title":"RealAddress","text":"<p>Generates real addresses for specified database columns using the <code>faker</code> library. It supports customization of the generated address format through Go templates.</p>"},{"location":"built_in_transformers/standard_transformers/real_address/#parameters","title":"Parameters","text":"Name Properties Description Default Required Supported DB types columns Specifies the affected column names along with additional properties for each column Yes Various \u221f name The name of the column to be affected Yes string \u221f template A Go template string for formatting real address attributes Yes string \u221f keep_null Indicates whether NULL values should be preserved No bool"},{"location":"built_in_transformers/standard_transformers/real_address/#template-value-descriptions","title":"Template value descriptions","text":"<p>The <code>template</code> parameter allows for the injection of real address attributes into a customizable template. The following values can be included in your template:</p> <ul> <li><code>{{.Address}}</code> \u2014 street address or equivalent</li> <li><code>{{.City}}</code> \u2014 city name</li> <li><code>{{.State}}</code> \u2014 state, province, or equivalent region name</li> <li><code>{{.PostalCode}}</code> \u2014 postal or ZIP code</li> <li><code>{{.Latitude}}</code> \u2014 geographic latitude</li> <li><code>{{.Longitude}}</code> \u2014 geographic longitude</li> </ul> <p>These placeholders can be combined and formatted as desired within the template string to generate custom address formats.</p>"},{"location":"built_in_transformers/standard_transformers/real_address/#description","title":"Description","text":"<p>The <code>RealAddress</code> transformer uses the <code>faker</code> library to generate realistic addresses, which can then be formatted according to a specified template and applied to selected columns in a database. It allows for the generated addresses to replace existing values or to preserve NULL values, based on the transformer's configuration.</p>"},{"location":"built_in_transformers/standard_transformers/real_address/#example-generate-real-addresses-for-the-employee-table","title":"Example: Generate Real addresses for the <code>employee</code> table","text":"<p>This example shows how to configure the <code>RealAddress</code> transformer to generate real addresses for the <code>address</code> column in the <code>employee</code> table, using a custom format.</p> RealAddress transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n    - name: \"RealAddress\"\n      params:\n        columns:\n          - name: \"address\"\n            template: \"{{.Address}}, {{.City}}, {{.State}} {{.PostalCode}}\"\n            keep_null: false\n</code></pre> <p>This configuration will generate real addresses with the format \"Street address, city, state postal code\" and apply them to the <code>address</code> column, replacing any existing non-NULL values.</p>"},{"location":"built_in_transformers/standard_transformers/regexp_replace/","title":"RegexpReplace","text":"<p>Replace a string using a regular expression.</p>"},{"location":"built_in_transformers/standard_transformers/regexp_replace/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes text, varchar regexp The regular expression pattern to search for in the column's value Yes - replace The replacement value. This value may be replaced with a captured group from the <code>regexp</code> parameter. Yes -"},{"location":"built_in_transformers/standard_transformers/regexp_replace/#description","title":"Description","text":"<p>The <code>RegexpReplace</code> transformer replaces a string according to the applied regular expression. The valid regular expressions syntax is the same as the general syntax used by Perl, Python, and other languages. To be precise, it is the syntax accepted by RE2 and described in the Golang documentation, except for <code>\\C</code>.</p>"},{"location":"built_in_transformers/standard_transformers/regexp_replace/#example-removing-leading-prefix-from-loginid-column-value","title":"Example: Removing leading prefix from <code>loginid</code> column value","text":"<p>In the following example, the original values from <code>loginid</code> matching the <code>adventure-works\\{{ id_name }}</code> format are replaced with <code>{{ id_name }}</code>.</p> RegexpReplace transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n  - name: \"RegexpReplace\"\n    params:\n      column: \"loginid\"\n      regexp: \"adventure-works\\\\\\\\(.*)\"\n      replace: \"$1\"\n</code></pre> Expected result<pre><code>| column name | original value       | transformed |\n|-------------|----------------------|-------------|\n| loginid     | adventure-works\\ken0 | ken0        |\n</code></pre> <p>Note</p> <p>YAML has control symbols, and using them without escaping may result in an error. In the example above, the prefix of <code>id</code> is separated by the <code>\\</code> symbol. Since this symbol is a control symbol, we must escape it using <code>\\\\</code>. However, the '\\' symbol is also a control symbol for regular expressions, which is why we need to double-escape it as <code>\\\\\\\\</code>.</p>"},{"location":"built_in_transformers/standard_transformers/replace/","title":"Replace","text":"<p>Replace an original value by the provided one.</p>"},{"location":"built_in_transformers/standard_transformers/replace/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes any replace The value to replace Yes - keep_null Indicates whether NULL values should be replaced with transformed values or not <code>true</code> No - validate Performs a decoding procedure via the PostgreSQL driver using the column type to ensure that values have correct type <code>true</code> No -"},{"location":"built_in_transformers/standard_transformers/replace/#description","title":"Description","text":"<p>The <code>Replace</code> transformer replace an original value from the specified column with the provided one. It can optionally run a validation check with the <code>validate</code> parameter to ensure that the values are of a correct type before starting transformation. The behaviour for NULL values can be configured using the <code>keep_null</code> parameter.</p>"},{"location":"built_in_transformers/standard_transformers/replace/#example-updating-the-jobtitle-column","title":"Example: Updating the <code>jobtitle</code> column","text":"<p>In the following example, the provided <code>value: \"programmer\"</code> is first validated through driver decoding. If the current value of the <code>jobtitle</code> column is not <code>NULL</code>, it will be replaced with <code>programmer</code>. If the current value is <code>NULL</code>, it will remain <code>NULL</code>.</p> Replace transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformers:\n  - name: \"Replace\"\n    params:\n      column: \"jobtitle\"\n      value: \"programmer\"\n      keep_null: false\n      validate: true\n</code></pre> Expected result<pre><code>| column name | original value          | transformed |\n|-------------|-------------------------|-------------|\n| jobtitle    | Chief Executive Officer | programmer  |\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/set_null/","title":"SetNull","text":"<p>Set <code>NULL</code> value to a column.</p>"},{"location":"built_in_transformers/standard_transformers/set_null/#parameters","title":"Parameters","text":"Name Description Default Required Supported DB types column The name of the column to be affected Yes any"},{"location":"built_in_transformers/standard_transformers/set_null/#description","title":"Description","text":"<p>The <code>SetNull</code> transformer assigns <code>NULL</code> value to a column. This transformer generates warning if the affected column has <code>NOT NULL</code> constraint.</p> NULL constraint violation warning<pre><code>{\n  \"hash\": \"5a229ee964a4ba674a41a4d63dab5a8c\",\n  \"meta\": {\n    \"ColumnName\": \"jobtitle\",\n    \"ConstraintType\": \"NotNull\",\n    \"ParameterName\": \"column\",\n    \"SchemaName\": \"humanresources\",\n    \"TableName\": \"employee\",\n    \"TransformerName\": \"SetNull\"\n  },\n  \"msg\": \"transformer may produce NULL values but column has NOT NULL constraint\",\n  \"severity\": \"warning\"\n}\n</code></pre>"},{"location":"built_in_transformers/standard_transformers/set_null/#example-set-null-value-to-updated_at-column","title":"Example: Set NULL value to <code>updated_at</code> column","text":"SetNull transformer example<pre><code>- schema: \"humanresources\"\n  name: \"employee\"\n  transformation:\n    - name: \"SetNull\"\n      params:\n        column: \"jobtitle\"\n</code></pre> Expected result<pre><code>| column name | original value          | transformed |\n|-------------|-------------------------|-------------|\n| jobtitle    | Chief Executive Officer | NULL        |\n</code></pre>"},{"location":"release_notes/greenmask_0_1_0/","title":"Greenmask 0.1.0","text":"<p>We are excited to announce the release of Greenmask v0.1.0, marking the first production-ready version. This release addresses various bug fixes, introduces improvements, and includes documentation refactoring for enhanced clarity.</p>"},{"location":"release_notes/greenmask_0_1_0/#new-features","title":"New features","text":"<ul> <li> <p>Added positional arguments for the list-transformers command, allowing specific transformer information retrieval (e.g., <code>greenmask list-transformers RandomDate</code>).</p> </li> <li> <p>Added a version parameter <code>--version</code> that prints Greenmask version.</p> </li> <li> <p>Added numeric parameters support for <code>-Int</code> and <code>-Float</code> transformers.</p> </li> </ul>"},{"location":"release_notes/greenmask_0_1_0/#improvements","title":"Improvements","text":"<ul> <li> <p>Improved verbosity in custom transformer interaction, accumulating <code>stderr</code> data and forwarding it in batches instead of writing it one by one.</p> </li> <li> <p>Updated dependencies to newer versions.</p> </li> <li> <p>Enhanced the stability of the JSON line interaction protocol by utilizing the stdlib JSON encoder/decoder.</p> </li> <li> <p>Modified the method for sending table metadata to custom transformers; now, it is sent via <code>stdin</code> in the first line in JSON format instead of providing it via command arguments.</p> </li> <li> <p>Refactored template functions naming.</p> </li> <li> <p>Refactored <code>NoiseDate</code> transformer implementation for improved stability and predictability.</p> </li> <li> <p>Changed the default value for the <code>Dict</code> transformer: <code>fail_not_matched parameter: true</code>.</p> </li> <li> <p>Refactored the <code>Hash</code> transformer to provide a salt parameter and receive a base64 encoded salt. If salt is not provided, it generates one randomly.</p> </li> <li> <p>Added validation for the truncate parameter of <code>NoiseDate</code> and <code>RandomDate</code> transformers that issues a warning if the provided value is invalid.</p> </li> <li> <p>Increased verbosity of parameter validation warnings, now properly forwarding warnings to <code>stdout</code>.</p> </li> </ul>"},{"location":"release_notes/greenmask_0_1_0/#fixes","title":"Fixes","text":"<ul> <li> <p>Resolved <code>pgx</code> driver connection leakage issue.</p> </li> <li> <p>Fixed deletion failure of dumps for S3 storage.</p> </li> <li> <p>Corrected cobra autocompletion for the Greenmask utility.</p> </li> <li> <p>Fixed NOT NULL constraint validation.</p> </li> <li> <p>Addressed JSON API interaction issues that previously caused deadlocks and timeouts.</p> </li> <li> <p>Fixed encode-decoding for binary parameters, ensuring accurate forwarding of values to custom transformers.</p> </li> <li> <p>Fixed the <code>RandomChoice</code> transformer to correctly marshal and unmarshal values during validation.</p> </li> <li> <p>Introduced the nullable property for the <code>SetNull</code> transformer to enhance NOT NULL constraint validation.</p> </li> <li> <p>Resolved text wrapping issues for the <code>validate</code> command.</p> </li> <li> <p>Fixed build failures on Windows due to Linux platform dependencies.</p> </li> <li> <p>Corrected <code>stdout</code> readline buffer reading during interaction with custom transformers.</p> </li> <li> <p>Fixed integration tests.</p> </li> </ul>"},{"location":"release_notes/greenmask_0_1_0/#ecosystem-changes","title":"Ecosystem changes","text":"<ul> <li> <p>Implemented CI/CD pipelines for the entire project.</p> </li> <li> <p>Established a user-friendly playground in Docker compose, including:</p> </li> <li> <p>Deployed Minio storage container.</p> </li> <li>PostgreSQL container containing both the original database (Adventure Works) and the transformed (empty DB).</li> <li> <p>Greenmask container itself.</p> </li> <li> <p>Refactored current readme files.</p> </li> </ul>"},{"location":"release_notes/greenmask_0_1_0/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_0_beta/","title":"Greenmask 0.0.1 Beta","text":"<p>We are excited to announce the beta release of Greenmask, a versatile and open-source utility for PostgreSQL logical backup dumping, obfuscation, and restoration. Greenmask is perfect for routine backup and restoration tasks. It facilitates anonymization and data masking for staging environments and analytics.</p> <p>This release introduces a range of features aimed at enhancing database management and security.</p>"},{"location":"release_notes/greenmask_0_1_0_beta/#key-features","title":"Key features","text":"<ul> <li>Cross-platform support \u2014 fully written in Go without platform dependencies.</li> <li>Type-safe database operations \u2014 validates and encodes data, maintaining integrity.</li> <li>Transformation validation \u2014 ensures data transformations are correct and maintainable.</li> <li>Partitioned table support \u2014 simplifies configuration for partitioned tables.</li> <li>Stateless and backward compatible \u2014 works alongside standard PostgreSQL utilities.</li> <li>Parallel execution \u2014 enhances efficiency in dumping and restoration processes.</li> <li>Multiple storage options \u2014 supports both local (directory) and remote (S3-like) storage solutions.</li> </ul>"},{"location":"release_notes/greenmask_0_1_0_beta/#download","title":"Download","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_1/","title":"Greenmask 0.1.1","text":"<p>This release introduces a suite of new transformers, significantly enhancing Greenmask's capabilities for obfuscating PostgreSQL databases.</p>"},{"location":"release_notes/greenmask_0_1_1/#new-features","title":"New features","text":"<p>Added the following new transformers:</p> Transformer Description RandomLatitude Generates a random latitude value RandomLongitude Generates a random longitude value RandomUnixTime Generates a random Unix timestamp RandomMonthName Generates the name of a random month RandomYearString Generates a random year as a string RandomDayOfWeek Generates a random day of the week RandomDayOfMonth Generates a random day of the month RandomCentury Generates a random century RandomTimezone Generates a random timezone RandomEmail Generates a random email address RandomMacAddress Generates a random MAC address RandomDomainName Generates a random domain name RandomURL Generates a random URL RandomUsername Generates a random username RandomIPv4 Generates a random IPv4 address RandomIPv6 Generates a random IPv6 address RandomPassword Generates a random password RandomWord Generates a random word RandomSentence Generates a random sentence RandomParagraph Generates a random paragraph RandomCCType Generates a random credit card type RandomCCNumber Generates a random credit card number RandomCurrency Generates a random currency code RandomAmountWithCurrency Generates a random monetary amount with currency RandomTitleMale Generates a random title for males RandomTitleFemale Generates a random title for females RandomFirstName Generates a random first name RandomFirstNameMale Generates a random male first name RandomFirstNameFemale Generates a random female first name RandomLastName Generates a random last name RandomName Generates a full random name RandomPhoneNumber Generates a random phone number RandomTollFreePhoneNumber Generates a random toll-free phone number RandomE164PhoneNumber Generates a random phone number in E.164 format RealAddress Generates a real address"},{"location":"release_notes/greenmask_0_1_1/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_10/","title":"Greenmask 0.1.10","text":"<p>This release introduces improvements and bug fixes</p>"},{"location":"release_notes/greenmask_0_1_10/#changes","title":"Changes","text":"<ul> <li>Fixed panic caused in <code>RandomString</code> transformer</li> <li>Fixed wrong table size calculation. Now the table size includes TOAST table size</li> <li>Added custom transformer interaction API defaults if not set</li> <li>Changed docker workdir to greenmask home</li> <li>Removed bucket name from object path prefix</li> </ul>"},{"location":"release_notes/greenmask_0_1_10/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_11/","title":"Greenmask 0.1.11","text":"<p>This release introduces improvements and bug fixes</p>"},{"location":"release_notes/greenmask_0_1_11/#changes","title":"Changes","text":"<ul> <li>Added support for generated columns in the table</li> <li>Fixed transformer parameters encoding issue caused by spf13/viper</li> <li>Fixed table scoring for transformed table</li> <li>Refactored connection management logic in restore command - fixes connection idle timeout</li> </ul>"},{"location":"release_notes/greenmask_0_1_11/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_12/","title":"Greenmask 0.1.12","text":"<p>This release introduces improvements and bug fixes</p>"},{"location":"release_notes/greenmask_0_1_12/#changes","title":"Changes","text":"<ul> <li>Fixed config decoding issue caused</li> <li>Fixed TOC entries merge behavior when data section is empty</li> <li>Fixed integration tests for S3 storage</li> </ul>"},{"location":"release_notes/greenmask_0_1_12/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_13/","title":"Greenmask 0.1.13","text":"<p>This release introduces only improvements in documentation deployment. The core greenmask utility does not contain any changes.</p>"},{"location":"release_notes/greenmask_0_1_13/#changes","title":"Changes","text":"<ul> <li>Added documentation deployment with versioning</li> </ul>"},{"location":"release_notes/greenmask_0_1_13/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_2/","title":"Greenmask 0.1.2","text":"<p>This release introduces bug fixes.</p>"},{"location":"release_notes/greenmask_0_1_2/#fixes","title":"Fixes","text":"<ul> <li>Fixed bug when raw COPY lines were parsed incorrectly</li> <li>Fixed <code>--version</code> parameter behavior</li> <li>Fixed <code>--dbname</code> parameter - now it correctly works with PostgreSQL connection string in URI format <code>postgresql:///</code></li> </ul>"},{"location":"release_notes/greenmask_0_1_2/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_3/","title":"Greenmask 0.1.3","text":"<p>This release introduces bug fixes.</p>"},{"location":"release_notes/greenmask_0_1_3/#fixes","title":"Fixes","text":"<ul> <li>Fixed the JSON transformer's parsing for the <code>operations</code> fields</li> <li>Fixed database connection string builder in <code>pg_restore</code> and <code>pg_dump</code></li> </ul>"},{"location":"release_notes/greenmask_0_1_3/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_4/","title":"Greenmask 0.1.4","text":"<p>This release introduces bug fixes.</p>"},{"location":"release_notes/greenmask_0_1_4/#fixes","title":"Fixes","text":"<ul> <li>Fixed database connection string behavior fields</li> </ul>"},{"location":"release_notes/greenmask_0_1_4/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_5/","title":"Greenmask 0.1.5","text":"<p>This release introduces a new Greenmask command, improvements, bug fixes, and numerous documentation updates.</p>"},{"location":"release_notes/greenmask_0_1_5/#new-features","title":"New features","text":"<p>Added a new Greenmask CLI command\u2014show-transformer that shows detailed information about a specified transformer.</p>"},{"location":"release_notes/greenmask_0_1_5/#improvements","title":"Improvements","text":"<ul> <li>The Hash transformer has been completely remastered and now has the <code>function</code> parameter to choose from several hash algorithm options and the <code>max_length</code> parameter to truncate the hash tail.</li> <li>Split information about transformers between the <code>list-transformers</code> and new <code>show-transformer</code> CLI commands, which allows for more comprehensible and useful outputs for both commands</li> <li>Added error severity for the <code>Cmd</code> parameter validator</li> <li>Improved UX for the Greenmask release binaries</li> </ul>"},{"location":"release_notes/greenmask_0_1_5/#fixes","title":"Fixes","text":"<ul> <li>Fixed metadata enrichment for validation warnings caused by <code>RawValueValidator</code></li> <li>Fixed a typo in the <code>credit_card</code> value for the <code>type</code> parameter of the <code>Masking</code> transformer</li> <li>Fixed Greenmask Playground environment variables and the <code>cleanup</code> command</li> <li>Fixed <code>list-dump</code>, <code>list-transformers</code>, and <code>restore</code> commands exit code on error</li> </ul>"},{"location":"release_notes/greenmask_0_1_5/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_6/","title":"Greenmask 0.1.6","text":"<p>This is a minor release that introduces a bug hotfix</p>"},{"location":"release_notes/greenmask_0_1_6/#fixes","title":"Fixes","text":"<ul> <li>Fixed uncontrolled buffer growth in the restore command</li> </ul>"},{"location":"release_notes/greenmask_0_1_6/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_7/","title":"Greenmask 0.1.7","text":"<p>This release introduces a new Greenmask command, improvements, bug fixes, and documentation update.</p>"},{"location":"release_notes/greenmask_0_1_7/#new-features","title":"New features","text":"<ul> <li>Added restoration filtering by <code>--table</code>, <code>--schema</code> and <code>--exclude-schema</code> parameters</li> <li>Validate parameters without parameters validates only configuration file</li> <li>Added the <code>--schema</code> parameter, which allows to make a schema diff between the previous dump and the current. This    is useful when you want to check if the schema has changed after the migration. By controlling it we can exclude    data leakage after migration</li> <li>Validate command divided by many stages that can be controlled using parameters<ul> <li>Configuration validation</li> <li>Transformer validation</li> <li>Constraint violation check</li> <li>Data difference check</li> </ul> </li> </ul>"},{"location":"release_notes/greenmask_0_1_7/#improvements","title":"Improvements","text":"<ul> <li>Improved Hash transformer <ul> <li>Added salt parameter that can be set via config or via <code>GREENMASK_GLOBAL_SALT</code></li> <li>Added sha3 functions support in different modes (sha3-224, sha3-256, sha3-384, sha3-512)</li> </ul> </li> <li>Refactored <code>Cmd</code> transformer logic<ul> <li>Json API: Now it allows to use of column names instead of column indexes in JSON format</li> <li>Csv API: Now it can use the column order from config via column remapping</li> </ul> </li> <li>The <code>validate</code> command was rewritten almost from scratch.<ul> <li>New option <code>--transformed-only</code> - displays only columns that are transformed with primary key (if exists). This   allows to reduce the output data and make it more readable</li> <li>Implemented <code>json</code> format for output</li> <li>Added the <code>--table-format</code> parameter which is responsible for the <code>vertical</code> and <code>horizontal</code> table orientation.   This works only when <code>--format=text</code></li> <li>Added the <code>--warnings</code> parameter, if it is specified then not only fatal-warnings will be displayed, but also   those with a lower severity</li> </ul> </li> </ul>"},{"location":"release_notes/greenmask_0_1_7/#fixes","title":"Fixes","text":"<ul> <li>Fixed <code>--use-list</code> option - now it applies toc entries according to the order in list file</li> <li>Fixed <code>--use-list</code> option behaviour together with <code>--list-format</code> option (<code>json</code> or <code>text</code>). Now it   generates temporal list file in text format for providing it to the pg_restore call</li> <li>Updated documentation according to the latest changes</li> </ul>"},{"location":"release_notes/greenmask_0_1_7/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_8/","title":"Greenmask 0.1.8","text":"<p>This release introduces improvements and bug fixes</p>"},{"location":"release_notes/greenmask_0_1_8/#improvements","title":"Improvements","text":"<ul> <li>Implemented <code>--exit-on-error</code> parameter for <code>pg_restore</code> run. But it does not play for \"data\" section restoration now. If any error is caused in <code>data</code> section greenmask exits with the error whether <code>--exit-on-error</code> was provided or not. This might be fixed later</li> </ul>"},{"location":"release_notes/greenmask_0_1_8/#fixes","title":"Fixes","text":"<ul> <li>Fixed dependent objects dropping when running with the <code>restore</code> command with the <code>--clean</code> parameter. Useful when restoring and overriding only required tables</li> <li>Fixed <code>show-dump</code> command output in text mode</li> <li>Disabled CGO. Fixes problem when downloaded binary from repo cannot run</li> <li>Fixed <code>delete</code> dump operation</li> </ul>"},{"location":"release_notes/greenmask_0_1_8/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"},{"location":"release_notes/greenmask_0_1_9/","title":"Greenmask 0.1.9","text":"<p>This release introduces improvements and bug fixes</p>"},{"location":"release_notes/greenmask_0_1_9/#improvements","title":"Improvements","text":"<ul> <li>Implemented tables scoring according to the table size and transformation costs. This correctly spread the tables   dumping between the requested workers pool and reduces the execution time. Now greenmask introspects the table size,   adds the transformation scoring using the formula   <code>score = tableSizeInBytes + (tableSizeInBytes * 0.03 * tableTransformationsCount)</code>, and uses the strategy \"Largest   First\". The problem is described here</li> <li>Introduced <code>no_verify_ssl</code> parameter for S3 storage</li> <li>Adjusted Dockerfile<ul> <li>Changed entrypoint to <code>greenmask</code> binary</li> <li>The <code>greenmask</code> container now runs under <code>greenmask</code> user and groups</li> </ul> </li> <li>Refactored storage config structure. Now it contains the <code>type</code> that is used for the storage type determination</li> <li>Most of the attributes may be overridden with environment variables where the letters are capitalized and the dots   are replaced with underscores. For instance, the setting <code>storage.type</code> might be represented with the environment   variable <code>STORAGE_TYPE</code></li> <li>Parameter <code>--config</code> is not required anymore. This simplifies the greenmask utility user experience</li> <li>Directory storage set as the default</li> <li>Set the default temporary directory as <code>/tmp</code></li> <li>Added environment variable section to the configuration docs</li> </ul>"},{"location":"release_notes/greenmask_0_1_9/#fixes","title":"Fixes","text":"<ul> <li>Fixed <code>S3_REGION</code> environment variable usage. Tested cases where the S3 storage is set up using <code>S3</code> variables that   uses by <code>github.com/aws/aws-sdk-go</code></li> <li>Updated project dependencies to the latest version</li> </ul>"},{"location":"release_notes/greenmask_0_1_9/#assets","title":"Assets","text":"<p>To download the Greenmask binary compatible with your system, see the release's assets list.</p>"}]}